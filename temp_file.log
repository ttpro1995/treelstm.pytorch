2017-05-02 23:53:00,827 : INFO : LOG_FILE
2017-05-02 23:53:00,834 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.01, mem_dim=150, num_classes=5, optim='adam', seed=123, wd=0.0001)
2017-05-02 23:53:00,944 : INFO : ==> SST vocabulary size : 21705
2017-05-02 23:54:47,876 : INFO : LOG_FILE
2017-05-02 23:54:47,882 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.01, mem_dim=150, num_classes=5, optim='adagrad', seed=123, wd=0.0001)
2017-05-02 23:54:47,996 : INFO : ==> SST vocabulary size : 21705
2017-05-03 00:14:31,841 : INFO : ==> Train loss   : 1.129850
2017-05-03 00:22:31,425 : INFO : LOG_FILE
2017-05-03 00:22:31,455 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.01, mem_dim=150, num_classes=5, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 00:22:31,559 : INFO : ==> SST vocabulary size : 21705
2017-05-03 00:26:43,229 : INFO : LOG_FILE
2017-05-03 00:26:43,261 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.01, mem_dim=150, num_classes=5, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 00:26:43,376 : INFO : ==> SST vocabulary size : 21705
2017-05-03 00:46:41,409 : INFO : LOG_FILE
2017-05-03 00:46:41,444 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.01, mem_dim=150, num_classes=5, optim='adam', seed=123, wd=0.0001)
2017-05-03 00:46:41,752 : INFO : ==> SST vocabulary size : 21705
2017-05-03 01:09:38,641 : INFO : LOG_FILE
2017-05-03 01:09:38,676 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.01, mem_dim=150, num_classes=5, optim='adam', seed=123, wd=0.0001)
2017-05-03 01:09:38,970 : INFO : ==> SST vocabulary size : 21705
2017-05-03 01:10:47,579 : INFO : LOG_FILE
2017-05-03 01:10:47,623 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.01, mem_dim=150, num_classes=5, optim='adam', seed=123, wd=0.0001)
2017-05-03 01:10:47,831 : INFO : ==> SST vocabulary size : 21705
2017-05-03 01:43:20,740 : INFO : LOG_FILE
2017-05-03 01:43:20,771 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.01, mem_dim=150, num_classes=5, optim='adam', seed=123, wd=0.0001)
2017-05-03 01:43:20,879 : INFO : ==> SST vocabulary size : 21705
2017-05-03 01:43:40,224 : INFO : LOG_FILE
2017-05-03 01:43:40,256 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.01, mem_dim=150, num_classes=5, optim='adam', seed=123, wd=0.0001)
2017-05-03 01:43:40,441 : INFO : ==> SST vocabulary size : 21705
2017-05-03 01:43:48,997 : INFO : LOG_FILE
2017-05-03 01:43:49,028 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.01, mem_dim=150, num_classes=5, optim='adam', seed=123, wd=0.0001)
2017-05-03 01:43:49,227 : INFO : ==> SST vocabulary size : 21705
2017-05-03 01:49:11,582 : INFO : LOG_FILE
2017-05-03 01:49:11,614 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.01, mem_dim=150, num_classes=5, optim='adam', seed=123, wd=0.0001)
2017-05-03 01:49:11,811 : INFO : ==> SST vocabulary size : 21705
2017-05-03 01:52:36,598 : INFO : LOG_FILE
2017-05-03 01:52:36,628 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.01, mem_dim=150, num_classes=5, optim='adam', seed=123, wd=0.0001)
2017-05-03 01:52:36,826 : INFO : ==> SST vocabulary size : 21705
2017-05-03 01:55:37,543 : INFO : LOG_FILE
2017-05-03 01:55:37,577 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.01, mem_dim=150, num_classes=5, optim='adam', seed=123, wd=0.0001)
2017-05-03 01:55:37,775 : INFO : ==> SST vocabulary size : 21705
2017-05-03 01:59:03,674 : INFO : LOG_FILE
2017-05-03 01:59:03,704 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.01, mem_dim=150, num_classes=5, optim='adam', seed=123, wd=0.0001)
2017-05-03 01:59:03,903 : INFO : ==> SST vocabulary size : 21705
2017-05-03 02:03:19,246 : INFO : LOG_FILE
2017-05-03 02:03:19,278 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.01, mem_dim=150, num_classes=5, optim='adam', seed=123, wd=0.0001)
2017-05-03 02:03:19,479 : INFO : ==> SST vocabulary size : 21705
2017-05-03 09:52:00,675 : INFO : LOG_FILE
2017-05-03 09:52:00,704 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.01, mem_dim=150, num_classes=5, optim='adam', seed=123, wd=0.0001)
2017-05-03 09:52:00,902 : INFO : ==> SST vocabulary size : 21705
2017-05-03 09:53:48,259 : INFO : LOG_FILE
2017-05-03 09:53:48,291 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.01, mem_dim=150, num_classes=5, optim='adam', seed=123, wd=0.0001)
2017-05-03 09:53:48,494 : INFO : ==> SST vocabulary size : 21705
2017-05-03 09:59:08,037 : INFO : LOG_FILE
2017-05-03 09:59:08,072 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.01, mem_dim=150, num_classes=5, optim='adam', seed=123, wd=0.0001)
2017-05-03 09:59:08,272 : INFO : ==> SST vocabulary size : 21705
2017-05-03 10:04:38,985 : INFO : LOG_FILE
2017-05-03 10:04:39,017 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.01, mem_dim=150, num_classes=5, optim='adam', seed=123, wd=0.0001)
2017-05-03 10:04:39,228 : INFO : ==> SST vocabulary size : 21705
2017-05-03 10:06:26,778 : INFO : ==> File found, loading to memory
2017-05-03 10:06:42,039 : INFO : ==> GLOVE vocabulary size: 2196016
2017-05-03 10:21:57,294 : INFO : LOG_FILE
2017-05-03 10:21:57,360 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.01, mem_dim=150, num_classes=5, optim='adam', seed=123, wd=0.0001)
2017-05-03 10:21:57,589 : INFO : ==> SST vocabulary size : 21705
2017-05-03 10:22:39,551 : INFO : ==> File found, loading to memory
2017-05-03 10:23:07,223 : INFO : ==> GLOVE vocabulary size: 2196016
2017-05-03 10:30:37,542 : INFO : LOG_FILE
2017-05-03 10:30:37,613 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.01, mem_dim=150, num_classes=5, optim='adam', seed=123, wd=0.0001)
2017-05-03 10:30:37,732 : INFO : ==> SST vocabulary size : 21705
2017-05-03 10:33:14,135 : INFO : LOG_FILE
2017-05-03 10:33:14,166 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.01, mem_dim=150, num_classes=5, optim='adam', seed=123, wd=0.0001)
2017-05-03 10:33:14,367 : INFO : ==> SST vocabulary size : 21705
2017-05-03 10:38:35,325 : INFO : LOG_FILE
2017-05-03 10:38:35,357 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.01, mem_dim=150, num_classes=5, optim='adam', seed=123, wd=0.0001)
2017-05-03 10:38:35,461 : INFO : ==> SST vocabulary size : 21705
2017-05-03 10:40:02,529 : INFO : LOG_FILE
2017-05-03 10:40:02,561 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.01, mem_dim=150, num_classes=5, optim='adam', seed=123, wd=0.0001)
2017-05-03 10:40:02,664 : INFO : ==> SST vocabulary size : 21705
2017-05-03 10:42:26,344 : INFO : ==> Train loss   : 1.196269
2017-05-03 10:42:26,345 : INFO : Epoch
2017-05-03 10:42:26,345 : INFO : 0
2017-05-03 10:42:26,345 : INFO :  percentage
2017-05-03 10:42:26,345 : INFO : 0.00726612170754
2017-05-03 10:44:43,912 : INFO : ==> Train loss   : 0.419768
2017-05-03 10:44:43,913 : INFO : Epoch
2017-05-03 10:44:43,913 : INFO : 1
2017-05-03 10:44:43,913 : INFO :  percentage
2017-05-03 10:44:43,913 : INFO : 0.00272479564033
2017-05-03 10:47:02,231 : INFO : ==> Train loss   : 0.086039
2017-05-03 10:47:02,231 : INFO : Epoch
2017-05-03 10:47:02,231 : INFO : 2
2017-05-03 10:47:02,231 : INFO :  percentage
2017-05-03 10:47:02,232 : INFO : 0.000908265213442
2017-05-03 10:47:35,904 : INFO : LOG_FILE
2017-05-03 10:47:35,935 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.01, mem_dim=150, num_classes=5, optim='adam', seed=123, wd=0.0001)
2017-05-03 10:47:36,130 : INFO : ==> SST vocabulary size : 21705
2017-05-03 10:58:58,200 : INFO : LOG_FILE
2017-05-03 10:58:58,227 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.01, mem_dim=150, num_classes=5, optim='adam', seed=123, wd=0.0001)
2017-05-03 10:58:58,329 : INFO : ==> SST vocabulary size : 21705
2017-05-03 11:02:24,382 : INFO : LOG_FILE
2017-05-03 11:02:24,412 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.01, mem_dim=150, num_classes=5, optim='adam', seed=123, wd=0.0001)
2017-05-03 11:02:24,516 : INFO : ==> SST vocabulary size : 21705
2017-05-03 11:04:45,880 : INFO : ==> Train loss   : 1.196269
2017-05-03 11:04:45,881 : INFO : Epoch
2017-05-03 11:04:45,881 : INFO : 0
2017-05-03 11:04:45,881 : INFO :  percentage
2017-05-03 11:04:45,881 : INFO : 0.549500454133
2017-05-03 11:07:02,331 : INFO : ==> Train loss   : 0.419768
2017-05-03 11:07:02,332 : INFO : Epoch
2017-05-03 11:07:02,332 : INFO : 1
2017-05-03 11:07:02,332 : INFO :  percentage
2017-05-03 11:07:02,332 : INFO : 0.874659400545
2017-05-03 11:09:15,190 : INFO : ==> Train loss   : 0.086039
2017-05-03 11:09:15,190 : INFO : Epoch
2017-05-03 11:09:15,192 : INFO : 2
2017-05-03 11:09:15,192 : INFO :  percentage
2017-05-03 11:09:15,192 : INFO : 0.97366030881
2017-05-03 11:11:28,467 : INFO : ==> Train loss   : 0.011199
2017-05-03 11:11:28,467 : INFO : Epoch
2017-05-03 11:11:28,468 : INFO : 3
2017-05-03 11:11:28,468 : INFO :  percentage
2017-05-03 11:11:28,468 : INFO : 1.0
2017-05-03 11:13:03,128 : INFO : LOG_FILE
2017-05-03 11:13:03,157 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.01, mem_dim=150, num_classes=5, optim='adam', seed=123, wd=0.0001)
2017-05-03 11:13:03,262 : INFO : ==> SST vocabulary size : 21705
2017-05-03 11:27:29,916 : INFO : ==> Train loss   : 1.446348
2017-05-03 11:27:29,916 : INFO : Epoch
2017-05-03 11:27:29,916 : INFO : 0
2017-05-03 11:27:29,917 : INFO : dev percentage
2017-05-03 11:27:29,917 : INFO : 0.366030881017
2017-05-03 11:27:29,917 : INFO : Epoch
2017-05-03 11:27:29,917 : INFO : 0
2017-05-03 11:27:29,917 : INFO : test percentage
2017-05-03 11:27:29,917 : INFO : 0.405429864253
2017-05-03 11:41:02,503 : INFO : ==> Train loss   : 1.052879
2017-05-03 11:41:02,504 : INFO : Epoch
2017-05-03 11:41:02,504 : INFO : 1
2017-05-03 11:41:02,504 : INFO : dev percentage
2017-05-03 11:41:02,504 : INFO : 0.351498637602
2017-05-03 11:41:02,504 : INFO : Epoch
2017-05-03 11:41:02,504 : INFO : 1
2017-05-03 11:41:02,504 : INFO : test percentage
2017-05-03 11:41:02,504 : INFO : 0.357918552036
2017-05-03 11:54:27,294 : INFO : ==> Train loss   : 0.678486
2017-05-03 11:54:27,294 : INFO : Epoch
2017-05-03 11:54:27,294 : INFO : 2
2017-05-03 11:54:27,294 : INFO : dev percentage
2017-05-03 11:54:27,294 : INFO : 0.354223433243
2017-05-03 11:54:27,294 : INFO : Epoch
2017-05-03 11:54:27,294 : INFO : 2
2017-05-03 11:54:27,294 : INFO : test percentage
2017-05-03 11:54:27,295 : INFO : 0.351131221719
2017-05-03 12:07:53,569 : INFO : ==> Train loss   : 0.493265
2017-05-03 12:07:53,570 : INFO : Epoch
2017-05-03 12:07:53,570 : INFO : 3
2017-05-03 12:07:53,570 : INFO : dev percentage
2017-05-03 12:07:53,570 : INFO : 0.320617620345
2017-05-03 12:07:53,570 : INFO : Epoch
2017-05-03 12:07:53,570 : INFO : 3
2017-05-03 12:07:53,570 : INFO : test percentage
2017-05-03 12:07:53,570 : INFO : 0.357918552036
2017-05-03 12:21:18,558 : INFO : ==> Train loss   : 0.394966
2017-05-03 12:21:18,558 : INFO : Epoch
2017-05-03 12:21:18,558 : INFO : 4
2017-05-03 12:21:18,558 : INFO : dev percentage
2017-05-03 12:21:18,558 : INFO : 0.325158946412
2017-05-03 12:21:18,559 : INFO : Epoch
2017-05-03 12:21:18,559 : INFO : 4
2017-05-03 12:21:18,559 : INFO : test percentage
2017-05-03 12:21:18,559 : INFO : 0.350226244344
2017-05-03 12:32:21,911 : INFO : LOG_FILE
2017-05-03 12:32:21,941 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.01, mem_dim=150, num_classes=5, optim='adam', seed=123, wd=0.0001)
2017-05-03 12:32:22,049 : INFO : ==> SST vocabulary size : 21705
2017-05-03 12:46:23,326 : INFO : ==> Train loss   : 1.446348
2017-05-03 12:46:23,326 : INFO : Epoch
2017-05-03 12:46:23,326 : INFO : 0
2017-05-03 12:46:23,326 : INFO : dev percentage
2017-05-03 12:46:23,326 : INFO : 0.366030881017
2017-05-03 12:46:23,326 : INFO : Epoch
2017-05-03 12:46:23,326 : INFO : 0
2017-05-03 12:46:23,327 : INFO : test percentage
2017-05-03 12:46:23,327 : INFO : 0.405429864253
2017-05-03 13:00:11,676 : INFO : ==> Train loss   : 1.052879
2017-05-03 13:00:11,676 : INFO : Epoch
2017-05-03 13:00:11,676 : INFO : 1
2017-05-03 13:00:11,676 : INFO : dev percentage
2017-05-03 13:00:11,676 : INFO : 0.351498637602
2017-05-03 13:00:11,676 : INFO : Epoch
2017-05-03 13:00:11,676 : INFO : 1
2017-05-03 13:00:11,676 : INFO : test percentage
2017-05-03 13:00:11,677 : INFO : 0.357918552036
2017-05-03 13:13:39,216 : INFO : ==> Train loss   : 0.678486
2017-05-03 13:13:39,216 : INFO : Epoch
2017-05-03 13:13:39,216 : INFO : 2
2017-05-03 13:13:39,217 : INFO : dev percentage
2017-05-03 13:13:39,217 : INFO : 0.354223433243
2017-05-03 13:13:39,217 : INFO : Epoch
2017-05-03 13:13:39,217 : INFO : 2
2017-05-03 13:13:39,217 : INFO : test percentage
2017-05-03 13:13:39,217 : INFO : 0.351131221719
2017-05-03 13:26:53,269 : INFO : ==> Train loss   : 0.493265
2017-05-03 13:26:53,269 : INFO : Epoch
2017-05-03 13:26:53,269 : INFO : 3
2017-05-03 13:26:53,270 : INFO : dev percentage
2017-05-03 13:26:53,270 : INFO : 0.320617620345
2017-05-03 13:26:53,270 : INFO : Epoch
2017-05-03 13:26:53,270 : INFO : 3
2017-05-03 13:26:53,270 : INFO : test percentage
2017-05-03 13:26:53,270 : INFO : 0.357918552036
2017-05-03 13:40:05,324 : INFO : ==> Train loss   : 0.394966
2017-05-03 13:40:05,325 : INFO : Epoch
2017-05-03 13:40:05,325 : INFO : 4
2017-05-03 13:40:05,325 : INFO : dev percentage
2017-05-03 13:40:05,325 : INFO : 0.325158946412
2017-05-03 13:40:05,325 : INFO : Epoch
2017-05-03 13:40:05,325 : INFO : 4
2017-05-03 13:40:05,325 : INFO : test percentage
2017-05-03 13:40:05,325 : INFO : 0.350226244344
2017-05-03 13:44:05,926 : INFO : LOG_FILE
2017-05-03 13:44:05,927 : INFO : _________________________________start___________________________________
2017-05-03 13:44:05,955 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.01, mem_dim=150, num_classes=5, optim='adam', seed=123, wd=0.0001)
2017-05-03 13:44:06,058 : INFO : ==> SST vocabulary size : 21705
2017-05-03 13:58:22,307 : INFO : ==> Train loss   : 1.446348
2017-05-03 13:58:22,307 : INFO : Epoch
2017-05-03 13:58:22,307 : INFO : 0
2017-05-03 13:58:22,307 : INFO : dev percentage
2017-05-03 13:58:22,307 : INFO : 0.366030881017
2017-05-03 13:58:22,307 : INFO : Epoch
2017-05-03 13:58:22,307 : INFO : 0
2017-05-03 13:58:22,308 : INFO : test percentage
2017-05-03 13:58:22,308 : INFO : 0.405429864253
2017-05-03 14:12:17,053 : INFO : ==> Train loss   : 1.052879
2017-05-03 14:12:17,053 : INFO : Epoch
2017-05-03 14:12:17,054 : INFO : 1
2017-05-03 14:12:17,054 : INFO : dev percentage
2017-05-03 14:12:17,054 : INFO : 0.351498637602
2017-05-03 14:12:17,054 : INFO : Epoch
2017-05-03 14:12:17,054 : INFO : 1
2017-05-03 14:12:17,054 : INFO : test percentage
2017-05-03 14:12:17,054 : INFO : 0.357918552036
2017-05-03 14:29:14,591 : INFO : LOG_FILE
2017-05-03 14:29:14,591 : INFO : _________________________________start___________________________________
2017-05-03 14:29:14,620 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=150, num_classes=5, optim='adagrad', seed=123, wd=0)
2017-05-03 14:29:14,724 : INFO : ==> SST vocabulary size : 21705
2017-05-03 14:43:30,464 : INFO : ==> Train loss   : 1.524501
2017-05-03 14:43:30,464 : INFO : Epoch
2017-05-03 14:43:30,464 : INFO : 0
2017-05-03 14:43:30,464 : INFO : dev percentage
2017-05-03 14:43:30,464 : INFO : 0.406902815622
2017-05-03 14:43:30,464 : INFO : Epoch
2017-05-03 14:43:30,464 : INFO : 0
2017-05-03 14:43:30,465 : INFO : test percentage
2017-05-03 14:43:30,465 : INFO : 0.419457013575
2017-05-03 14:57:05,756 : INFO : ==> Train loss   : 0.764218
2017-05-03 14:57:05,756 : INFO : Epoch
2017-05-03 14:57:05,756 : INFO : 1
2017-05-03 14:57:05,756 : INFO : dev percentage
2017-05-03 14:57:05,756 : INFO : 0.38782924614
2017-05-03 14:57:05,756 : INFO : Epoch
2017-05-03 14:57:05,757 : INFO : 1
2017-05-03 14:57:05,757 : INFO : test percentage
2017-05-03 14:57:05,757 : INFO : 0.415837104072
2017-05-03 15:06:22,937 : INFO : LOG_FILE
2017-05-03 15:06:22,937 : INFO : _________________________________start___________________________________
2017-05-03 15:06:22,963 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0)
2017-05-03 15:06:23,066 : INFO : ==> SST vocabulary size : 21705
2017-05-03 15:20:34,736 : INFO : ==> Train loss   : 0.998788
2017-05-03 15:20:34,736 : INFO : Epoch
2017-05-03 15:20:34,736 : INFO : 0
2017-05-03 15:20:34,736 : INFO : dev percentage
2017-05-03 15:20:34,736 : INFO : 0.207992733878
2017-05-03 15:20:34,737 : INFO : Epoch
2017-05-03 15:20:34,737 : INFO : 0
2017-05-03 15:20:34,737 : INFO : test percentage
2017-05-03 15:20:34,737 : INFO : 0.17963800905
2017-05-03 15:37:50,415 : INFO : LOG_FILE
2017-05-03 15:37:50,416 : INFO : _________________________________start___________________________________
2017-05-03 15:37:50,444 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0)
2017-05-03 15:37:50,549 : INFO : ==> SST vocabulary size : 21705
2017-05-03 15:41:02,737 : INFO : LOG_FILE
2017-05-03 15:41:02,737 : INFO : _________________________________start___________________________________
2017-05-03 15:41:02,765 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0)
2017-05-03 15:41:02,870 : INFO : ==> SST vocabulary size : 21705
2017-05-03 15:41:24,023 : INFO : LOG_FILE
2017-05-03 15:41:24,023 : INFO : _________________________________start___________________________________
2017-05-03 15:41:24,049 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0)
2017-05-03 15:41:24,156 : INFO : ==> SST vocabulary size : 21705
2017-05-03 15:41:33,968 : INFO : quit program due to memory leak during preprocess data, please rerun
2017-05-03 15:41:36,659 : INFO : ==> File found, loading to memory
2017-05-03 15:41:59,628 : INFO : LOG_FILE
2017-05-03 15:41:59,628 : INFO : _________________________________start___________________________________
2017-05-03 15:41:59,656 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0)
2017-05-03 15:41:59,766 : INFO : ==> SST vocabulary size : 21705
2017-05-03 15:42:05,213 : INFO : ==> File found, loading to memory
2017-05-03 15:42:19,727 : INFO : ==> GLOVE vocabulary size: 2196016
2017-05-03 15:42:56,943 : INFO : LOG_FILE
2017-05-03 15:42:56,943 : INFO : _________________________________start___________________________________
2017-05-03 15:42:56,971 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0)
2017-05-03 15:42:57,076 : INFO : ==> SST vocabulary size : 21705
2017-05-03 15:43:11,999 : INFO : LOG_FILE
2017-05-03 15:43:11,999 : INFO : _________________________________start___________________________________
2017-05-03 15:43:12,031 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0)
2017-05-03 15:43:12,141 : INFO : ==> SST vocabulary size : 21705
2017-05-03 15:43:43,029 : INFO : LOG_FILE
2017-05-03 15:43:43,029 : INFO : _________________________________start___________________________________
2017-05-03 15:43:43,057 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0)
2017-05-03 15:43:43,161 : INFO : ==> SST vocabulary size : 21705
2017-05-03 15:46:03,850 : INFO : ==> Train loss   : 3.141350
2017-05-03 15:46:03,850 : INFO : Epoch
2017-05-03 15:46:03,850 : INFO : 0
2017-05-03 15:46:03,851 : INFO : dev percentage
2017-05-03 15:46:03,851 : INFO : 0.0481380563124
2017-05-03 15:48:16,013 : INFO : ==> Train loss   : 0.432979
2017-05-03 15:48:16,014 : INFO : Epoch
2017-05-03 15:48:16,014 : INFO : 1
2017-05-03 15:48:16,014 : INFO : dev percentage
2017-05-03 15:48:16,014 : INFO : 0.00544959128065
2017-05-03 15:50:04,482 : INFO : LOG_FILE
2017-05-03 15:50:04,482 : INFO : _________________________________start___________________________________
2017-05-03 15:50:04,511 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0)
2017-05-03 15:50:04,705 : INFO : ==> SST vocabulary size : 21705
2017-05-03 15:56:11,899 : INFO : LOG_FILE
2017-05-03 15:56:11,899 : INFO : _________________________________start___________________________________
2017-05-03 15:56:11,926 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0)
2017-05-03 15:56:12,030 : INFO : ==> SST vocabulary size : 21705
2017-05-03 16:00:02,918 : INFO : LOG_FILE
2017-05-03 16:00:02,918 : INFO : _________________________________start___________________________________
2017-05-03 16:00:02,947 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0)
2017-05-03 16:00:03,054 : INFO : ==> SST vocabulary size : 21705
2017-05-03 16:02:27,327 : INFO : ==> Train loss   : 3.141350
2017-05-03 16:02:27,327 : INFO : Epoch
2017-05-03 16:02:27,328 : INFO : 0
2017-05-03 16:02:27,328 : INFO : dev percentage
2017-05-03 16:02:27,328 : INFO : 0.841053587648
2017-05-03 16:13:17,559 : INFO : LOG_FILE
2017-05-03 16:13:17,559 : INFO : _________________________________start___________________________________
2017-05-03 16:13:17,587 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 16:13:17,693 : INFO : ==> SST vocabulary size : 21705
2017-05-03 16:15:21,024 : INFO : LOG_FILE
2017-05-03 16:15:21,024 : INFO : _________________________________start___________________________________
2017-05-03 16:15:21,052 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 16:15:21,157 : INFO : ==> SST vocabulary size : 21705
2017-05-03 16:30:23,174 : INFO : ==> Train loss   : 1.049211
2017-05-03 16:30:23,174 : INFO : Epoch
2017-05-03 16:30:23,174 : INFO : 0
2017-05-03 16:30:23,175 : INFO : dev percentage
2017-05-03 16:30:23,175 : INFO : 0.633060853769
2017-05-03 16:30:23,175 : INFO : Epoch
2017-05-03 16:30:23,175 : INFO : 0
2017-05-03 16:30:23,175 : INFO : test percentage
2017-05-03 16:30:23,175 : INFO : 0.676018099548
2017-05-03 16:44:41,902 : INFO : ==> Train loss   : 0.441415
2017-05-03 16:44:41,902 : INFO : Epoch
2017-05-03 16:44:41,902 : INFO : 1
2017-05-03 16:44:41,903 : INFO : dev percentage
2017-05-03 16:44:41,903 : INFO : 0.600363306085
2017-05-03 16:44:41,903 : INFO : Epoch
2017-05-03 16:44:41,903 : INFO : 1
2017-05-03 16:44:41,903 : INFO : test percentage
2017-05-03 16:44:41,903 : INFO : 0.641176470588
2017-05-03 17:00:04,883 : INFO : ==> Train loss   : 0.148315
2017-05-03 17:00:04,883 : INFO : Epoch
2017-05-03 17:00:04,883 : INFO : 2
2017-05-03 17:00:04,883 : INFO : dev percentage
2017-05-03 17:00:04,884 : INFO : 0.58310626703
2017-05-03 17:00:04,884 : INFO : Epoch
2017-05-03 17:00:04,884 : INFO : 2
2017-05-03 17:00:04,884 : INFO : test percentage
2017-05-03 17:00:04,884 : INFO : 0.606334841629
2017-05-03 17:14:48,798 : INFO : LOG_FILE
2017-05-03 17:14:48,799 : INFO : _________________________________start___________________________________
2017-05-03 17:14:48,829 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 17:14:48,943 : INFO : ==> SST vocabulary size : 21705
2017-05-03 17:15:01,014 : INFO : ==> File found, loading to memory
2017-05-03 17:15:11,041 : INFO : ==> GLOVE vocabulary size: 2196016
2017-05-03 17:15:11,720 : INFO : done creating emb, quit
2017-05-03 17:15:11,721 : INFO : quit program due to memory leak during preprocess data, please rerun sentiment.py
2017-05-03 17:15:19,579 : INFO : LOG_FILE
2017-05-03 17:15:19,579 : INFO : _________________________________start___________________________________
2017-05-03 17:15:19,615 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 17:15:19,742 : INFO : ==> SST vocabulary size : 21705
2017-05-03 17:18:02,620 : INFO : LOG_FILE
2017-05-03 17:18:02,621 : INFO : _________________________________start___________________________________
2017-05-03 17:18:02,648 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 17:18:02,759 : INFO : ==> SST vocabulary size : 21705
2017-05-03 17:18:14,892 : INFO : ==> File found, loading to memory
2017-05-03 17:18:20,013 : INFO : ==> GLOVE vocabulary size: 2196016
2017-05-03 17:18:20,703 : INFO : done creating emb, quit
2017-05-03 17:18:20,703 : INFO : quit program due to memory leak during preprocess data, please rerun sentiment.py
2017-05-03 17:20:43,230 : INFO : LOG_FILE
2017-05-03 17:20:43,231 : INFO : _________________________________start___________________________________
2017-05-03 17:20:43,260 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 17:20:43,366 : INFO : ==> SST vocabulary size : 21705
2017-05-03 17:20:55,495 : INFO : ==> File found, loading to memory
2017-05-03 17:21:00,599 : INFO : ==> GLOVE vocabulary size: 2196016
2017-05-03 17:21:01,269 : INFO : done creating emb, quit
2017-05-03 17:21:01,269 : INFO : quit program due to memory leak during preprocess data, please rerun sentiment.py
2017-05-03 17:21:04,556 : INFO : LOG_FILE
2017-05-03 17:21:04,556 : INFO : _________________________________start___________________________________
2017-05-03 17:21:04,585 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 17:21:04,699 : INFO : ==> SST vocabulary size : 21705
2017-05-03 17:21:39,741 : INFO : LOG_FILE
2017-05-03 17:21:39,741 : INFO : _________________________________start___________________________________
2017-05-03 17:21:39,767 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 17:21:39,895 : INFO : ==> SST vocabulary size : 21705
2017-05-03 17:21:51,803 : INFO : ==> File not found, preparing, be patient
2017-05-03 17:25:37,100 : INFO : ==> GLOVE vocabulary size: 2196016
2017-05-03 17:25:37,795 : INFO : done creating emb, quit
2017-05-03 17:25:37,795 : INFO : quit program due to memory leak during preprocess data, please rerun sentiment.py
2017-05-03 17:27:04,542 : INFO : LOG_FILE
2017-05-03 17:27:04,543 : INFO : _________________________________start___________________________________
2017-05-03 17:27:04,573 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 17:27:04,679 : INFO : ==> SST vocabulary size : 21705
2017-05-03 17:28:38,736 : INFO : LOG_FILE
2017-05-03 17:28:38,737 : INFO : _________________________________start___________________________________
2017-05-03 17:28:38,770 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 17:28:38,974 : INFO : ==> SST vocabulary size : 21705
2017-05-03 17:29:37,370 : INFO : LOG_FILE
2017-05-03 17:29:37,370 : INFO : _________________________________start___________________________________
2017-05-03 17:29:37,397 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 17:29:37,508 : INFO : ==> SST vocabulary size : 21705
2017-05-03 17:30:41,809 : INFO : LOG_FILE
2017-05-03 17:30:41,809 : INFO : _________________________________start___________________________________
2017-05-03 17:30:41,842 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 17:30:41,973 : INFO : ==> SST vocabulary size : 21705
2017-05-03 17:30:54,530 : INFO : ==> File found, loading to memory
2017-05-03 17:30:58,843 : INFO : ==> GLOVE vocabulary size: 2196016
2017-05-03 17:30:59,483 : INFO : done creating emb, quit
2017-05-03 17:30:59,483 : INFO : quit program due to memory leak during preprocess data, please rerun sentiment.py
2017-05-03 17:31:06,476 : INFO : LOG_FILE
2017-05-03 17:31:06,476 : INFO : _________________________________start___________________________________
2017-05-03 17:31:06,503 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 17:31:06,608 : INFO : ==> SST vocabulary size : 21705
2017-05-03 17:31:32,600 : INFO : LOG_FILE
2017-05-03 17:31:32,601 : INFO : _________________________________start___________________________________
2017-05-03 17:31:32,633 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 17:31:32,846 : INFO : ==> SST vocabulary size : 21705
2017-05-03 17:31:40,361 : INFO : LOG_FILE
2017-05-03 17:31:40,362 : INFO : _________________________________start___________________________________
2017-05-03 17:31:40,393 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 17:31:40,594 : INFO : ==> SST vocabulary size : 21705
2017-05-03 17:33:08,709 : INFO : LOG_FILE
2017-05-03 17:33:08,709 : INFO : _________________________________start___________________________________
2017-05-03 17:33:08,738 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 17:33:08,857 : INFO : ==> SST vocabulary size : 21705
2017-05-03 17:33:20,684 : INFO : ==> File found, loading to memory
2017-05-03 17:33:24,604 : INFO : ==> GLOVE vocabulary size: 2196016
2017-05-03 17:33:25,249 : INFO : done creating emb, quit
2017-05-03 17:33:25,249 : INFO : quit program due to memory leak during preprocess data, please rerun sentiment.py
2017-05-03 17:33:28,010 : INFO : LOG_FILE
2017-05-03 17:33:28,011 : INFO : _________________________________start___________________________________
2017-05-03 17:33:28,040 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 17:33:28,158 : INFO : ==> SST vocabulary size : 21705
2017-05-03 17:37:12,687 : INFO : LOG_FILE
2017-05-03 17:37:12,688 : INFO : _________________________________start___________________________________
2017-05-03 17:37:12,719 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 17:37:12,920 : INFO : ==> SST vocabulary size : 21705
2017-05-03 17:37:26,773 : INFO : meow
2017-05-03 17:37:40,669 : INFO : LOG_FILE
2017-05-03 17:37:40,669 : INFO : _________________________________start___________________________________
2017-05-03 17:37:40,705 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 17:37:40,916 : INFO : ==> SST vocabulary size : 21705
2017-05-03 17:37:49,359 : INFO : meow
2017-05-03 17:38:26,603 : INFO : LOG_FILE
2017-05-03 17:38:26,603 : INFO : _________________________________start___________________________________
2017-05-03 17:38:26,633 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 17:38:26,747 : INFO : ==> SST vocabulary size : 21705
2017-05-03 17:38:32,492 : INFO : meow
2017-05-03 17:38:58,697 : INFO : LOG_FILE
2017-05-03 17:38:58,697 : INFO : _________________________________start___________________________________
2017-05-03 17:38:58,730 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 17:38:58,951 : INFO : ==> SST vocabulary size : 21705
2017-05-03 17:40:06,783 : INFO : LOG_FILE
2017-05-03 17:40:06,783 : INFO : _________________________________start___________________________________
2017-05-03 17:40:06,814 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 17:40:06,925 : INFO : ==> SST vocabulary size : 21705
2017-05-03 17:40:18,978 : INFO : ==> File found, loading to memory
2017-05-03 17:40:23,212 : INFO : ==> GLOVE vocabulary size: 2196016
2017-05-03 17:40:23,912 : INFO : done creating emb, quit
2017-05-03 17:40:23,912 : INFO : quit program due to memory leak during preprocess data, please rerun sentiment.py
2017-05-03 17:40:28,647 : INFO : LOG_FILE
2017-05-03 17:40:28,647 : INFO : _________________________________start___________________________________
2017-05-03 17:40:28,674 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 17:40:28,792 : INFO : ==> SST vocabulary size : 21705
2017-05-03 17:40:34,207 : INFO : meow
2017-05-03 17:42:21,758 : INFO : LOG_FILE
2017-05-03 17:42:21,758 : INFO : _________________________________start___________________________________
2017-05-03 17:42:21,793 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 17:42:22,004 : INFO : ==> SST vocabulary size : 21705
2017-05-03 17:42:32,113 : INFO : LOG_FILE
2017-05-03 17:42:32,114 : INFO : _________________________________start___________________________________
2017-05-03 17:42:32,146 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 17:42:32,345 : INFO : ==> SST vocabulary size : 21705
2017-05-03 17:44:57,850 : INFO : LOG_FILE
2017-05-03 17:44:57,851 : INFO : _________________________________start___________________________________
2017-05-03 17:44:57,879 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 17:44:57,988 : INFO : ==> SST vocabulary size : 21705
2017-05-03 17:45:11,457 : INFO : ==> File found, loading to memory
2017-05-03 17:45:15,449 : INFO : ==> GLOVE vocabulary size: 2196016
2017-05-03 17:45:16,089 : INFO : done creating emb, quit
2017-05-03 17:45:16,089 : INFO : quit program due to memory leak during preprocess data, please rerun sentiment.py
2017-05-03 17:45:18,636 : INFO : LOG_FILE
2017-05-03 17:45:18,636 : INFO : _________________________________start___________________________________
2017-05-03 17:45:18,664 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 17:45:18,778 : INFO : ==> SST vocabulary size : 21705
2017-05-03 17:45:24,524 : INFO : meow
2017-05-03 17:45:24,648 : INFO : meow
2017-05-03 17:45:24,745 : INFO : meow
2017-05-03 17:45:24,923 : INFO : meow
2017-05-03 17:45:25,057 : INFO : meow
2017-05-03 17:45:25,332 : INFO : meow
2017-05-03 17:45:25,427 : INFO : meow
2017-05-03 17:45:25,531 : INFO : meow
2017-05-03 17:45:25,746 : INFO : meow
2017-05-03 17:45:25,824 : INFO : meow
2017-05-03 17:45:25,968 : INFO : meow
2017-05-03 17:45:26,066 : INFO : meow
2017-05-03 17:45:26,314 : INFO : meow
2017-05-03 17:45:26,397 : INFO : meow
2017-05-03 17:45:26,468 : INFO : meow
2017-05-03 17:45:26,653 : INFO : meow
2017-05-03 17:45:26,831 : INFO : meow
2017-05-03 17:45:26,908 : INFO : meow
2017-05-03 17:45:26,996 : INFO : meow
2017-05-03 17:45:27,154 : INFO : meow
2017-05-03 17:45:27,237 : INFO : meow
2017-05-03 17:45:27,377 : INFO : meow
2017-05-03 17:45:27,528 : INFO : meow
2017-05-03 17:45:27,607 : INFO : meow
2017-05-03 17:45:27,746 : INFO : meow
2017-05-03 17:45:27,816 : INFO : meow
2017-05-03 17:45:27,900 : INFO : meow
2017-05-03 17:45:28,086 : INFO : meow
2017-05-03 17:45:28,208 : INFO : meow
2017-05-03 17:45:28,372 : INFO : meow
2017-05-03 17:45:28,904 : INFO : meow
2017-05-03 17:45:29,038 : INFO : meow
2017-05-03 17:45:29,260 : INFO : meow
2017-05-03 17:45:29,366 : INFO : meow
2017-05-03 17:45:29,480 : INFO : meow
2017-05-03 17:45:29,663 : INFO : meow
2017-05-03 17:45:29,830 : INFO : meow
2017-05-03 17:45:29,931 : INFO : meow
2017-05-03 17:45:29,992 : INFO : meow
2017-05-03 17:45:30,126 : INFO : meow
2017-05-03 17:45:30,213 : INFO : meow
2017-05-03 17:45:30,367 : INFO : meow
2017-05-03 17:45:30,442 : INFO : meow
2017-05-03 17:45:30,563 : INFO : meow
2017-05-03 17:45:30,657 : INFO : meow
2017-05-03 17:45:30,825 : INFO : meow
2017-05-03 17:45:30,972 : INFO : meow
2017-05-03 17:45:31,083 : INFO : meow
2017-05-03 17:45:31,158 : INFO : meow
2017-05-03 17:45:31,258 : INFO : meow
2017-05-03 17:45:31,340 : INFO : meow
2017-05-03 17:45:31,520 : INFO : meow
2017-05-03 17:45:31,626 : INFO : meow
2017-05-03 17:45:31,811 : INFO : meow
2017-05-03 17:45:31,878 : INFO : meow
2017-05-03 17:45:32,063 : INFO : meow
2017-05-03 17:45:32,217 : INFO : meow
2017-05-03 17:45:32,316 : INFO : meow
2017-05-03 17:45:32,417 : INFO : meow
2017-05-03 17:45:32,507 : INFO : meow
2017-05-03 17:45:32,649 : INFO : meow
2017-05-03 17:45:32,793 : INFO : meow
2017-05-03 17:45:32,984 : INFO : meow
2017-05-03 17:45:33,095 : INFO : meow
2017-05-03 17:45:33,314 : INFO : meow
2017-05-03 17:45:33,433 : INFO : meow
2017-05-03 17:45:33,514 : INFO : meow
2017-05-03 17:45:33,599 : INFO : meow
2017-05-03 17:45:33,783 : INFO : meow
2017-05-03 17:45:33,947 : INFO : meow
2017-05-03 17:45:34,026 : INFO : meow
2017-05-03 17:45:34,124 : INFO : meow
2017-05-03 17:45:34,217 : INFO : meow
2017-05-03 17:45:34,331 : INFO : meow
2017-05-03 17:45:34,492 : INFO : meow
2017-05-03 17:45:34,582 : INFO : meow
2017-05-03 17:45:34,648 : INFO : meow
2017-05-03 17:45:34,828 : INFO : meow
2017-05-03 17:45:34,892 : INFO : meow
2017-05-03 17:45:35,083 : INFO : meow
2017-05-03 17:45:35,182 : INFO : meow
2017-05-03 17:45:35,303 : INFO : meow
2017-05-03 17:45:35,386 : INFO : meow
2017-05-03 17:45:35,502 : INFO : meow
2017-05-03 17:45:35,595 : INFO : meow
2017-05-03 17:45:35,696 : INFO : meow
2017-05-03 17:45:35,859 : INFO : meow
2017-05-03 17:45:35,919 : INFO : meow
2017-05-03 17:45:36,017 : INFO : meow
2017-05-03 17:45:36,091 : INFO : meow
2017-05-03 17:45:36,265 : INFO : meow
2017-05-03 17:45:36,375 : INFO : meow
2017-05-03 17:45:36,494 : INFO : meow
2017-05-03 17:45:36,611 : INFO : meow
2017-05-03 17:45:36,684 : INFO : meow
2017-05-03 17:45:37,006 : INFO : meow
2017-05-03 17:45:37,143 : INFO : meow
2017-05-03 17:45:37,230 : INFO : meow
2017-05-03 17:45:37,370 : INFO : meow
2017-05-03 17:45:37,452 : INFO : meow
2017-05-03 17:45:37,619 : INFO : meow
2017-05-03 17:45:37,695 : INFO : meow
2017-05-03 17:45:37,839 : INFO : meow
2017-05-03 17:45:41,277 : INFO : LOG_FILE
2017-05-03 17:45:41,277 : INFO : _________________________________start___________________________________
2017-05-03 17:45:41,307 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 17:45:41,413 : INFO : ==> SST vocabulary size : 21705
2017-05-03 17:45:47,349 : INFO : meow
2017-05-03 17:45:47,485 : INFO : meow
2017-05-03 17:45:47,584 : INFO : meow
2017-05-03 17:45:47,778 : INFO : meow
2017-05-03 17:45:47,894 : INFO : meow
2017-05-03 17:45:48,165 : INFO : meow
2017-05-03 17:45:48,265 : INFO : meow
2017-05-03 17:45:48,349 : INFO : meow
2017-05-03 17:45:48,551 : INFO : meow
2017-05-03 17:45:48,631 : INFO : meow
2017-05-03 17:45:48,798 : INFO : meow
2017-05-03 17:45:48,901 : INFO : meow
2017-05-03 17:45:49,147 : INFO : meow
2017-05-03 17:45:49,230 : INFO : meow
2017-05-03 17:45:49,307 : INFO : meow
2017-05-03 17:45:49,488 : INFO : meow
2017-05-03 17:45:49,680 : INFO : meow
2017-05-03 17:45:49,754 : INFO : meow
2017-05-03 17:45:49,833 : INFO : meow
2017-05-03 17:45:49,981 : INFO : meow
2017-05-03 17:45:50,069 : INFO : meow
2017-05-03 17:45:50,208 : INFO : meow
2017-05-03 17:45:50,359 : INFO : meow
2017-05-03 17:45:50,429 : INFO : meow
2017-05-03 17:45:50,576 : INFO : meow
2017-05-03 17:45:50,644 : INFO : meow
2017-05-03 17:45:50,727 : INFO : meow
2017-05-03 17:45:50,917 : INFO : meow
2017-05-03 17:45:51,041 : INFO : meow
2017-05-03 17:45:51,179 : INFO : meow
2017-05-03 17:45:51,683 : INFO : meow
2017-05-03 17:45:51,812 : INFO : meow
2017-05-03 17:45:52,062 : INFO : meow
2017-05-03 17:46:06,651 : INFO : LOG_FILE
2017-05-03 17:46:06,651 : INFO : _________________________________start___________________________________
2017-05-03 17:46:06,680 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 17:46:06,793 : INFO : ==> SST vocabulary size : 21705
2017-05-03 17:46:12,687 : INFO : meow
2017-05-03 17:46:12,827 : INFO : meow
2017-05-03 17:46:12,922 : INFO : meow
2017-05-03 17:46:13,097 : INFO : meow
2017-05-03 17:46:13,209 : INFO : meow
2017-05-03 17:46:13,463 : INFO : meow
2017-05-03 17:46:13,570 : INFO : meow
2017-05-03 17:46:13,654 : INFO : meow
2017-05-03 17:46:13,869 : INFO : meow
2017-05-03 17:46:13,960 : INFO : meow
2017-05-03 17:46:14,148 : INFO : meow
2017-05-03 17:46:14,240 : INFO : meow
2017-05-03 17:46:19,641 : INFO : LOG_FILE
2017-05-03 17:46:19,641 : INFO : _________________________________start___________________________________
2017-05-03 17:46:19,670 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 17:46:19,780 : INFO : ==> SST vocabulary size : 21705
2017-05-03 17:46:32,554 : INFO : ==> File found, loading to memory
2017-05-03 17:46:36,449 : INFO : ==> GLOVE vocabulary size: 2196016
2017-05-03 17:46:37,086 : INFO : done creating emb, quit
2017-05-03 17:46:37,086 : INFO : quit program due to memory leak during preprocess data, please rerun sentiment.py
2017-05-03 17:46:40,010 : INFO : LOG_FILE
2017-05-03 17:46:40,010 : INFO : _________________________________start___________________________________
2017-05-03 17:46:40,038 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 17:46:40,152 : INFO : ==> SST vocabulary size : 21705
2017-05-03 17:46:45,983 : INFO : meow
2017-05-03 17:46:46,119 : INFO : meow
2017-05-03 17:46:46,214 : INFO : meow
2017-05-03 17:46:46,413 : INFO : meow
2017-05-03 17:46:46,522 : INFO : meow
2017-05-03 17:46:46,795 : INFO : meow
2017-05-03 17:46:46,907 : INFO : meow
2017-05-03 17:46:46,991 : INFO : meow
2017-05-03 17:46:47,209 : INFO : meow
2017-05-03 17:46:47,301 : INFO : meow
2017-05-03 17:46:47,455 : INFO : meow
2017-05-03 17:46:47,547 : INFO : meow
2017-05-03 17:46:47,827 : INFO : meow
2017-05-03 17:46:47,922 : INFO : meow
2017-05-03 17:46:47,995 : INFO : meow
2017-05-03 17:46:48,190 : INFO : meow
2017-05-03 17:46:48,372 : INFO : meow
2017-05-03 17:46:48,450 : INFO : meow
2017-05-03 17:46:48,528 : INFO : meow
2017-05-03 17:46:48,691 : INFO : meow
2017-05-03 17:46:48,773 : INFO : meow
2017-05-03 17:46:48,925 : INFO : meow
2017-05-03 17:46:49,093 : INFO : meow
2017-05-03 17:46:49,164 : INFO : meow
2017-05-03 17:46:49,318 : INFO : meow
2017-05-03 17:46:49,389 : INFO : meow
2017-05-03 17:46:49,471 : INFO : meow
2017-05-03 17:46:49,653 : INFO : meow
2017-05-03 17:46:49,771 : INFO : meow
2017-05-03 17:46:49,909 : INFO : meow
2017-05-03 17:46:50,401 : INFO : meow
2017-05-03 17:46:50,526 : INFO : meow
2017-05-03 17:46:50,742 : INFO : meow
2017-05-03 17:46:50,846 : INFO : meow
2017-05-03 17:47:43,037 : INFO : LOG_FILE
2017-05-03 17:47:43,037 : INFO : _________________________________start___________________________________
2017-05-03 17:47:43,069 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 17:47:43,178 : INFO : ==> SST vocabulary size : 21705
2017-05-03 17:47:49,202 : INFO : meow
2017-05-03 17:47:49,343 : INFO : meow
2017-05-03 17:47:49,444 : INFO : meow
2017-05-03 17:47:49,641 : INFO : meow
2017-05-03 17:47:49,756 : INFO : meow
2017-05-03 17:47:50,060 : INFO : meow
2017-05-03 17:47:50,160 : INFO : meow
2017-05-03 17:47:50,250 : INFO : meow
2017-05-03 17:47:50,447 : INFO : meow
2017-05-03 17:47:50,531 : INFO : meow
2017-05-03 17:47:50,682 : INFO : meow
2017-05-03 17:47:50,779 : INFO : meow
2017-05-03 17:47:51,060 : INFO : meow
2017-05-03 17:47:51,169 : INFO : meow
2017-05-03 17:47:51,240 : INFO : meow
2017-05-03 17:47:51,437 : INFO : meow
2017-05-03 17:47:51,645 : INFO : meow
2017-05-03 17:47:51,727 : INFO : meow
2017-05-03 17:54:03,987 : INFO : LOG_FILE
2017-05-03 17:54:03,987 : INFO : _________________________________start___________________________________
2017-05-03 17:54:04,016 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 17:54:04,133 : INFO : ==> SST vocabulary size : 21705
2017-05-03 17:54:40,207 : INFO : LOG_FILE
2017-05-03 17:54:40,207 : INFO : _________________________________start___________________________________
2017-05-03 17:54:40,239 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 17:54:40,348 : INFO : ==> SST vocabulary size : 21705
2017-05-03 17:54:47,273 : INFO : ==> File found, loading to memory
2017-05-03 17:54:51,171 : INFO : ==> GLOVE vocabulary size: 2196016
2017-05-03 17:54:51,808 : INFO : done creating emb, quit
2017-05-03 17:54:51,808 : INFO : quit program due to memory leak during preprocess data, please rerun sentiment.py
2017-05-03 17:54:54,199 : INFO : LOG_FILE
2017-05-03 17:54:54,200 : INFO : _________________________________start___________________________________
2017-05-03 17:54:54,229 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 17:54:54,341 : INFO : ==> SST vocabulary size : 21705
2017-05-03 17:55:40,126 : INFO : LOG_FILE
2017-05-03 17:55:40,126 : INFO : _________________________________start___________________________________
2017-05-03 17:55:40,154 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 17:55:40,260 : INFO : ==> SST vocabulary size : 21705
2017-05-03 17:55:48,892 : INFO : LOG_FILE
2017-05-03 17:55:48,893 : INFO : _________________________________start___________________________________
2017-05-03 17:55:48,925 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 17:55:49,234 : INFO : ==> SST vocabulary size : 21705
2017-05-03 17:57:18,151 : INFO : LOG_FILE
2017-05-03 17:57:18,151 : INFO : _________________________________start___________________________________
2017-05-03 17:57:18,180 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 17:57:18,289 : INFO : ==> SST vocabulary size : 21705
2017-05-03 17:57:30,147 : INFO : ==> File found, loading to memory
2017-05-03 17:57:34,051 : INFO : ==> GLOVE vocabulary size: 2196016
2017-05-03 17:57:34,684 : INFO : done creating emb, quit
2017-05-03 17:57:34,684 : INFO : quit program due to memory leak during preprocess data, please rerun sentiment.py
2017-05-03 17:57:41,606 : INFO : LOG_FILE
2017-05-03 17:57:41,606 : INFO : _________________________________start___________________________________
2017-05-03 17:57:41,633 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 17:57:41,740 : INFO : ==> SST vocabulary size : 21705
2017-05-03 17:59:59,549 : INFO : LOG_FILE
2017-05-03 17:59:59,549 : INFO : _________________________________start___________________________________
2017-05-03 17:59:59,580 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 17:59:59,686 : INFO : ==> SST vocabulary size : 21705
2017-05-03 18:02:46,390 : INFO : LOG_FILE
2017-05-03 18:02:46,390 : INFO : _________________________________start___________________________________
2017-05-03 18:02:46,421 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 18:02:46,532 : INFO : ==> SST vocabulary size : 21705
2017-05-03 18:15:12,871 : INFO : ==> Train loss   : 0.702669
2017-05-03 18:15:12,872 : INFO : Epoch
2017-05-03 18:15:12,872 : INFO : 0
2017-05-03 18:15:12,872 : INFO : dev percentage
2017-05-03 18:15:12,872 : INFO : 0.774082568807
2017-05-03 18:15:12,873 : INFO : Epoch
2017-05-03 18:15:12,873 : INFO : 0
2017-05-03 18:15:12,873 : INFO : test percentage
2017-05-03 18:15:12,873 : INFO : 0.799560680945
2017-05-03 18:16:45,935 : INFO : LOG_FILE
2017-05-03 18:16:45,936 : INFO : _________________________________start___________________________________
2017-05-03 18:16:45,962 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 18:16:46,071 : INFO : ==> SST vocabulary size : 21705
2017-05-03 18:19:50,011 : INFO : ==> Train loss   : 2.289395
2017-05-03 18:19:50,012 : INFO : Epoch
2017-05-03 18:19:50,012 : INFO : 0
2017-05-03 18:19:50,012 : INFO : dev percentage
2017-05-03 18:19:50,012 : INFO : 0.934633027523
2017-05-03 18:19:50,012 : INFO : Epoch
2017-05-03 18:19:50,012 : INFO : 0
2017-05-03 18:19:50,013 : INFO : test percentage
2017-05-03 18:19:50,013 : INFO : 0.699066447007
2017-05-03 18:22:43,415 : INFO : ==> Train loss   : 0.188368
2017-05-03 18:22:43,415 : INFO : Epoch
2017-05-03 18:22:43,415 : INFO : 1
2017-05-03 18:22:43,415 : INFO : dev percentage
2017-05-03 18:22:43,416 : INFO : 0.994266055046
2017-05-03 18:22:43,416 : INFO : Epoch
2017-05-03 18:22:43,416 : INFO : 1
2017-05-03 18:22:43,416 : INFO : test percentage
2017-05-03 18:22:43,416 : INFO : 0.709500274574
2017-05-03 18:25:46,856 : INFO : LOG_FILE
2017-05-03 18:25:46,856 : INFO : _________________________________start___________________________________
2017-05-03 18:25:46,891 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 18:25:47,187 : INFO : ==> SST vocabulary size : 21705
2017-05-03 18:26:46,204 : INFO : LOG_FILE
2017-05-03 18:26:46,204 : INFO : _________________________________start___________________________________
2017-05-03 18:26:46,233 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 18:26:46,337 : INFO : ==> SST vocabulary size : 21705
2017-05-03 18:38:36,701 : INFO : ==> Train loss   : 0.702669
2017-05-03 18:38:36,701 : INFO : Epoch
2017-05-03 18:38:36,701 : INFO : 0
2017-05-03 18:38:36,701 : INFO : dev percentage
2017-05-03 18:38:36,701 : INFO : 0.774082568807
2017-05-03 18:38:36,701 : INFO : Epoch
2017-05-03 18:38:36,702 : INFO : 0
2017-05-03 18:38:36,702 : INFO : test percentage
2017-05-03 18:38:36,702 : INFO : 0.799560680945
2017-05-03 18:50:21,300 : INFO : ==> Train loss   : 0.147812
2017-05-03 18:50:21,300 : INFO : Epoch
2017-05-03 18:50:21,300 : INFO : 1
2017-05-03 18:50:21,300 : INFO : dev percentage
2017-05-03 18:50:21,300 : INFO : 0.770642201835
2017-05-03 18:50:21,301 : INFO : Epoch
2017-05-03 18:50:21,301 : INFO : 1
2017-05-03 18:50:21,301 : INFO : test percentage
2017-05-03 18:50:21,301 : INFO : 0.796265788029
2017-05-03 19:01:58,037 : INFO : ==> Train loss   : 0.037012
2017-05-03 19:01:58,037 : INFO : Epoch
2017-05-03 19:01:58,037 : INFO : 2
2017-05-03 19:01:58,037 : INFO : dev percentage
2017-05-03 19:01:58,038 : INFO : 0.76376146789
2017-05-03 19:01:58,038 : INFO : Epoch
2017-05-03 19:01:58,038 : INFO : 2
2017-05-03 19:01:58,038 : INFO : test percentage
2017-05-03 19:01:58,038 : INFO : 0.81164195497
2017-05-03 19:03:17,379 : INFO : LOG_FILE
2017-05-03 19:03:17,380 : INFO : _________________________________start___________________________________
2017-05-03 19:03:17,413 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 19:03:17,711 : INFO : ==> SST vocabulary size : 21705
2017-05-03 19:10:26,754 : INFO : LOG_FILE
2017-05-03 19:10:26,754 : INFO : _________________________________start___________________________________
2017-05-03 19:10:26,783 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 19:10:26,894 : INFO : ==> SST vocabulary size : 21705
2017-05-03 19:10:31,813 : INFO : _param count_
2017-05-03 19:10:31,813 : INFO : torch.Size([21705, 300])
2017-05-03 19:10:31,813 : INFO : torch.Size([168, 300])
2017-05-03 19:10:31,813 : INFO : torch.Size([168])
2017-05-03 19:10:31,814 : INFO : torch.Size([168, 168])
2017-05-03 19:10:31,814 : INFO : torch.Size([168])
2017-05-03 19:10:31,814 : INFO : torch.Size([168, 300])
2017-05-03 19:10:31,814 : INFO : torch.Size([168])
2017-05-03 19:10:31,814 : INFO : torch.Size([168, 168])
2017-05-03 19:10:31,814 : INFO : torch.Size([168])
2017-05-03 19:10:31,814 : INFO : torch.Size([168, 300])
2017-05-03 19:10:31,815 : INFO : torch.Size([168])
2017-05-03 19:10:31,815 : INFO : torch.Size([168, 168])
2017-05-03 19:10:31,815 : INFO : torch.Size([168])
2017-05-03 19:10:31,815 : INFO : torch.Size([168, 300])
2017-05-03 19:10:31,815 : INFO : torch.Size([168])
2017-05-03 19:10:31,815 : INFO : torch.Size([168, 168])
2017-05-03 19:10:31,815 : INFO : torch.Size([168])
2017-05-03 19:10:31,816 : INFO : torch.Size([3, 168])
2017-05-03 19:10:31,816 : INFO : torch.Size([3])
2017-05-03 19:10:31,816 : INFO : ____________
2017-05-03 19:13:49,200 : INFO : LOG_FILE
2017-05-03 19:13:49,200 : INFO : _________________________________start___________________________________
2017-05-03 19:13:49,228 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 19:13:49,341 : INFO : ==> SST vocabulary size : 21705
2017-05-03 19:13:54,260 : INFO : _param count_
2017-05-03 19:13:54,260 : INFO : torch.Size([21705, 300])
2017-05-03 19:13:54,261 : INFO : torch.Size([168, 300])
2017-05-03 19:13:54,261 : INFO : torch.Size([168])
2017-05-03 19:13:54,261 : INFO : torch.Size([168, 168])
2017-05-03 19:13:54,261 : INFO : torch.Size([168])
2017-05-03 19:13:54,261 : INFO : torch.Size([168, 300])
2017-05-03 19:13:54,261 : INFO : torch.Size([168])
2017-05-03 19:13:54,261 : INFO : torch.Size([168, 168])
2017-05-03 19:13:54,262 : INFO : torch.Size([168])
2017-05-03 19:13:54,262 : INFO : torch.Size([168, 300])
2017-05-03 19:13:54,262 : INFO : torch.Size([168])
2017-05-03 19:13:54,262 : INFO : torch.Size([168, 168])
2017-05-03 19:13:54,262 : INFO : torch.Size([168])
2017-05-03 19:13:54,262 : INFO : torch.Size([168, 300])
2017-05-03 19:13:54,262 : INFO : torch.Size([168])
2017-05-03 19:13:54,262 : INFO : torch.Size([168, 168])
2017-05-03 19:13:54,263 : INFO : torch.Size([168])
2017-05-03 19:13:54,263 : INFO : torch.Size([3, 168])
2017-05-03 19:13:54,263 : INFO : torch.Size([3])
2017-05-03 19:13:54,263 : INFO : sum
2017-05-03 19:13:54,263 : INFO : 6827847
2017-05-03 19:13:54,263 : INFO : ____________
2017-05-03 19:14:41,193 : INFO : LOG_FILE
2017-05-03 19:14:41,193 : INFO : _________________________________start___________________________________
2017-05-03 19:14:41,222 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 19:14:41,330 : INFO : ==> SST vocabulary size : 21705
2017-05-03 19:14:46,256 : INFO : _param count_
2017-05-03 19:14:46,256 : INFO : torch.Size([21705, 300])
2017-05-03 19:14:46,256 : INFO : torch.Size([168, 300])
2017-05-03 19:14:46,256 : INFO : torch.Size([168])
2017-05-03 19:14:46,256 : INFO : torch.Size([168, 168])
2017-05-03 19:14:46,257 : INFO : torch.Size([168])
2017-05-03 19:14:46,257 : INFO : torch.Size([168, 300])
2017-05-03 19:14:46,257 : INFO : torch.Size([168])
2017-05-03 19:14:46,257 : INFO : torch.Size([168, 168])
2017-05-03 19:14:46,257 : INFO : torch.Size([168])
2017-05-03 19:14:46,257 : INFO : torch.Size([168, 300])
2017-05-03 19:14:46,257 : INFO : torch.Size([168])
2017-05-03 19:14:46,258 : INFO : torch.Size([168, 168])
2017-05-03 19:14:46,258 : INFO : torch.Size([168])
2017-05-03 19:14:46,258 : INFO : torch.Size([168, 300])
2017-05-03 19:14:46,258 : INFO : torch.Size([168])
2017-05-03 19:14:46,258 : INFO : torch.Size([168, 168])
2017-05-03 19:14:46,258 : INFO : torch.Size([168])
2017-05-03 19:14:46,258 : INFO : torch.Size([3, 168])
2017-05-03 19:14:46,259 : INFO : torch.Size([3])
2017-05-03 19:14:46,259 : INFO : sum
2017-05-03 19:14:46,259 : INFO : 316347
2017-05-03 19:14:46,259 : INFO : ____________
2017-05-03 19:17:37,079 : INFO : LOG_FILE
2017-05-03 19:17:37,079 : INFO : _________________________________start___________________________________
2017-05-03 19:17:37,109 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 19:17:37,214 : INFO : ==> SST vocabulary size : 21705
2017-05-03 19:17:42,119 : INFO : _param count_
2017-05-03 19:17:42,119 : INFO : torch.Size([21705, 300])
2017-05-03 19:17:42,120 : INFO : torch.Size([168, 300])
2017-05-03 19:17:42,120 : INFO : torch.Size([168])
2017-05-03 19:17:42,120 : INFO : torch.Size([168, 168])
2017-05-03 19:17:42,120 : INFO : torch.Size([168])
2017-05-03 19:17:42,120 : INFO : torch.Size([168, 300])
2017-05-03 19:17:42,121 : INFO : torch.Size([168])
2017-05-03 19:17:42,121 : INFO : torch.Size([168, 168])
2017-05-03 19:17:42,121 : INFO : torch.Size([168])
2017-05-03 19:17:42,121 : INFO : torch.Size([168, 300])
2017-05-03 19:17:42,121 : INFO : torch.Size([168])
2017-05-03 19:17:42,121 : INFO : torch.Size([168, 168])
2017-05-03 19:17:42,121 : INFO : torch.Size([168])
2017-05-03 19:17:42,122 : INFO : torch.Size([168, 300])
2017-05-03 19:17:42,122 : INFO : torch.Size([168])
2017-05-03 19:17:42,122 : INFO : torch.Size([168, 168])
2017-05-03 19:17:42,122 : INFO : torch.Size([168])
2017-05-03 19:17:42,122 : INFO : torch.Size([3, 168])
2017-05-03 19:17:42,122 : INFO : torch.Size([3])
2017-05-03 19:17:42,122 : INFO : sum
2017-05-03 19:17:42,122 : INFO : 316347
2017-05-03 19:17:42,123 : INFO : ____________
2017-05-03 19:17:42,325 : INFO : _param count_
2017-05-03 19:17:42,325 : INFO : torch.Size([21705, 300])
2017-05-03 19:17:42,326 : INFO : torch.Size([168, 300])
2017-05-03 19:17:42,326 : INFO : torch.Size([168])
2017-05-03 19:17:42,326 : INFO : torch.Size([168, 168])
2017-05-03 19:17:42,326 : INFO : torch.Size([168])
2017-05-03 19:17:42,326 : INFO : torch.Size([168, 300])
2017-05-03 19:17:42,326 : INFO : torch.Size([168])
2017-05-03 19:17:42,326 : INFO : torch.Size([168, 168])
2017-05-03 19:17:42,326 : INFO : torch.Size([168])
2017-05-03 19:17:42,327 : INFO : torch.Size([168, 300])
2017-05-03 19:17:42,327 : INFO : torch.Size([168])
2017-05-03 19:17:42,327 : INFO : torch.Size([168, 168])
2017-05-03 19:17:42,327 : INFO : torch.Size([168])
2017-05-03 19:17:42,327 : INFO : torch.Size([168, 300])
2017-05-03 19:17:42,327 : INFO : torch.Size([168])
2017-05-03 19:17:42,327 : INFO : torch.Size([168, 168])
2017-05-03 19:17:42,328 : INFO : torch.Size([168])
2017-05-03 19:17:42,328 : INFO : torch.Size([3, 168])
2017-05-03 19:17:42,328 : INFO : torch.Size([3])
2017-05-03 19:17:42,328 : INFO : sum
2017-05-03 19:17:42,328 : INFO : 316347
2017-05-03 19:17:42,328 : INFO : ____________
2017-05-03 19:17:42,385 : INFO : _param count_
2017-05-03 19:17:42,385 : INFO : torch.Size([21705, 300])
2017-05-03 19:17:42,386 : INFO : torch.Size([168, 300])
2017-05-03 19:17:42,386 : INFO : torch.Size([168])
2017-05-03 19:17:42,386 : INFO : torch.Size([168, 168])
2017-05-03 19:17:42,386 : INFO : torch.Size([168])
2017-05-03 19:17:42,386 : INFO : torch.Size([168, 300])
2017-05-03 19:17:42,386 : INFO : torch.Size([168])
2017-05-03 19:17:42,386 : INFO : torch.Size([168, 168])
2017-05-03 19:17:42,387 : INFO : torch.Size([168])
2017-05-03 19:17:42,387 : INFO : torch.Size([168, 300])
2017-05-03 19:17:42,387 : INFO : torch.Size([168])
2017-05-03 19:17:42,387 : INFO : torch.Size([168, 168])
2017-05-03 19:17:42,387 : INFO : torch.Size([168])
2017-05-03 19:17:42,387 : INFO : torch.Size([168, 300])
2017-05-03 19:17:42,388 : INFO : torch.Size([168])
2017-05-03 19:17:42,388 : INFO : torch.Size([168, 168])
2017-05-03 19:17:42,388 : INFO : torch.Size([168])
2017-05-03 19:17:42,388 : INFO : torch.Size([3, 168])
2017-05-03 19:17:42,388 : INFO : torch.Size([3])
2017-05-03 19:17:42,388 : INFO : sum
2017-05-03 19:17:42,389 : INFO : 316347
2017-05-03 19:17:42,389 : INFO : ____________
2017-05-03 19:17:42,485 : INFO : _param count_
2017-05-03 19:17:42,486 : INFO : torch.Size([21705, 300])
2017-05-03 19:17:42,486 : INFO : torch.Size([168, 300])
2017-05-03 19:17:42,486 : INFO : torch.Size([168])
2017-05-03 19:17:42,486 : INFO : torch.Size([168, 168])
2017-05-03 19:17:42,486 : INFO : torch.Size([168])
2017-05-03 19:17:42,486 : INFO : torch.Size([168, 300])
2017-05-03 19:17:42,487 : INFO : torch.Size([168])
2017-05-03 19:17:42,487 : INFO : torch.Size([168, 168])
2017-05-03 19:17:42,487 : INFO : torch.Size([168])
2017-05-03 19:17:42,487 : INFO : torch.Size([168, 300])
2017-05-03 19:17:42,487 : INFO : torch.Size([168])
2017-05-03 19:17:42,487 : INFO : torch.Size([168, 168])
2017-05-03 19:17:42,487 : INFO : torch.Size([168])
2017-05-03 19:17:42,488 : INFO : torch.Size([168, 300])
2017-05-03 19:17:42,488 : INFO : torch.Size([168])
2017-05-03 19:17:42,488 : INFO : torch.Size([168, 168])
2017-05-03 19:17:42,488 : INFO : torch.Size([168])
2017-05-03 19:17:42,488 : INFO : torch.Size([3, 168])
2017-05-03 19:17:42,488 : INFO : torch.Size([3])
2017-05-03 19:17:42,488 : INFO : sum
2017-05-03 19:17:42,489 : INFO : 316347
2017-05-03 19:17:42,489 : INFO : ____________
2017-05-03 19:17:42,568 : INFO : _param count_
2017-05-03 19:17:42,569 : INFO : torch.Size([21705, 300])
2017-05-03 19:17:42,569 : INFO : torch.Size([168, 300])
2017-05-03 19:17:42,569 : INFO : torch.Size([168])
2017-05-03 19:17:42,569 : INFO : torch.Size([168, 168])
2017-05-03 19:17:42,569 : INFO : torch.Size([168])
2017-05-03 19:17:42,569 : INFO : torch.Size([168, 300])
2017-05-03 19:17:42,570 : INFO : torch.Size([168])
2017-05-03 19:17:42,570 : INFO : torch.Size([168, 168])
2017-05-03 19:17:42,570 : INFO : torch.Size([168])
2017-05-03 19:17:42,570 : INFO : torch.Size([168, 300])
2017-05-03 19:17:42,570 : INFO : torch.Size([168])
2017-05-03 19:17:42,570 : INFO : torch.Size([168, 168])
2017-05-03 19:17:42,571 : INFO : torch.Size([168])
2017-05-03 19:17:42,571 : INFO : torch.Size([168, 300])
2017-05-03 19:17:42,571 : INFO : torch.Size([168])
2017-05-03 19:17:42,571 : INFO : torch.Size([168, 168])
2017-05-03 19:17:42,571 : INFO : torch.Size([168])
2017-05-03 19:17:42,571 : INFO : torch.Size([3, 168])
2017-05-03 19:17:42,571 : INFO : torch.Size([3])
2017-05-03 19:17:42,572 : INFO : sum
2017-05-03 19:17:42,572 : INFO : 316347
2017-05-03 19:17:42,572 : INFO : ____________
2017-05-03 19:17:42,619 : INFO : _param count_
2017-05-03 19:17:42,619 : INFO : torch.Size([21705, 300])
2017-05-03 19:17:42,619 : INFO : torch.Size([168, 300])
2017-05-03 19:17:42,619 : INFO : torch.Size([168])
2017-05-03 19:17:42,620 : INFO : torch.Size([168, 168])
2017-05-03 19:17:42,620 : INFO : torch.Size([168])
2017-05-03 19:17:42,620 : INFO : torch.Size([168, 300])
2017-05-03 19:17:42,620 : INFO : torch.Size([168])
2017-05-03 19:17:42,620 : INFO : torch.Size([168, 168])
2017-05-03 19:17:42,620 : INFO : torch.Size([168])
2017-05-03 19:17:42,620 : INFO : torch.Size([168, 300])
2017-05-03 19:17:42,620 : INFO : torch.Size([168])
2017-05-03 19:17:42,621 : INFO : torch.Size([168, 168])
2017-05-03 19:17:42,621 : INFO : torch.Size([168])
2017-05-03 19:17:42,621 : INFO : torch.Size([168, 300])
2017-05-03 19:17:42,621 : INFO : torch.Size([168])
2017-05-03 19:17:42,621 : INFO : torch.Size([168, 168])
2017-05-03 19:17:42,621 : INFO : torch.Size([168])
2017-05-03 19:17:42,621 : INFO : torch.Size([3, 168])
2017-05-03 19:17:42,622 : INFO : torch.Size([3])
2017-05-03 19:17:42,622 : INFO : sum
2017-05-03 19:17:42,622 : INFO : 316347
2017-05-03 19:17:42,622 : INFO : ____________
2017-05-03 19:17:42,674 : INFO : _param count_
2017-05-03 19:17:42,674 : INFO : torch.Size([21705, 300])
2017-05-03 19:17:42,675 : INFO : torch.Size([168, 300])
2017-05-03 19:17:42,675 : INFO : torch.Size([168])
2017-05-03 19:17:42,675 : INFO : torch.Size([168, 168])
2017-05-03 19:17:42,675 : INFO : torch.Size([168])
2017-05-03 19:17:42,675 : INFO : torch.Size([168, 300])
2017-05-03 19:17:42,675 : INFO : torch.Size([168])
2017-05-03 19:17:42,675 : INFO : torch.Size([168, 168])
2017-05-03 19:17:42,675 : INFO : torch.Size([168])
2017-05-03 19:17:42,676 : INFO : torch.Size([168, 300])
2017-05-03 19:17:42,676 : INFO : torch.Size([168])
2017-05-03 19:17:42,676 : INFO : torch.Size([168, 168])
2017-05-03 19:17:42,676 : INFO : torch.Size([168])
2017-05-03 19:17:42,676 : INFO : torch.Size([168, 300])
2017-05-03 19:17:42,676 : INFO : torch.Size([168])
2017-05-03 19:17:42,676 : INFO : torch.Size([168, 168])
2017-05-03 19:17:42,677 : INFO : torch.Size([168])
2017-05-03 19:17:42,677 : INFO : torch.Size([3, 168])
2017-05-03 19:17:42,677 : INFO : torch.Size([3])
2017-05-03 19:17:42,677 : INFO : sum
2017-05-03 19:17:42,677 : INFO : 316347
2017-05-03 19:17:42,677 : INFO : ____________
2017-05-03 19:17:42,752 : INFO : _param count_
2017-05-03 19:17:42,752 : INFO : torch.Size([21705, 300])
2017-05-03 19:17:42,752 : INFO : torch.Size([168, 300])
2017-05-03 19:17:42,752 : INFO : torch.Size([168])
2017-05-03 19:17:42,752 : INFO : torch.Size([168, 168])
2017-05-03 19:17:42,752 : INFO : torch.Size([168])
2017-05-03 19:17:42,753 : INFO : torch.Size([168, 300])
2017-05-03 19:17:42,753 : INFO : torch.Size([168])
2017-05-03 19:17:42,753 : INFO : torch.Size([168, 168])
2017-05-03 19:17:42,753 : INFO : torch.Size([168])
2017-05-03 19:17:42,753 : INFO : torch.Size([168, 300])
2017-05-03 19:17:42,753 : INFO : torch.Size([168])
2017-05-03 19:17:42,753 : INFO : torch.Size([168, 168])
2017-05-03 19:17:42,754 : INFO : torch.Size([168])
2017-05-03 19:17:42,754 : INFO : torch.Size([168, 300])
2017-05-03 19:17:42,754 : INFO : torch.Size([168])
2017-05-03 19:17:42,754 : INFO : torch.Size([168, 168])
2017-05-03 19:17:42,754 : INFO : torch.Size([168])
2017-05-03 19:17:42,754 : INFO : torch.Size([3, 168])
2017-05-03 19:17:42,754 : INFO : torch.Size([3])
2017-05-03 19:17:42,754 : INFO : sum
2017-05-03 19:17:42,755 : INFO : 316347
2017-05-03 19:17:42,755 : INFO : ____________
2017-05-03 19:17:42,809 : INFO : _param count_
2017-05-03 19:17:42,809 : INFO : torch.Size([21705, 300])
2017-05-03 19:17:42,809 : INFO : torch.Size([168, 300])
2017-05-03 19:17:42,810 : INFO : torch.Size([168])
2017-05-03 19:17:42,810 : INFO : torch.Size([168, 168])
2017-05-03 19:17:42,810 : INFO : torch.Size([168])
2017-05-03 19:17:42,810 : INFO : torch.Size([168, 300])
2017-05-03 19:17:42,810 : INFO : torch.Size([168])
2017-05-03 19:17:42,810 : INFO : torch.Size([168, 168])
2017-05-03 19:17:42,810 : INFO : torch.Size([168])
2017-05-03 19:17:42,811 : INFO : torch.Size([168, 300])
2017-05-03 19:17:42,811 : INFO : torch.Size([168])
2017-05-03 19:17:42,811 : INFO : torch.Size([168, 168])
2017-05-03 19:17:42,811 : INFO : torch.Size([168])
2017-05-03 19:17:42,811 : INFO : torch.Size([168, 300])
2017-05-03 19:17:42,811 : INFO : torch.Size([168])
2017-05-03 19:17:42,811 : INFO : torch.Size([168, 168])
2017-05-03 19:17:42,811 : INFO : torch.Size([168])
2017-05-03 19:17:42,812 : INFO : torch.Size([3, 168])
2017-05-03 19:17:42,812 : INFO : torch.Size([3])
2017-05-03 19:17:42,812 : INFO : sum
2017-05-03 19:17:42,812 : INFO : 316347
2017-05-03 19:17:42,812 : INFO : ____________
2017-05-03 19:17:42,875 : INFO : _param count_
2017-05-03 19:17:42,875 : INFO : torch.Size([21705, 300])
2017-05-03 19:17:42,875 : INFO : torch.Size([168, 300])
2017-05-03 19:17:42,875 : INFO : torch.Size([168])
2017-05-03 19:17:42,876 : INFO : torch.Size([168, 168])
2017-05-03 19:17:42,876 : INFO : torch.Size([168])
2017-05-03 19:17:42,876 : INFO : torch.Size([168, 300])
2017-05-03 19:17:42,876 : INFO : torch.Size([168])
2017-05-03 19:17:42,876 : INFO : torch.Size([168, 168])
2017-05-03 19:17:42,876 : INFO : torch.Size([168])
2017-05-03 19:17:42,876 : INFO : torch.Size([168, 300])
2017-05-03 19:17:42,877 : INFO : torch.Size([168])
2017-05-03 19:17:42,877 : INFO : torch.Size([168, 168])
2017-05-03 19:17:42,877 : INFO : torch.Size([168])
2017-05-03 19:17:42,877 : INFO : torch.Size([168, 300])
2017-05-03 19:17:42,877 : INFO : torch.Size([168])
2017-05-03 19:17:42,877 : INFO : torch.Size([168, 168])
2017-05-03 19:17:42,877 : INFO : torch.Size([168])
2017-05-03 19:17:42,878 : INFO : torch.Size([3, 168])
2017-05-03 19:17:42,878 : INFO : torch.Size([3])
2017-05-03 19:17:42,878 : INFO : sum
2017-05-03 19:17:42,878 : INFO : 316347
2017-05-03 19:17:42,878 : INFO : ____________
2017-05-03 19:17:42,964 : INFO : _param count_
2017-05-03 19:17:42,964 : INFO : torch.Size([21705, 300])
2017-05-03 19:17:42,964 : INFO : torch.Size([168, 300])
2017-05-03 19:17:42,964 : INFO : torch.Size([168])
2017-05-03 19:17:42,965 : INFO : torch.Size([168, 168])
2017-05-03 19:17:42,965 : INFO : torch.Size([168])
2017-05-03 19:17:42,965 : INFO : torch.Size([168, 300])
2017-05-03 19:17:42,965 : INFO : torch.Size([168])
2017-05-03 19:17:42,965 : INFO : torch.Size([168, 168])
2017-05-03 19:17:42,965 : INFO : torch.Size([168])
2017-05-03 19:17:42,965 : INFO : torch.Size([168, 300])
2017-05-03 19:17:42,965 : INFO : torch.Size([168])
2017-05-03 19:17:42,966 : INFO : torch.Size([168, 168])
2017-05-03 19:17:42,966 : INFO : torch.Size([168])
2017-05-03 19:17:42,966 : INFO : torch.Size([168, 300])
2017-05-03 19:17:42,966 : INFO : torch.Size([168])
2017-05-03 19:17:42,966 : INFO : torch.Size([168, 168])
2017-05-03 19:17:42,966 : INFO : torch.Size([168])
2017-05-03 19:17:42,966 : INFO : torch.Size([3, 168])
2017-05-03 19:17:42,967 : INFO : torch.Size([3])
2017-05-03 19:17:42,967 : INFO : sum
2017-05-03 19:17:42,967 : INFO : 316347
2017-05-03 19:17:42,967 : INFO : ____________
2017-05-03 19:17:43,048 : INFO : _param count_
2017-05-03 19:17:43,049 : INFO : torch.Size([21705, 300])
2017-05-03 19:17:43,049 : INFO : torch.Size([168, 300])
2017-05-03 19:17:43,049 : INFO : torch.Size([168])
2017-05-03 19:17:43,049 : INFO : torch.Size([168, 168])
2017-05-03 19:17:43,049 : INFO : torch.Size([168])
2017-05-03 19:17:43,049 : INFO : torch.Size([168, 300])
2017-05-03 19:17:43,050 : INFO : torch.Size([168])
2017-05-03 19:17:43,050 : INFO : torch.Size([168, 168])
2017-05-03 19:17:43,050 : INFO : torch.Size([168])
2017-05-03 19:17:43,050 : INFO : torch.Size([168, 300])
2017-05-03 19:17:43,050 : INFO : torch.Size([168])
2017-05-03 19:17:43,050 : INFO : torch.Size([168, 168])
2017-05-03 19:17:43,051 : INFO : torch.Size([168])
2017-05-03 19:17:43,051 : INFO : torch.Size([168, 300])
2017-05-03 19:17:43,051 : INFO : torch.Size([168])
2017-05-03 19:17:43,051 : INFO : torch.Size([168, 168])
2017-05-03 19:17:43,051 : INFO : torch.Size([168])
2017-05-03 19:17:43,051 : INFO : torch.Size([3, 168])
2017-05-03 19:17:43,052 : INFO : torch.Size([3])
2017-05-03 19:17:43,052 : INFO : sum
2017-05-03 19:17:43,052 : INFO : 316347
2017-05-03 19:17:43,052 : INFO : ____________
2017-05-03 19:17:43,135 : INFO : _param count_
2017-05-03 19:17:43,136 : INFO : torch.Size([21705, 300])
2017-05-03 19:17:43,136 : INFO : torch.Size([168, 300])
2017-05-03 19:17:43,136 : INFO : torch.Size([168])
2017-05-03 19:17:43,136 : INFO : torch.Size([168, 168])
2017-05-03 19:17:43,136 : INFO : torch.Size([168])
2017-05-03 19:17:43,136 : INFO : torch.Size([168, 300])
2017-05-03 19:17:43,136 : INFO : torch.Size([168])
2017-05-03 19:17:43,137 : INFO : torch.Size([168, 168])
2017-05-03 19:17:43,137 : INFO : torch.Size([168])
2017-05-03 19:17:43,137 : INFO : torch.Size([168, 300])
2017-05-03 19:17:43,137 : INFO : torch.Size([168])
2017-05-03 19:17:43,137 : INFO : torch.Size([168, 168])
2017-05-03 19:17:43,137 : INFO : torch.Size([168])
2017-05-03 19:17:43,137 : INFO : torch.Size([168, 300])
2017-05-03 19:17:43,138 : INFO : torch.Size([168])
2017-05-03 19:17:43,138 : INFO : torch.Size([168, 168])
2017-05-03 19:17:43,138 : INFO : torch.Size([168])
2017-05-03 19:17:43,138 : INFO : torch.Size([3, 168])
2017-05-03 19:17:43,138 : INFO : torch.Size([3])
2017-05-03 19:17:43,138 : INFO : sum
2017-05-03 19:17:43,138 : INFO : 316347
2017-05-03 19:17:43,138 : INFO : ____________
2017-05-03 19:17:43,237 : INFO : _param count_
2017-05-03 19:17:43,237 : INFO : torch.Size([21705, 300])
2017-05-03 19:17:43,237 : INFO : torch.Size([168, 300])
2017-05-03 19:17:43,237 : INFO : torch.Size([168])
2017-05-03 19:17:43,238 : INFO : torch.Size([168, 168])
2017-05-03 19:17:43,238 : INFO : torch.Size([168])
2017-05-03 19:17:43,238 : INFO : torch.Size([168, 300])
2017-05-03 19:17:43,238 : INFO : torch.Size([168])
2017-05-03 19:17:43,238 : INFO : torch.Size([168, 168])
2017-05-03 19:17:43,238 : INFO : torch.Size([168])
2017-05-03 19:17:43,238 : INFO : torch.Size([168, 300])
2017-05-03 19:17:43,238 : INFO : torch.Size([168])
2017-05-03 19:17:43,239 : INFO : torch.Size([168, 168])
2017-05-03 19:17:43,239 : INFO : torch.Size([168])
2017-05-03 19:17:43,239 : INFO : torch.Size([168, 300])
2017-05-03 19:17:43,239 : INFO : torch.Size([168])
2017-05-03 19:17:43,239 : INFO : torch.Size([168, 168])
2017-05-03 19:17:43,239 : INFO : torch.Size([168])
2017-05-03 19:17:43,239 : INFO : torch.Size([3, 168])
2017-05-03 19:17:43,240 : INFO : torch.Size([3])
2017-05-03 19:17:43,240 : INFO : sum
2017-05-03 19:17:43,240 : INFO : 316347
2017-05-03 19:17:43,240 : INFO : ____________
2017-05-03 19:17:43,316 : INFO : _param count_
2017-05-03 19:17:43,316 : INFO : torch.Size([21705, 300])
2017-05-03 19:17:43,316 : INFO : torch.Size([168, 300])
2017-05-03 19:17:43,317 : INFO : torch.Size([168])
2017-05-03 19:17:43,317 : INFO : torch.Size([168, 168])
2017-05-03 19:17:43,317 : INFO : torch.Size([168])
2017-05-03 19:17:43,317 : INFO : torch.Size([168, 300])
2017-05-03 19:17:43,317 : INFO : torch.Size([168])
2017-05-03 19:17:43,317 : INFO : torch.Size([168, 168])
2017-05-03 19:17:43,317 : INFO : torch.Size([168])
2017-05-03 19:17:43,318 : INFO : torch.Size([168, 300])
2017-05-03 19:17:43,318 : INFO : torch.Size([168])
2017-05-03 19:17:43,318 : INFO : torch.Size([168, 168])
2017-05-03 19:17:43,318 : INFO : torch.Size([168])
2017-05-03 19:17:43,318 : INFO : torch.Size([168, 300])
2017-05-03 19:17:43,318 : INFO : torch.Size([168])
2017-05-03 19:17:43,318 : INFO : torch.Size([168, 168])
2017-05-03 19:17:43,318 : INFO : torch.Size([168])
2017-05-03 19:17:43,319 : INFO : torch.Size([3, 168])
2017-05-03 19:17:43,319 : INFO : torch.Size([3])
2017-05-03 19:17:43,319 : INFO : sum
2017-05-03 19:17:43,319 : INFO : 316347
2017-05-03 19:17:43,319 : INFO : ____________
2017-05-03 19:17:43,351 : INFO : _param count_
2017-05-03 19:17:43,352 : INFO : torch.Size([21705, 300])
2017-05-03 19:17:43,352 : INFO : torch.Size([168, 300])
2017-05-03 19:17:43,352 : INFO : torch.Size([168])
2017-05-03 19:17:43,352 : INFO : torch.Size([168, 168])
2017-05-03 19:17:43,352 : INFO : torch.Size([168])
2017-05-03 19:17:43,352 : INFO : torch.Size([168, 300])
2017-05-03 19:17:43,352 : INFO : torch.Size([168])
2017-05-03 19:17:43,352 : INFO : torch.Size([168, 168])
2017-05-03 19:17:43,353 : INFO : torch.Size([168])
2017-05-03 19:17:43,353 : INFO : torch.Size([168, 300])
2017-05-03 19:17:43,353 : INFO : torch.Size([168])
2017-05-03 19:17:43,353 : INFO : torch.Size([168, 168])
2017-05-03 19:17:43,353 : INFO : torch.Size([168])
2017-05-03 19:17:43,353 : INFO : torch.Size([168, 300])
2017-05-03 19:17:43,353 : INFO : torch.Size([168])
2017-05-03 19:17:43,354 : INFO : torch.Size([168, 168])
2017-05-03 19:17:43,354 : INFO : torch.Size([168])
2017-05-03 19:17:43,354 : INFO : torch.Size([3, 168])
2017-05-03 19:17:43,354 : INFO : torch.Size([3])
2017-05-03 19:17:43,354 : INFO : sum
2017-05-03 19:17:43,354 : INFO : 316347
2017-05-03 19:17:43,354 : INFO : ____________
2017-05-03 19:17:43,380 : INFO : _param count_
2017-05-03 19:17:43,380 : INFO : torch.Size([21705, 300])
2017-05-03 19:17:43,380 : INFO : torch.Size([168, 300])
2017-05-03 19:17:43,380 : INFO : torch.Size([168])
2017-05-03 19:17:43,381 : INFO : torch.Size([168, 168])
2017-05-03 19:17:43,381 : INFO : torch.Size([168])
2017-05-03 19:17:43,381 : INFO : torch.Size([168, 300])
2017-05-03 19:17:43,381 : INFO : torch.Size([168])
2017-05-03 19:17:43,381 : INFO : torch.Size([168, 168])
2017-05-03 19:17:43,382 : INFO : torch.Size([168])
2017-05-03 19:17:43,382 : INFO : torch.Size([168, 300])
2017-05-03 19:17:43,382 : INFO : torch.Size([168])
2017-05-03 19:17:43,382 : INFO : torch.Size([168, 168])
2017-05-03 19:17:43,382 : INFO : torch.Size([168])
2017-05-03 19:17:43,383 : INFO : torch.Size([168, 300])
2017-05-03 19:17:43,383 : INFO : torch.Size([168])
2017-05-03 19:17:43,383 : INFO : torch.Size([168, 168])
2017-05-03 19:17:43,383 : INFO : torch.Size([168])
2017-05-03 19:17:43,383 : INFO : torch.Size([3, 168])
2017-05-03 19:17:43,384 : INFO : torch.Size([3])
2017-05-03 19:17:43,384 : INFO : sum
2017-05-03 19:17:43,384 : INFO : 316347
2017-05-03 19:17:43,384 : INFO : ____________
2017-05-03 19:17:43,451 : INFO : _param count_
2017-05-03 19:17:43,452 : INFO : torch.Size([21705, 300])
2017-05-03 19:17:43,452 : INFO : torch.Size([168, 300])
2017-05-03 19:17:43,452 : INFO : torch.Size([168])
2017-05-03 19:17:43,452 : INFO : torch.Size([168, 168])
2017-05-03 19:17:43,452 : INFO : torch.Size([168])
2017-05-03 19:17:43,452 : INFO : torch.Size([168, 300])
2017-05-03 19:17:43,452 : INFO : torch.Size([168])
2017-05-03 19:17:43,453 : INFO : torch.Size([168, 168])
2017-05-03 19:17:43,453 : INFO : torch.Size([168])
2017-05-03 19:17:43,453 : INFO : torch.Size([168, 300])
2017-05-03 19:17:43,453 : INFO : torch.Size([168])
2017-05-03 19:17:43,454 : INFO : torch.Size([168, 168])
2017-05-03 19:17:43,454 : INFO : torch.Size([168])
2017-05-03 19:17:43,454 : INFO : torch.Size([168, 300])
2017-05-03 19:17:43,454 : INFO : torch.Size([168])
2017-05-03 19:17:43,454 : INFO : torch.Size([168, 168])
2017-05-03 19:17:43,454 : INFO : torch.Size([168])
2017-05-03 19:17:43,455 : INFO : torch.Size([3, 168])
2017-05-03 19:17:43,455 : INFO : torch.Size([3])
2017-05-03 19:17:43,455 : INFO : sum
2017-05-03 19:17:43,455 : INFO : 316347
2017-05-03 19:17:43,455 : INFO : ____________
2017-05-03 19:17:43,556 : INFO : _param count_
2017-05-03 19:17:43,556 : INFO : torch.Size([21705, 300])
2017-05-03 19:17:43,556 : INFO : torch.Size([168, 300])
2017-05-03 19:17:43,556 : INFO : torch.Size([168])
2017-05-03 19:17:43,556 : INFO : torch.Size([168, 168])
2017-05-03 19:17:43,557 : INFO : torch.Size([168])
2017-05-03 19:17:43,557 : INFO : torch.Size([168, 300])
2017-05-03 19:17:43,557 : INFO : torch.Size([168])
2017-05-03 19:17:43,557 : INFO : torch.Size([168, 168])
2017-05-03 19:17:43,557 : INFO : torch.Size([168])
2017-05-03 19:17:43,557 : INFO : torch.Size([168, 300])
2017-05-03 19:17:43,557 : INFO : torch.Size([168])
2017-05-03 19:17:43,557 : INFO : torch.Size([168, 168])
2017-05-03 19:17:43,558 : INFO : torch.Size([168])
2017-05-03 19:17:43,558 : INFO : torch.Size([168, 300])
2017-05-03 19:17:43,558 : INFO : torch.Size([168])
2017-05-03 19:17:43,558 : INFO : torch.Size([168, 168])
2017-05-03 19:17:43,558 : INFO : torch.Size([168])
2017-05-03 19:17:43,558 : INFO : torch.Size([3, 168])
2017-05-03 19:17:43,558 : INFO : torch.Size([3])
2017-05-03 19:17:43,559 : INFO : sum
2017-05-03 19:17:43,559 : INFO : 316347
2017-05-03 19:17:43,559 : INFO : ____________
2017-05-03 19:17:43,658 : INFO : _param count_
2017-05-03 19:17:43,659 : INFO : torch.Size([21705, 300])
2017-05-03 19:17:43,659 : INFO : torch.Size([168, 300])
2017-05-03 19:17:43,659 : INFO : torch.Size([168])
2017-05-03 19:17:43,659 : INFO : torch.Size([168, 168])
2017-05-03 19:17:43,659 : INFO : torch.Size([168])
2017-05-03 19:17:43,659 : INFO : torch.Size([168, 300])
2017-05-03 19:17:43,659 : INFO : torch.Size([168])
2017-05-03 19:17:43,660 : INFO : torch.Size([168, 168])
2017-05-03 19:17:43,660 : INFO : torch.Size([168])
2017-05-03 19:17:43,660 : INFO : torch.Size([168, 300])
2017-05-03 19:17:43,660 : INFO : torch.Size([168])
2017-05-03 19:17:43,660 : INFO : torch.Size([168, 168])
2017-05-03 19:17:43,660 : INFO : torch.Size([168])
2017-05-03 19:17:43,660 : INFO : torch.Size([168, 300])
2017-05-03 19:17:43,661 : INFO : torch.Size([168])
2017-05-03 19:17:43,661 : INFO : torch.Size([168, 168])
2017-05-03 19:17:43,661 : INFO : torch.Size([168])
2017-05-03 19:17:43,661 : INFO : torch.Size([3, 168])
2017-05-03 19:17:43,661 : INFO : torch.Size([3])
2017-05-03 19:17:43,661 : INFO : sum
2017-05-03 19:17:43,661 : INFO : 316347
2017-05-03 19:17:43,661 : INFO : ____________
2017-05-03 19:17:43,734 : INFO : _param count_
2017-05-03 19:17:43,735 : INFO : torch.Size([21705, 300])
2017-05-03 19:17:43,735 : INFO : torch.Size([168, 300])
2017-05-03 19:17:43,735 : INFO : torch.Size([168])
2017-05-03 19:17:43,735 : INFO : torch.Size([168, 168])
2017-05-03 19:17:43,736 : INFO : torch.Size([168])
2017-05-03 19:17:43,736 : INFO : torch.Size([168, 300])
2017-05-03 19:17:43,736 : INFO : torch.Size([168])
2017-05-03 19:17:43,736 : INFO : torch.Size([168, 168])
2017-05-03 19:17:43,736 : INFO : torch.Size([168])
2017-05-03 19:17:43,737 : INFO : torch.Size([168, 300])
2017-05-03 19:17:43,737 : INFO : torch.Size([168])
2017-05-03 19:17:43,737 : INFO : torch.Size([168, 168])
2017-05-03 19:17:43,737 : INFO : torch.Size([168])
2017-05-03 19:17:43,738 : INFO : torch.Size([168, 300])
2017-05-03 19:17:43,738 : INFO : torch.Size([168])
2017-05-03 19:17:43,738 : INFO : torch.Size([168, 168])
2017-05-03 19:17:43,738 : INFO : torch.Size([168])
2017-05-03 19:17:43,738 : INFO : torch.Size([3, 168])
2017-05-03 19:17:43,739 : INFO : torch.Size([3])
2017-05-03 19:17:43,739 : INFO : sum
2017-05-03 19:17:43,739 : INFO : 316347
2017-05-03 19:17:43,739 : INFO : ____________
2017-05-03 19:17:43,801 : INFO : _param count_
2017-05-03 19:17:43,801 : INFO : torch.Size([21705, 300])
2017-05-03 19:17:43,802 : INFO : torch.Size([168, 300])
2017-05-03 19:17:43,802 : INFO : torch.Size([168])
2017-05-03 19:17:43,802 : INFO : torch.Size([168, 168])
2017-05-03 19:17:43,802 : INFO : torch.Size([168])
2017-05-03 19:17:43,802 : INFO : torch.Size([168, 300])
2017-05-03 19:17:43,802 : INFO : torch.Size([168])
2017-05-03 19:17:43,802 : INFO : torch.Size([168, 168])
2017-05-03 19:17:43,803 : INFO : torch.Size([168])
2017-05-03 19:17:43,803 : INFO : torch.Size([168, 300])
2017-05-03 19:17:43,803 : INFO : torch.Size([168])
2017-05-03 19:17:43,803 : INFO : torch.Size([168, 168])
2017-05-03 19:17:43,803 : INFO : torch.Size([168])
2017-05-03 19:17:43,803 : INFO : torch.Size([168, 300])
2017-05-03 19:17:43,803 : INFO : torch.Size([168])
2017-05-03 19:17:43,803 : INFO : torch.Size([168, 168])
2017-05-03 19:17:43,804 : INFO : torch.Size([168])
2017-05-03 19:17:43,804 : INFO : torch.Size([3, 168])
2017-05-03 19:17:43,804 : INFO : torch.Size([3])
2017-05-03 19:17:43,804 : INFO : sum
2017-05-03 19:17:43,804 : INFO : 316347
2017-05-03 19:17:43,804 : INFO : ____________
2017-05-03 19:17:43,888 : INFO : _param count_
2017-05-03 19:17:43,889 : INFO : torch.Size([21705, 300])
2017-05-03 19:17:43,889 : INFO : torch.Size([168, 300])
2017-05-03 19:17:43,889 : INFO : torch.Size([168])
2017-05-03 19:17:43,889 : INFO : torch.Size([168, 168])
2017-05-03 19:17:43,889 : INFO : torch.Size([168])
2017-05-03 19:17:43,889 : INFO : torch.Size([168, 300])
2017-05-03 19:17:43,890 : INFO : torch.Size([168])
2017-05-03 19:17:43,890 : INFO : torch.Size([168, 168])
2017-05-03 19:17:43,890 : INFO : torch.Size([168])
2017-05-03 19:17:43,890 : INFO : torch.Size([168, 300])
2017-05-03 19:17:43,890 : INFO : torch.Size([168])
2017-05-03 19:17:43,890 : INFO : torch.Size([168, 168])
2017-05-03 19:17:43,890 : INFO : torch.Size([168])
2017-05-03 19:17:43,891 : INFO : torch.Size([168, 300])
2017-05-03 19:17:43,891 : INFO : torch.Size([168])
2017-05-03 19:17:43,891 : INFO : torch.Size([168, 168])
2017-05-03 19:17:43,891 : INFO : torch.Size([168])
2017-05-03 19:17:43,891 : INFO : torch.Size([3, 168])
2017-05-03 19:17:43,891 : INFO : torch.Size([3])
2017-05-03 19:17:43,892 : INFO : sum
2017-05-03 19:17:43,892 : INFO : 316347
2017-05-03 19:17:43,892 : INFO : ____________
2017-05-03 19:17:43,986 : INFO : _param count_
2017-05-03 19:17:43,987 : INFO : torch.Size([21705, 300])
2017-05-03 19:17:43,987 : INFO : torch.Size([168, 300])
2017-05-03 19:17:43,987 : INFO : torch.Size([168])
2017-05-03 19:17:43,987 : INFO : torch.Size([168, 168])
2017-05-03 19:17:43,987 : INFO : torch.Size([168])
2017-05-03 19:17:43,988 : INFO : torch.Size([168, 300])
2017-05-03 19:17:43,988 : INFO : torch.Size([168])
2017-05-03 19:17:43,988 : INFO : torch.Size([168, 168])
2017-05-03 19:17:43,988 : INFO : torch.Size([168])
2017-05-03 19:17:43,988 : INFO : torch.Size([168, 300])
2017-05-03 19:17:43,988 : INFO : torch.Size([168])
2017-05-03 19:17:43,989 : INFO : torch.Size([168, 168])
2017-05-03 19:17:43,989 : INFO : torch.Size([168])
2017-05-03 19:17:43,989 : INFO : torch.Size([168, 300])
2017-05-03 19:17:43,989 : INFO : torch.Size([168])
2017-05-03 19:17:43,989 : INFO : torch.Size([168, 168])
2017-05-03 19:17:43,989 : INFO : torch.Size([168])
2017-05-03 19:17:43,989 : INFO : torch.Size([3, 168])
2017-05-03 19:17:43,990 : INFO : torch.Size([3])
2017-05-03 19:17:43,990 : INFO : sum
2017-05-03 19:17:43,990 : INFO : 316347
2017-05-03 19:17:43,990 : INFO : ____________
2017-05-03 19:17:44,413 : INFO : _param count_
2017-05-03 19:17:44,413 : INFO : torch.Size([21705, 300])
2017-05-03 19:17:44,414 : INFO : torch.Size([168, 300])
2017-05-03 19:17:44,414 : INFO : torch.Size([168])
2017-05-03 19:17:44,414 : INFO : torch.Size([168, 168])
2017-05-03 19:17:44,414 : INFO : torch.Size([168])
2017-05-03 19:17:44,414 : INFO : torch.Size([168, 300])
2017-05-03 19:17:44,414 : INFO : torch.Size([168])
2017-05-03 19:17:44,414 : INFO : torch.Size([168, 168])
2017-05-03 19:17:44,415 : INFO : torch.Size([168])
2017-05-03 19:17:44,415 : INFO : torch.Size([168, 300])
2017-05-03 19:17:44,415 : INFO : torch.Size([168])
2017-05-03 19:17:44,415 : INFO : torch.Size([168, 168])
2017-05-03 19:17:44,415 : INFO : torch.Size([168])
2017-05-03 19:17:44,415 : INFO : torch.Size([168, 300])
2017-05-03 19:17:44,415 : INFO : torch.Size([168])
2017-05-03 19:17:44,416 : INFO : torch.Size([168, 168])
2017-05-03 19:17:44,416 : INFO : torch.Size([168])
2017-05-03 19:17:44,416 : INFO : torch.Size([3, 168])
2017-05-03 19:17:44,416 : INFO : torch.Size([3])
2017-05-03 19:17:44,416 : INFO : sum
2017-05-03 19:17:44,416 : INFO : 316347
2017-05-03 19:17:44,416 : INFO : ____________
2017-05-03 19:17:44,544 : INFO : _param count_
2017-05-03 19:17:44,544 : INFO : torch.Size([21705, 300])
2017-05-03 19:17:44,544 : INFO : torch.Size([168, 300])
2017-05-03 19:17:44,545 : INFO : torch.Size([168])
2017-05-03 19:17:44,545 : INFO : torch.Size([168, 168])
2017-05-03 19:17:44,545 : INFO : torch.Size([168])
2017-05-03 19:17:44,545 : INFO : torch.Size([168, 300])
2017-05-03 19:17:44,545 : INFO : torch.Size([168])
2017-05-03 19:17:44,545 : INFO : torch.Size([168, 168])
2017-05-03 19:17:44,545 : INFO : torch.Size([168])
2017-05-03 19:17:44,546 : INFO : torch.Size([168, 300])
2017-05-03 19:17:44,546 : INFO : torch.Size([168])
2017-05-03 19:17:44,546 : INFO : torch.Size([168, 168])
2017-05-03 19:17:44,546 : INFO : torch.Size([168])
2017-05-03 19:17:44,546 : INFO : torch.Size([168, 300])
2017-05-03 19:17:44,546 : INFO : torch.Size([168])
2017-05-03 19:17:44,546 : INFO : torch.Size([168, 168])
2017-05-03 19:17:44,547 : INFO : torch.Size([168])
2017-05-03 19:17:44,547 : INFO : torch.Size([3, 168])
2017-05-03 19:17:44,547 : INFO : torch.Size([3])
2017-05-03 19:17:44,547 : INFO : sum
2017-05-03 19:17:44,547 : INFO : 316347
2017-05-03 19:17:44,547 : INFO : ____________
2017-05-03 19:17:44,668 : INFO : _param count_
2017-05-03 19:17:44,670 : INFO : torch.Size([21705, 300])
2017-05-03 19:17:44,670 : INFO : torch.Size([168, 300])
2017-05-03 19:17:44,670 : INFO : torch.Size([168])
2017-05-03 19:17:44,670 : INFO : torch.Size([168, 168])
2017-05-03 19:17:44,670 : INFO : torch.Size([168])
2017-05-03 19:17:44,671 : INFO : torch.Size([168, 300])
2017-05-03 19:17:44,671 : INFO : torch.Size([168])
2017-05-03 19:17:44,671 : INFO : torch.Size([168, 168])
2017-05-03 19:17:44,671 : INFO : torch.Size([168])
2017-05-03 19:17:44,671 : INFO : torch.Size([168, 300])
2017-05-03 19:17:44,671 : INFO : torch.Size([168])
2017-05-03 19:17:44,671 : INFO : torch.Size([168, 168])
2017-05-03 19:17:44,671 : INFO : torch.Size([168])
2017-05-03 19:17:44,672 : INFO : torch.Size([168, 300])
2017-05-03 19:17:44,672 : INFO : torch.Size([168])
2017-05-03 19:17:44,672 : INFO : torch.Size([168, 168])
2017-05-03 19:17:44,672 : INFO : torch.Size([168])
2017-05-03 19:17:44,672 : INFO : torch.Size([3, 168])
2017-05-03 19:17:44,672 : INFO : torch.Size([3])
2017-05-03 19:17:44,672 : INFO : sum
2017-05-03 19:17:44,673 : INFO : 316347
2017-05-03 19:17:44,673 : INFO : ____________
2017-05-03 19:17:44,761 : INFO : _param count_
2017-05-03 19:17:44,761 : INFO : torch.Size([21705, 300])
2017-05-03 19:17:44,761 : INFO : torch.Size([168, 300])
2017-05-03 19:17:44,761 : INFO : torch.Size([168])
2017-05-03 19:17:44,762 : INFO : torch.Size([168, 168])
2017-05-03 19:17:44,762 : INFO : torch.Size([168])
2017-05-03 19:17:44,762 : INFO : torch.Size([168, 300])
2017-05-03 19:17:44,762 : INFO : torch.Size([168])
2017-05-03 19:17:44,762 : INFO : torch.Size([168, 168])
2017-05-03 19:17:44,762 : INFO : torch.Size([168])
2017-05-03 19:17:44,762 : INFO : torch.Size([168, 300])
2017-05-03 19:17:44,763 : INFO : torch.Size([168])
2017-05-03 19:17:44,763 : INFO : torch.Size([168, 168])
2017-05-03 19:17:44,763 : INFO : torch.Size([168])
2017-05-03 19:17:44,763 : INFO : torch.Size([168, 300])
2017-05-03 19:17:44,763 : INFO : torch.Size([168])
2017-05-03 19:17:44,763 : INFO : torch.Size([168, 168])
2017-05-03 19:17:44,763 : INFO : torch.Size([168])
2017-05-03 19:17:44,764 : INFO : torch.Size([3, 168])
2017-05-03 19:17:44,764 : INFO : torch.Size([3])
2017-05-03 19:17:44,764 : INFO : sum
2017-05-03 19:17:44,764 : INFO : 316347
2017-05-03 19:17:44,764 : INFO : ____________
2017-05-03 19:17:44,837 : INFO : _param count_
2017-05-03 19:17:44,838 : INFO : torch.Size([21705, 300])
2017-05-03 19:17:44,838 : INFO : torch.Size([168, 300])
2017-05-03 19:17:44,838 : INFO : torch.Size([168])
2017-05-03 19:17:44,838 : INFO : torch.Size([168, 168])
2017-05-03 19:17:44,838 : INFO : torch.Size([168])
2017-05-03 19:17:44,838 : INFO : torch.Size([168, 300])
2017-05-03 19:17:44,839 : INFO : torch.Size([168])
2017-05-03 19:17:44,839 : INFO : torch.Size([168, 168])
2017-05-03 19:17:44,839 : INFO : torch.Size([168])
2017-05-03 19:17:44,839 : INFO : torch.Size([168, 300])
2017-05-03 19:17:44,839 : INFO : torch.Size([168])
2017-05-03 19:17:44,839 : INFO : torch.Size([168, 168])
2017-05-03 19:17:44,839 : INFO : torch.Size([168])
2017-05-03 19:17:44,840 : INFO : torch.Size([168, 300])
2017-05-03 19:17:44,840 : INFO : torch.Size([168])
2017-05-03 19:17:44,840 : INFO : torch.Size([168, 168])
2017-05-03 19:17:44,840 : INFO : torch.Size([168])
2017-05-03 19:17:44,840 : INFO : torch.Size([3, 168])
2017-05-03 19:17:44,840 : INFO : torch.Size([3])
2017-05-03 19:17:44,840 : INFO : sum
2017-05-03 19:17:44,840 : INFO : 316347
2017-05-03 19:17:44,841 : INFO : ____________
2017-05-03 19:17:44,915 : INFO : _param count_
2017-05-03 19:17:44,915 : INFO : torch.Size([21705, 300])
2017-05-03 19:17:44,916 : INFO : torch.Size([168, 300])
2017-05-03 19:17:44,916 : INFO : torch.Size([168])
2017-05-03 19:17:44,916 : INFO : torch.Size([168, 168])
2017-05-03 19:17:44,916 : INFO : torch.Size([168])
2017-05-03 19:17:44,916 : INFO : torch.Size([168, 300])
2017-05-03 19:17:44,916 : INFO : torch.Size([168])
2017-05-03 19:17:44,916 : INFO : torch.Size([168, 168])
2017-05-03 19:17:44,917 : INFO : torch.Size([168])
2017-05-03 19:17:44,917 : INFO : torch.Size([168, 300])
2017-05-03 19:17:44,917 : INFO : torch.Size([168])
2017-05-03 19:17:44,917 : INFO : torch.Size([168, 168])
2017-05-03 19:17:44,917 : INFO : torch.Size([168])
2017-05-03 19:17:44,917 : INFO : torch.Size([168, 300])
2017-05-03 19:17:44,917 : INFO : torch.Size([168])
2017-05-03 19:17:44,917 : INFO : torch.Size([168, 168])
2017-05-03 19:17:44,918 : INFO : torch.Size([168])
2017-05-03 19:17:44,918 : INFO : torch.Size([3, 168])
2017-05-03 19:17:44,918 : INFO : torch.Size([3])
2017-05-03 19:17:44,918 : INFO : sum
2017-05-03 19:17:44,918 : INFO : 316347
2017-05-03 19:17:44,918 : INFO : ____________
2017-05-03 19:17:44,958 : INFO : _param count_
2017-05-03 19:17:44,958 : INFO : torch.Size([21705, 300])
2017-05-03 19:17:44,959 : INFO : torch.Size([168, 300])
2017-05-03 19:17:44,959 : INFO : torch.Size([168])
2017-05-03 19:17:44,959 : INFO : torch.Size([168, 168])
2017-05-03 19:17:44,959 : INFO : torch.Size([168])
2017-05-03 19:17:44,959 : INFO : torch.Size([168, 300])
2017-05-03 19:17:44,959 : INFO : torch.Size([168])
2017-05-03 19:17:44,959 : INFO : torch.Size([168, 168])
2017-05-03 19:17:44,960 : INFO : torch.Size([168])
2017-05-03 19:17:44,960 : INFO : torch.Size([168, 300])
2017-05-03 19:17:44,960 : INFO : torch.Size([168])
2017-05-03 19:17:44,960 : INFO : torch.Size([168, 168])
2017-05-03 19:17:44,960 : INFO : torch.Size([168])
2017-05-03 19:17:44,960 : INFO : torch.Size([168, 300])
2017-05-03 19:17:44,960 : INFO : torch.Size([168])
2017-05-03 19:17:44,960 : INFO : torch.Size([168, 168])
2017-05-03 19:17:44,961 : INFO : torch.Size([168])
2017-05-03 19:17:44,961 : INFO : torch.Size([3, 168])
2017-05-03 19:17:44,961 : INFO : torch.Size([3])
2017-05-03 19:17:44,961 : INFO : sum
2017-05-03 19:17:44,961 : INFO : 316347
2017-05-03 19:17:44,961 : INFO : ____________
2017-05-03 19:17:45,000 : INFO : _param count_
2017-05-03 19:17:45,000 : INFO : torch.Size([21705, 300])
2017-05-03 19:17:45,000 : INFO : torch.Size([168, 300])
2017-05-03 19:17:45,000 : INFO : torch.Size([168])
2017-05-03 19:17:45,000 : INFO : torch.Size([168, 168])
2017-05-03 19:17:45,000 : INFO : torch.Size([168])
2017-05-03 19:17:45,000 : INFO : torch.Size([168, 300])
2017-05-03 19:17:45,001 : INFO : torch.Size([168])
2017-05-03 19:17:45,001 : INFO : torch.Size([168, 168])
2017-05-03 19:17:45,001 : INFO : torch.Size([168])
2017-05-03 19:17:45,001 : INFO : torch.Size([168, 300])
2017-05-03 19:17:45,001 : INFO : torch.Size([168])
2017-05-03 19:17:45,001 : INFO : torch.Size([168, 168])
2017-05-03 19:17:45,001 : INFO : torch.Size([168])
2017-05-03 19:17:45,002 : INFO : torch.Size([168, 300])
2017-05-03 19:17:45,002 : INFO : torch.Size([168])
2017-05-03 19:17:45,002 : INFO : torch.Size([168, 168])
2017-05-03 19:17:45,002 : INFO : torch.Size([168])
2017-05-03 19:17:45,002 : INFO : torch.Size([3, 168])
2017-05-03 19:17:45,002 : INFO : torch.Size([3])
2017-05-03 19:17:45,002 : INFO : sum
2017-05-03 19:17:45,003 : INFO : 316347
2017-05-03 19:17:45,003 : INFO : ____________
2017-05-03 19:17:45,062 : INFO : _param count_
2017-05-03 19:17:45,063 : INFO : torch.Size([21705, 300])
2017-05-03 19:17:45,063 : INFO : torch.Size([168, 300])
2017-05-03 19:17:45,063 : INFO : torch.Size([168])
2017-05-03 19:17:45,063 : INFO : torch.Size([168, 168])
2017-05-03 19:17:45,063 : INFO : torch.Size([168])
2017-05-03 19:17:45,063 : INFO : torch.Size([168, 300])
2017-05-03 19:17:45,063 : INFO : torch.Size([168])
2017-05-03 19:17:45,064 : INFO : torch.Size([168, 168])
2017-05-03 19:17:45,064 : INFO : torch.Size([168])
2017-05-03 19:17:45,064 : INFO : torch.Size([168, 300])
2017-05-03 19:17:45,064 : INFO : torch.Size([168])
2017-05-03 19:17:45,064 : INFO : torch.Size([168, 168])
2017-05-03 19:17:45,064 : INFO : torch.Size([168])
2017-05-03 19:17:45,064 : INFO : torch.Size([168, 300])
2017-05-03 19:17:45,064 : INFO : torch.Size([168])
2017-05-03 19:17:45,065 : INFO : torch.Size([168, 168])
2017-05-03 19:17:45,065 : INFO : torch.Size([168])
2017-05-03 19:17:45,065 : INFO : torch.Size([3, 168])
2017-05-03 19:17:45,065 : INFO : torch.Size([3])
2017-05-03 19:17:45,065 : INFO : sum
2017-05-03 19:17:45,065 : INFO : 316347
2017-05-03 19:17:45,065 : INFO : ____________
2017-05-03 19:17:45,146 : INFO : _param count_
2017-05-03 19:17:45,147 : INFO : torch.Size([21705, 300])
2017-05-03 19:17:45,147 : INFO : torch.Size([168, 300])
2017-05-03 19:17:45,147 : INFO : torch.Size([168])
2017-05-03 19:17:45,147 : INFO : torch.Size([168, 168])
2017-05-03 19:17:45,148 : INFO : torch.Size([168])
2017-05-03 19:17:45,148 : INFO : torch.Size([168, 300])
2017-05-03 19:17:45,148 : INFO : torch.Size([168])
2017-05-03 19:17:45,148 : INFO : torch.Size([168, 168])
2017-05-03 19:17:45,149 : INFO : torch.Size([168])
2017-05-03 19:17:45,149 : INFO : torch.Size([168, 300])
2017-05-03 19:17:45,149 : INFO : torch.Size([168])
2017-05-03 19:17:45,149 : INFO : torch.Size([168, 168])
2017-05-03 19:17:45,149 : INFO : torch.Size([168])
2017-05-03 19:17:45,149 : INFO : torch.Size([168, 300])
2017-05-03 19:17:45,149 : INFO : torch.Size([168])
2017-05-03 19:17:45,150 : INFO : torch.Size([168, 168])
2017-05-03 19:17:45,150 : INFO : torch.Size([168])
2017-05-03 19:17:45,150 : INFO : torch.Size([3, 168])
2017-05-03 19:17:45,150 : INFO : torch.Size([3])
2017-05-03 19:17:45,150 : INFO : sum
2017-05-03 19:17:45,150 : INFO : 316347
2017-05-03 19:17:45,150 : INFO : ____________
2017-05-03 19:17:45,196 : INFO : _param count_
2017-05-03 19:17:45,196 : INFO : torch.Size([21705, 300])
2017-05-03 19:17:45,197 : INFO : torch.Size([168, 300])
2017-05-03 19:17:45,197 : INFO : torch.Size([168])
2017-05-03 19:17:45,197 : INFO : torch.Size([168, 168])
2017-05-03 19:17:45,197 : INFO : torch.Size([168])
2017-05-03 19:17:45,197 : INFO : torch.Size([168, 300])
2017-05-03 19:17:45,197 : INFO : torch.Size([168])
2017-05-03 19:17:45,197 : INFO : torch.Size([168, 168])
2017-05-03 19:17:45,197 : INFO : torch.Size([168])
2017-05-03 19:17:45,198 : INFO : torch.Size([168, 300])
2017-05-03 19:17:45,198 : INFO : torch.Size([168])
2017-05-03 19:17:45,198 : INFO : torch.Size([168, 168])
2017-05-03 19:17:45,198 : INFO : torch.Size([168])
2017-05-03 19:17:45,198 : INFO : torch.Size([168, 300])
2017-05-03 19:17:45,198 : INFO : torch.Size([168])
2017-05-03 19:17:45,198 : INFO : torch.Size([168, 168])
2017-05-03 19:17:45,199 : INFO : torch.Size([168])
2017-05-03 19:17:45,199 : INFO : torch.Size([3, 168])
2017-05-03 19:17:45,199 : INFO : torch.Size([3])
2017-05-03 19:17:45,199 : INFO : sum
2017-05-03 19:17:45,199 : INFO : 316347
2017-05-03 19:17:45,199 : INFO : ____________
2017-05-03 19:17:45,266 : INFO : _param count_
2017-05-03 19:17:45,267 : INFO : torch.Size([21705, 300])
2017-05-03 19:17:45,267 : INFO : torch.Size([168, 300])
2017-05-03 19:17:45,267 : INFO : torch.Size([168])
2017-05-03 19:17:45,267 : INFO : torch.Size([168, 168])
2017-05-03 19:17:45,267 : INFO : torch.Size([168])
2017-05-03 19:17:45,267 : INFO : torch.Size([168, 300])
2017-05-03 19:17:45,267 : INFO : torch.Size([168])
2017-05-03 19:17:45,268 : INFO : torch.Size([168, 168])
2017-05-03 19:17:45,268 : INFO : torch.Size([168])
2017-05-03 19:17:45,268 : INFO : torch.Size([168, 300])
2017-05-03 19:17:45,268 : INFO : torch.Size([168])
2017-05-03 19:17:45,268 : INFO : torch.Size([168, 168])
2017-05-03 19:17:45,268 : INFO : torch.Size([168])
2017-05-03 19:17:45,268 : INFO : torch.Size([168, 300])
2017-05-03 19:17:45,268 : INFO : torch.Size([168])
2017-05-03 19:22:54,753 : INFO : LOG_FILE
2017-05-03 19:22:54,754 : INFO : _________________________________start___________________________________
2017-05-03 19:22:54,786 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 19:22:55,084 : INFO : ==> SST vocabulary size : 21705
2017-05-03 19:23:00,385 : INFO : _param count_
2017-05-03 19:23:00,387 : INFO : torch.Size([21705, 300])
2017-05-03 19:23:00,388 : INFO : torch.Size([168, 300])
2017-05-03 19:23:00,389 : INFO : torch.Size([168])
2017-05-03 19:23:00,389 : INFO : torch.Size([168, 168])
2017-05-03 19:23:00,390 : INFO : torch.Size([168])
2017-05-03 19:23:00,390 : INFO : torch.Size([168, 300])
2017-05-03 19:23:00,391 : INFO : torch.Size([168])
2017-05-03 19:23:00,391 : INFO : torch.Size([168, 168])
2017-05-03 19:23:00,392 : INFO : torch.Size([168])
2017-05-03 19:23:00,392 : INFO : torch.Size([168, 300])
2017-05-03 19:23:00,393 : INFO : torch.Size([168])
2017-05-03 19:23:00,394 : INFO : torch.Size([168, 168])
2017-05-03 19:23:00,394 : INFO : torch.Size([168])
2017-05-03 19:23:00,395 : INFO : torch.Size([168, 300])
2017-05-03 19:23:00,395 : INFO : torch.Size([168])
2017-05-03 19:23:00,396 : INFO : torch.Size([168, 168])
2017-05-03 19:23:00,396 : INFO : torch.Size([168])
2017-05-03 19:23:00,397 : INFO : torch.Size([3, 168])
2017-05-03 19:23:00,397 : INFO : torch.Size([3])
2017-05-03 19:23:00,398 : INFO : sum
2017-05-03 19:23:00,399 : INFO : 316347
2017-05-03 19:23:00,399 : INFO : ____________
2017-05-03 19:25:07,771 : INFO : LOG_FILE
2017-05-03 19:25:07,771 : INFO : _________________________________start___________________________________
2017-05-03 19:25:07,801 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', hidden_dim=50, input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 19:25:07,909 : INFO : ==> SST vocabulary size : 21705
2017-05-03 19:25:12,780 : INFO : _param count_
2017-05-03 19:25:12,780 : INFO : torch.Size([21705, 300])
2017-05-03 19:25:12,780 : INFO : torch.Size([168, 300])
2017-05-03 19:25:12,780 : INFO : torch.Size([168])
2017-05-03 19:25:12,781 : INFO : torch.Size([168, 168])
2017-05-03 19:25:12,781 : INFO : torch.Size([168])
2017-05-03 19:25:12,781 : INFO : torch.Size([168, 300])
2017-05-03 19:25:12,781 : INFO : torch.Size([168])
2017-05-03 19:25:12,781 : INFO : torch.Size([168, 168])
2017-05-03 19:25:12,781 : INFO : torch.Size([168])
2017-05-03 19:25:12,782 : INFO : torch.Size([168, 300])
2017-05-03 19:25:12,782 : INFO : torch.Size([168])
2017-05-03 19:25:12,782 : INFO : torch.Size([168, 168])
2017-05-03 19:25:12,782 : INFO : torch.Size([168])
2017-05-03 19:25:12,782 : INFO : torch.Size([168, 300])
2017-05-03 19:25:12,782 : INFO : torch.Size([168])
2017-05-03 19:25:12,783 : INFO : torch.Size([168, 168])
2017-05-03 19:25:12,783 : INFO : torch.Size([168])
2017-05-03 19:25:12,783 : INFO : torch.Size([3, 168])
2017-05-03 19:25:12,783 : INFO : torch.Size([3])
2017-05-03 19:25:12,783 : INFO : sum
2017-05-03 19:25:12,783 : INFO : 316347
2017-05-03 19:25:12,784 : INFO : ____________
2017-05-03 19:36:39,774 : INFO : ==> Train loss   : 0.688580
2017-05-03 19:36:39,775 : INFO : Epoch
2017-05-03 19:36:39,775 : INFO : 0
2017-05-03 19:36:39,775 : INFO : dev percentage
2017-05-03 19:36:39,775 : INFO : 0.754587155963
2017-05-03 19:36:39,775 : INFO : Epoch
2017-05-03 19:36:39,775 : INFO : 0
2017-05-03 19:36:39,776 : INFO : test percentage
2017-05-03 19:36:39,776 : INFO : 0.801757276222
2017-05-03 19:48:08,257 : INFO : ==> Train loss   : 0.174314
2017-05-03 19:48:08,257 : INFO : Epoch
2017-05-03 19:48:08,258 : INFO : 1
2017-05-03 19:48:08,258 : INFO : dev percentage
2017-05-03 19:48:08,258 : INFO : 0.775229357798
2017-05-03 19:48:08,258 : INFO : Epoch
2017-05-03 19:48:08,258 : INFO : 1
2017-05-03 19:48:08,258 : INFO : test percentage
2017-05-03 19:48:08,258 : INFO : 0.788028555739
2017-05-03 19:59:39,569 : INFO : ==> Train loss   : 0.050930
2017-05-03 19:59:39,569 : INFO : Epoch
2017-05-03 19:59:39,569 : INFO : 2
2017-05-03 19:59:39,569 : INFO : dev percentage
2017-05-03 19:59:39,569 : INFO : 0.767201834862
2017-05-03 19:59:39,569 : INFO : Epoch
2017-05-03 19:59:39,570 : INFO : 2
2017-05-03 19:59:39,570 : INFO : test percentage
2017-05-03 19:59:39,570 : INFO : 0.807797913234
2017-05-03 20:11:26,602 : INFO : ==> Train loss   : 0.016399
2017-05-03 20:11:26,603 : INFO : Epoch
2017-05-03 20:11:26,603 : INFO : 3
2017-05-03 20:11:26,603 : INFO : dev percentage
2017-05-03 20:11:26,603 : INFO : 0.755733944954
2017-05-03 20:11:26,603 : INFO : Epoch
2017-05-03 20:11:26,603 : INFO : 3
2017-05-03 20:11:26,603 : INFO : test percentage
2017-05-03 20:11:26,604 : INFO : 0.80340472268
2017-05-03 20:22:52,832 : INFO : ==> Train loss   : 0.005915
2017-05-03 20:22:52,833 : INFO : Epoch
2017-05-03 20:22:52,833 : INFO : 4
2017-05-03 20:22:52,833 : INFO : dev percentage
2017-05-03 20:22:52,833 : INFO : 0.752293577982
2017-05-03 20:22:52,833 : INFO : Epoch
2017-05-03 20:22:52,833 : INFO : 4
2017-05-03 20:22:52,833 : INFO : test percentage
2017-05-03 20:22:52,834 : INFO : 0.796265788029
2017-05-03 20:34:13,399 : INFO : ==> Train loss   : 0.002484
2017-05-03 20:34:13,399 : INFO : Epoch
2017-05-03 20:34:13,400 : INFO : 5
2017-05-03 20:34:13,400 : INFO : dev percentage
2017-05-03 20:34:13,400 : INFO : 0.747706422018
2017-05-03 20:34:13,400 : INFO : Epoch
2017-05-03 20:34:13,400 : INFO : 5
2017-05-03 20:34:13,400 : INFO : test percentage
2017-05-03 20:34:13,400 : INFO : 0.797913234487
2017-05-03 20:45:33,779 : INFO : ==> Train loss   : 0.001484
2017-05-03 20:45:33,779 : INFO : Epoch
2017-05-03 20:45:33,779 : INFO : 6
2017-05-03 20:45:33,779 : INFO : dev percentage
2017-05-03 20:45:33,779 : INFO : 0.747706422018
2017-05-03 20:45:33,780 : INFO : Epoch
2017-05-03 20:45:33,780 : INFO : 6
2017-05-03 20:45:33,780 : INFO : test percentage
2017-05-03 20:45:33,780 : INFO : 0.792970895113
2017-05-03 20:56:43,911 : INFO : ==> Train loss   : 0.000955
2017-05-03 20:56:43,912 : INFO : Epoch
2017-05-03 20:56:43,912 : INFO : 7
2017-05-03 20:56:43,912 : INFO : dev percentage
2017-05-03 20:56:43,912 : INFO : 0.753440366972
2017-05-03 20:56:43,912 : INFO : Epoch
2017-05-03 20:56:43,912 : INFO : 7
2017-05-03 20:56:43,912 : INFO : test percentage
2017-05-03 20:56:43,913 : INFO : 0.792421746293
2017-05-03 21:07:50,906 : INFO : ==> Train loss   : 0.000930
2017-05-03 21:07:50,906 : INFO : Epoch
2017-05-03 21:07:50,906 : INFO : 8
2017-05-03 21:07:50,906 : INFO : dev percentage
2017-05-03 21:07:50,907 : INFO : 0.745412844037
2017-05-03 21:07:50,907 : INFO : Epoch
2017-05-03 21:07:50,907 : INFO : 8
2017-05-03 21:07:50,907 : INFO : test percentage
2017-05-03 21:07:50,907 : INFO : 0.789126853377
2017-05-03 21:19:04,651 : INFO : ==> Train loss   : 0.000737
2017-05-03 21:19:04,651 : INFO : Epoch
2017-05-03 21:19:04,652 : INFO : 9
2017-05-03 21:19:04,652 : INFO : dev percentage
2017-05-03 21:19:04,652 : INFO : 0.746559633028
2017-05-03 21:19:04,652 : INFO : Epoch
2017-05-03 21:19:04,652 : INFO : 9
2017-05-03 21:19:04,652 : INFO : test percentage
2017-05-03 21:19:04,652 : INFO : 0.786381109281
2017-05-03 21:29:59,177 : INFO : ==> Train loss   : 0.000517
2017-05-03 21:29:59,177 : INFO : Epoch
2017-05-03 21:29:59,178 : INFO : 10
2017-05-03 21:29:59,178 : INFO : dev percentage
2017-05-03 21:29:59,178 : INFO : 0.75
2017-05-03 21:29:59,178 : INFO : Epoch
2017-05-03 21:29:59,178 : INFO : 10
2017-05-03 21:29:59,178 : INFO : test percentage
2017-05-03 21:29:59,178 : INFO : 0.789126853377
2017-05-03 21:40:56,583 : INFO : ==> Train loss   : 0.000474
2017-05-03 21:40:56,583 : INFO : Epoch
2017-05-03 21:40:56,584 : INFO : 11
2017-05-03 21:40:56,584 : INFO : dev percentage
2017-05-03 21:40:56,584 : INFO : 0.744266055046
2017-05-03 21:40:56,584 : INFO : Epoch
2017-05-03 21:40:56,584 : INFO : 11
2017-05-03 21:40:56,584 : INFO : test percentage
2017-05-03 21:40:56,584 : INFO : 0.786381109281
2017-05-03 21:51:55,845 : INFO : ==> Train loss   : 0.000930
2017-05-03 21:51:55,846 : INFO : Epoch
2017-05-03 21:51:55,846 : INFO : 12
2017-05-03 21:51:55,846 : INFO : dev percentage
2017-05-03 21:51:55,846 : INFO : 0.76376146789
2017-05-03 21:51:55,846 : INFO : Epoch
2017-05-03 21:51:55,846 : INFO : 12
2017-05-03 21:51:55,846 : INFO : test percentage
2017-05-03 21:51:55,847 : INFO : 0.786381109281
2017-05-03 22:03:00,407 : INFO : ==> Train loss   : 0.023472
2017-05-03 22:03:00,408 : INFO : Epoch
2017-05-03 22:03:00,408 : INFO : 13
2017-05-03 22:03:00,408 : INFO : dev percentage
2017-05-03 22:03:00,408 : INFO : 0.764908256881
2017-05-03 22:03:00,408 : INFO : Epoch
2017-05-03 22:03:00,408 : INFO : 13
2017-05-03 22:03:00,408 : INFO : test percentage
2017-05-03 22:03:00,408 : INFO : 0.777594728171
2017-05-03 22:14:27,055 : INFO : ==> Train loss   : 0.027252
2017-05-03 22:14:27,056 : INFO : Epoch
2017-05-03 22:14:27,056 : INFO : 14
2017-05-03 22:14:27,056 : INFO : dev percentage
2017-05-03 22:14:27,056 : INFO : 0.764908256881
2017-05-03 22:14:27,056 : INFO : Epoch
2017-05-03 22:14:27,056 : INFO : 14
2017-05-03 22:14:27,056 : INFO : test percentage
2017-05-03 22:14:27,057 : INFO : 0.769357495881
2017-05-03 23:53:44,548 : INFO : LOG_FILE
2017-05-03 23:53:44,549 : INFO : _________________________________start___________________________________
2017-05-03 23:53:44,583 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 23:53:44,884 : INFO : ==> SST vocabulary size : 21705
2017-05-03 23:55:07,548 : INFO : LOG_FILE
2017-05-03 23:55:07,548 : INFO : _________________________________start___________________________________
2017-05-03 23:55:07,581 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 23:55:07,882 : INFO : ==> SST vocabulary size : 21705
2017-05-03 23:55:13,335 : INFO : _param count_
2017-05-03 23:55:13,338 : INFO : torch.Size([21705, 300])
2017-05-03 23:55:13,339 : INFO : torch.Size([168, 300])
2017-05-03 23:55:13,339 : INFO : torch.Size([168])
2017-05-03 23:55:13,340 : INFO : torch.Size([168, 168])
2017-05-03 23:55:13,340 : INFO : torch.Size([168])
2017-05-03 23:55:13,341 : INFO : torch.Size([168, 300])
2017-05-03 23:55:13,341 : INFO : torch.Size([168])
2017-05-03 23:55:13,342 : INFO : torch.Size([168, 168])
2017-05-03 23:55:13,343 : INFO : torch.Size([168])
2017-05-03 23:55:13,343 : INFO : torch.Size([168, 300])
2017-05-03 23:55:13,344 : INFO : torch.Size([168])
2017-05-03 23:55:13,344 : INFO : torch.Size([168, 168])
2017-05-03 23:55:13,345 : INFO : torch.Size([168])
2017-05-03 23:55:13,345 : INFO : torch.Size([168, 300])
2017-05-03 23:55:13,346 : INFO : torch.Size([168])
2017-05-03 23:55:13,347 : INFO : torch.Size([168, 168])
2017-05-03 23:55:13,347 : INFO : torch.Size([168])
2017-05-03 23:55:13,348 : INFO : torch.Size([3, 168])
2017-05-03 23:55:13,348 : INFO : torch.Size([3])
2017-05-03 23:55:13,349 : INFO : sum
2017-05-03 23:55:13,349 : INFO : 316347
2017-05-03 23:55:13,350 : INFO : ____________
2017-05-03 23:56:32,157 : INFO : LOG_FILE
2017-05-03 23:56:32,157 : INFO : _________________________________start___________________________________
2017-05-03 23:56:32,185 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 23:56:32,290 : INFO : ==> SST vocabulary size : 21705
2017-05-03 23:56:37,263 : INFO : _param count_
2017-05-03 23:56:37,263 : INFO : torch.Size([21705, 300])
2017-05-03 23:56:37,263 : INFO : torch.Size([168, 300])
2017-05-03 23:56:37,263 : INFO : torch.Size([168])
2017-05-03 23:56:37,264 : INFO : torch.Size([168, 168])
2017-05-03 23:56:37,264 : INFO : torch.Size([168])
2017-05-03 23:56:37,264 : INFO : torch.Size([168, 300])
2017-05-03 23:56:37,264 : INFO : torch.Size([168])
2017-05-03 23:56:37,264 : INFO : torch.Size([168, 168])
2017-05-03 23:56:37,264 : INFO : torch.Size([168])
2017-05-03 23:56:37,264 : INFO : torch.Size([168, 300])
2017-05-03 23:56:37,264 : INFO : torch.Size([168])
2017-05-03 23:56:37,265 : INFO : torch.Size([168, 168])
2017-05-03 23:56:37,265 : INFO : torch.Size([168])
2017-05-03 23:56:37,265 : INFO : torch.Size([168, 300])
2017-05-03 23:56:37,265 : INFO : torch.Size([168])
2017-05-03 23:56:37,265 : INFO : torch.Size([168, 168])
2017-05-03 23:56:37,265 : INFO : torch.Size([168])
2017-05-03 23:56:37,265 : INFO : torch.Size([3, 168])
2017-05-03 23:56:37,265 : INFO : torch.Size([3])
2017-05-03 23:56:37,266 : INFO : sum
2017-05-03 23:56:37,266 : INFO : 316347
2017-05-03 23:56:37,266 : INFO : ____________
2017-05-03 23:59:43,714 : INFO : LOG_FILE
2017-05-03 23:59:43,714 : INFO : _________________________________start___________________________________
2017-05-03 23:59:43,744 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-03 23:59:43,851 : INFO : ==> SST vocabulary size : 21705
2017-05-03 23:59:56,750 : INFO : _param count_
2017-05-03 23:59:56,751 : INFO : torch.Size([21705, 300])
2017-05-03 23:59:56,751 : INFO : torch.Size([168, 300])
2017-05-03 23:59:56,751 : INFO : torch.Size([168])
2017-05-03 23:59:56,751 : INFO : torch.Size([168, 168])
2017-05-03 23:59:56,751 : INFO : torch.Size([168])
2017-05-03 23:59:56,751 : INFO : torch.Size([168, 300])
2017-05-03 23:59:56,751 : INFO : torch.Size([168])
2017-05-03 23:59:56,752 : INFO : torch.Size([168, 168])
2017-05-03 23:59:56,752 : INFO : torch.Size([168])
2017-05-03 23:59:56,752 : INFO : torch.Size([168, 300])
2017-05-03 23:59:56,752 : INFO : torch.Size([168])
2017-05-03 23:59:56,752 : INFO : torch.Size([168, 168])
2017-05-03 23:59:56,752 : INFO : torch.Size([168])
2017-05-03 23:59:56,752 : INFO : torch.Size([168, 300])
2017-05-03 23:59:56,752 : INFO : torch.Size([168])
2017-05-03 23:59:56,753 : INFO : torch.Size([168, 168])
2017-05-03 23:59:56,753 : INFO : torch.Size([168])
2017-05-03 23:59:56,753 : INFO : torch.Size([3, 168])
2017-05-03 23:59:56,753 : INFO : torch.Size([3])
2017-05-03 23:59:56,753 : INFO : sum
2017-05-03 23:59:56,753 : INFO : 316347
2017-05-03 23:59:56,753 : INFO : ____________
2017-05-03 23:59:56,753 : INFO : ==> File found, loading to memory
2017-05-04 00:00:03,147 : INFO : ==> GLOVE vocabulary size: 2196016
2017-05-04 00:00:03,777 : INFO : done creating emb, quit
2017-05-04 00:00:03,778 : INFO : quit program due to memory leak during preprocess data, please rerun sentiment.py
2017-05-04 00:00:07,889 : INFO : LOG_FILE
2017-05-04 00:00:07,889 : INFO : _________________________________start___________________________________
2017-05-04 00:00:07,919 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-04 00:00:08,030 : INFO : ==> SST vocabulary size : 21705
2017-05-04 00:00:13,849 : INFO : _param count_
2017-05-04 00:00:13,849 : INFO : torch.Size([21705, 300])
2017-05-04 00:00:13,849 : INFO : torch.Size([168, 300])
2017-05-04 00:00:13,849 : INFO : torch.Size([168])
2017-05-04 00:00:13,850 : INFO : torch.Size([168, 168])
2017-05-04 00:00:13,850 : INFO : torch.Size([168])
2017-05-04 00:00:13,850 : INFO : torch.Size([168, 300])
2017-05-04 00:00:13,850 : INFO : torch.Size([168])
2017-05-04 00:00:13,850 : INFO : torch.Size([168, 168])
2017-05-04 00:00:13,850 : INFO : torch.Size([168])
2017-05-04 00:00:13,850 : INFO : torch.Size([168, 300])
2017-05-04 00:00:13,850 : INFO : torch.Size([168])
2017-05-04 00:00:13,851 : INFO : torch.Size([168, 168])
2017-05-04 00:00:13,851 : INFO : torch.Size([168])
2017-05-04 00:00:13,851 : INFO : torch.Size([168, 300])
2017-05-04 00:00:13,851 : INFO : torch.Size([168])
2017-05-04 00:00:13,851 : INFO : torch.Size([168, 168])
2017-05-04 00:00:13,851 : INFO : torch.Size([168])
2017-05-04 00:00:13,851 : INFO : torch.Size([3, 168])
2017-05-04 00:00:13,851 : INFO : torch.Size([3])
2017-05-04 00:00:13,851 : INFO : sum
2017-05-04 00:00:13,852 : INFO : 316347
2017-05-04 00:00:13,852 : INFO : ____________
2017-05-04 00:03:39,918 : INFO : LOG_FILE
2017-05-04 00:03:39,919 : INFO : _________________________________start___________________________________
2017-05-04 00:03:39,948 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-04 00:03:40,056 : INFO : ==> SST vocabulary size : 21705
2017-05-04 00:03:45,680 : INFO : _param count_
2017-05-04 00:03:45,680 : INFO : torch.Size([21705, 300])
2017-05-04 00:03:45,680 : INFO : torch.Size([168, 300])
2017-05-04 00:03:45,680 : INFO : torch.Size([168])
2017-05-04 00:03:45,680 : INFO : torch.Size([168, 168])
2017-05-04 00:03:45,680 : INFO : torch.Size([168])
2017-05-04 00:03:45,681 : INFO : torch.Size([168, 300])
2017-05-04 00:03:45,681 : INFO : torch.Size([168])
2017-05-04 00:03:45,681 : INFO : torch.Size([168, 168])
2017-05-04 00:03:45,681 : INFO : torch.Size([168])
2017-05-04 00:03:45,681 : INFO : torch.Size([168, 300])
2017-05-04 00:03:45,681 : INFO : torch.Size([168])
2017-05-04 00:03:45,681 : INFO : torch.Size([168, 168])
2017-05-04 00:03:45,681 : INFO : torch.Size([168])
2017-05-04 00:03:45,682 : INFO : torch.Size([168, 300])
2017-05-04 00:03:45,682 : INFO : torch.Size([168])
2017-05-04 00:03:45,682 : INFO : torch.Size([168, 168])
2017-05-04 00:03:45,682 : INFO : torch.Size([168])
2017-05-04 00:03:45,682 : INFO : torch.Size([3, 168])
2017-05-04 00:03:45,682 : INFO : torch.Size([3])
2017-05-04 00:03:45,682 : INFO : sum
2017-05-04 00:03:45,682 : INFO : 316347
2017-05-04 00:03:45,683 : INFO : ____________
2017-05-04 00:03:58,848 : INFO : LOG_FILE
2017-05-04 00:03:58,848 : INFO : _________________________________start___________________________________
2017-05-04 00:03:58,883 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-04 00:03:59,180 : INFO : ==> SST vocabulary size : 21705
2017-05-04 00:04:05,531 : INFO : _param count_
2017-05-04 00:04:05,534 : INFO : torch.Size([21705, 300])
2017-05-04 00:04:05,534 : INFO : torch.Size([168, 300])
2017-05-04 00:04:05,535 : INFO : torch.Size([168])
2017-05-04 00:04:05,536 : INFO : torch.Size([168, 168])
2017-05-04 00:04:05,536 : INFO : torch.Size([168])
2017-05-04 00:04:05,537 : INFO : torch.Size([168, 300])
2017-05-04 00:04:05,538 : INFO : torch.Size([168])
2017-05-04 00:04:05,538 : INFO : torch.Size([168, 168])
2017-05-04 00:04:05,539 : INFO : torch.Size([168])
2017-05-04 00:04:05,539 : INFO : torch.Size([168, 300])
2017-05-04 00:04:05,540 : INFO : torch.Size([168])
2017-05-04 00:04:05,541 : INFO : torch.Size([168, 168])
2017-05-04 00:04:05,541 : INFO : torch.Size([168])
2017-05-04 00:04:05,542 : INFO : torch.Size([168, 300])
2017-05-04 00:04:05,543 : INFO : torch.Size([168])
2017-05-04 00:04:05,543 : INFO : torch.Size([168, 168])
2017-05-04 00:04:05,544 : INFO : torch.Size([168])
2017-05-04 00:04:05,545 : INFO : torch.Size([3, 168])
2017-05-04 00:04:05,545 : INFO : torch.Size([3])
2017-05-04 00:04:05,546 : INFO : sum
2017-05-04 00:04:05,546 : INFO : 316347
2017-05-04 00:04:05,547 : INFO : ____________
2017-05-04 00:05:08,829 : INFO : LOG_FILE
2017-05-04 00:05:08,829 : INFO : _________________________________start___________________________________
2017-05-04 00:05:08,860 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-04 00:05:08,966 : INFO : ==> SST vocabulary size : 21705
2017-05-04 00:05:14,643 : INFO : _param count_
2017-05-04 00:05:14,643 : INFO : torch.Size([21705, 300])
2017-05-04 00:05:14,643 : INFO : torch.Size([168, 300])
2017-05-04 00:05:14,644 : INFO : torch.Size([168])
2017-05-04 00:05:14,644 : INFO : torch.Size([168, 168])
2017-05-04 00:05:14,644 : INFO : torch.Size([168])
2017-05-04 00:05:14,644 : INFO : torch.Size([168, 300])
2017-05-04 00:05:14,644 : INFO : torch.Size([168])
2017-05-04 00:05:14,644 : INFO : torch.Size([168, 168])
2017-05-04 00:05:14,644 : INFO : torch.Size([168])
2017-05-04 00:05:14,645 : INFO : torch.Size([168, 300])
2017-05-04 00:05:14,645 : INFO : torch.Size([168])
2017-05-04 00:05:14,645 : INFO : torch.Size([168, 168])
2017-05-04 00:05:14,645 : INFO : torch.Size([168])
2017-05-04 00:05:14,645 : INFO : torch.Size([168, 300])
2017-05-04 00:05:14,645 : INFO : torch.Size([168])
2017-05-04 00:05:14,645 : INFO : torch.Size([168, 168])
2017-05-04 00:05:14,645 : INFO : torch.Size([168])
2017-05-04 00:05:14,646 : INFO : torch.Size([3, 168])
2017-05-04 00:05:14,646 : INFO : torch.Size([3])
2017-05-04 00:05:14,646 : INFO : sum
2017-05-04 00:05:14,646 : INFO : 316347
2017-05-04 00:05:14,646 : INFO : ____________
2017-05-04 00:08:55,325 : INFO : LOG_FILE
2017-05-04 00:08:55,326 : INFO : _________________________________start___________________________________
2017-05-04 00:08:55,352 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-04 00:08:55,459 : INFO : ==> SST vocabulary size : 21705
2017-05-04 00:09:01,198 : INFO : _param count_
2017-05-04 00:09:01,198 : INFO : torch.Size([21705, 300])
2017-05-04 00:09:01,198 : INFO : torch.Size([168, 300])
2017-05-04 00:09:01,198 : INFO : torch.Size([168])
2017-05-04 00:09:01,198 : INFO : torch.Size([168, 168])
2017-05-04 00:09:01,199 : INFO : torch.Size([168])
2017-05-04 00:09:01,199 : INFO : torch.Size([168, 300])
2017-05-04 00:09:01,199 : INFO : torch.Size([168])
2017-05-04 00:09:01,199 : INFO : torch.Size([168, 168])
2017-05-04 00:09:01,199 : INFO : torch.Size([168])
2017-05-04 00:09:01,199 : INFO : torch.Size([168, 300])
2017-05-04 00:09:01,199 : INFO : torch.Size([168])
2017-05-04 00:09:01,199 : INFO : torch.Size([168, 168])
2017-05-04 00:09:01,200 : INFO : torch.Size([168])
2017-05-04 00:09:01,200 : INFO : torch.Size([168, 300])
2017-05-04 00:09:01,200 : INFO : torch.Size([168])
2017-05-04 00:09:01,200 : INFO : torch.Size([168, 168])
2017-05-04 00:09:01,200 : INFO : torch.Size([168])
2017-05-04 00:09:01,200 : INFO : torch.Size([3, 168])
2017-05-04 00:09:01,200 : INFO : torch.Size([3])
2017-05-04 00:09:01,200 : INFO : sum
2017-05-04 00:09:01,200 : INFO : 316347
2017-05-04 00:09:01,201 : INFO : ____________
2017-05-04 00:11:28,247 : INFO : LOG_FILE
2017-05-04 00:11:28,247 : INFO : _________________________________start___________________________________
2017-05-04 00:11:28,276 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-04 00:11:28,380 : INFO : ==> SST vocabulary size : 21705
2017-05-04 00:11:34,081 : INFO : _param count_
2017-05-04 00:11:34,082 : INFO : torch.Size([21705, 300])
2017-05-04 00:11:34,082 : INFO : torch.Size([168, 300])
2017-05-04 00:11:34,082 : INFO : torch.Size([168])
2017-05-04 00:11:34,082 : INFO : torch.Size([168, 168])
2017-05-04 00:11:34,082 : INFO : torch.Size([168])
2017-05-04 00:11:34,082 : INFO : torch.Size([168, 300])
2017-05-04 00:11:34,082 : INFO : torch.Size([168])
2017-05-04 00:11:34,082 : INFO : torch.Size([168, 168])
2017-05-04 00:11:34,083 : INFO : torch.Size([168])
2017-05-04 00:11:34,083 : INFO : torch.Size([168, 300])
2017-05-04 00:11:34,083 : INFO : torch.Size([168])
2017-05-04 00:11:34,083 : INFO : torch.Size([168, 168])
2017-05-04 00:11:34,083 : INFO : torch.Size([168])
2017-05-04 00:11:34,083 : INFO : torch.Size([168, 300])
2017-05-04 00:11:34,083 : INFO : torch.Size([168])
2017-05-04 00:11:34,083 : INFO : torch.Size([168, 168])
2017-05-04 00:11:34,084 : INFO : torch.Size([168])
2017-05-04 00:11:34,084 : INFO : torch.Size([3, 168])
2017-05-04 00:11:34,084 : INFO : torch.Size([3])
2017-05-04 00:11:34,084 : INFO : sum
2017-05-04 00:11:34,084 : INFO : 316347
2017-05-04 00:11:34,084 : INFO : ____________
2017-05-04 00:12:04,399 : INFO : LOG_FILE
2017-05-04 00:12:04,399 : INFO : _________________________________start___________________________________
2017-05-04 00:12:04,427 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-04 00:12:04,534 : INFO : ==> SST vocabulary size : 21705
2017-05-04 00:12:10,245 : INFO : _param count_
2017-05-04 00:12:10,245 : INFO : torch.Size([21705, 300])
2017-05-04 00:12:10,245 : INFO : torch.Size([168, 300])
2017-05-04 00:12:10,245 : INFO : torch.Size([168])
2017-05-04 00:12:10,245 : INFO : torch.Size([168, 168])
2017-05-04 00:12:10,246 : INFO : torch.Size([168])
2017-05-04 00:12:10,246 : INFO : torch.Size([168, 300])
2017-05-04 00:12:10,246 : INFO : torch.Size([168])
2017-05-04 00:12:10,246 : INFO : torch.Size([168, 168])
2017-05-04 00:12:10,246 : INFO : torch.Size([168])
2017-05-04 00:12:10,246 : INFO : torch.Size([168, 300])
2017-05-04 00:12:10,246 : INFO : torch.Size([168])
2017-05-04 00:12:10,246 : INFO : torch.Size([168, 168])
2017-05-04 00:12:10,247 : INFO : torch.Size([168])
2017-05-04 00:12:10,247 : INFO : torch.Size([168, 300])
2017-05-04 00:12:10,247 : INFO : torch.Size([168])
2017-05-04 00:12:10,247 : INFO : torch.Size([168, 168])
2017-05-04 00:12:10,247 : INFO : torch.Size([168])
2017-05-04 00:12:10,247 : INFO : torch.Size([3, 168])
2017-05-04 00:12:10,247 : INFO : torch.Size([3])
2017-05-04 00:12:10,248 : INFO : sum
2017-05-04 00:12:10,248 : INFO : 316347
2017-05-04 00:12:10,248 : INFO : ____________
2017-05-04 00:14:56,507 : INFO : LOG_FILE
2017-05-04 00:14:56,507 : INFO : _________________________________start___________________________________
2017-05-04 00:14:56,538 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-04 00:14:56,642 : INFO : ==> SST vocabulary size : 21705
2017-05-04 00:15:02,322 : INFO : _param count_
2017-05-04 00:15:02,322 : INFO : torch.Size([21705, 300])
2017-05-04 00:15:02,322 : INFO : torch.Size([168, 300])
2017-05-04 00:15:02,322 : INFO : torch.Size([168])
2017-05-04 00:15:02,322 : INFO : torch.Size([168, 168])
2017-05-04 00:15:02,322 : INFO : torch.Size([168])
2017-05-04 00:15:02,323 : INFO : torch.Size([168, 300])
2017-05-04 00:15:02,323 : INFO : torch.Size([168])
2017-05-04 00:15:02,323 : INFO : torch.Size([168, 168])
2017-05-04 00:15:02,323 : INFO : torch.Size([168])
2017-05-04 00:15:02,323 : INFO : torch.Size([168, 300])
2017-05-04 00:15:02,323 : INFO : torch.Size([168])
2017-05-04 00:15:02,323 : INFO : torch.Size([168, 168])
2017-05-04 00:15:02,323 : INFO : torch.Size([168])
2017-05-04 00:15:02,324 : INFO : torch.Size([168, 300])
2017-05-04 00:15:02,324 : INFO : torch.Size([168])
2017-05-04 00:15:02,324 : INFO : torch.Size([168, 168])
2017-05-04 00:15:02,324 : INFO : torch.Size([168])
2017-05-04 00:15:02,324 : INFO : torch.Size([3, 168])
2017-05-04 00:15:02,324 : INFO : torch.Size([3])
2017-05-04 00:15:02,324 : INFO : sum
2017-05-04 00:15:02,324 : INFO : 316347
2017-05-04 00:15:02,325 : INFO : ____________
2017-05-04 00:17:25,169 : INFO : LOG_FILE
2017-05-04 00:17:25,169 : INFO : _________________________________start___________________________________
2017-05-04 00:17:25,199 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-04 00:17:25,318 : INFO : ==> SST vocabulary size : 21705
2017-05-04 00:17:31,007 : INFO : _param count_
2017-05-04 00:17:31,007 : INFO : torch.Size([21705, 300])
2017-05-04 00:17:31,007 : INFO : torch.Size([168, 300])
2017-05-04 00:17:31,007 : INFO : torch.Size([168])
2017-05-04 00:17:31,007 : INFO : torch.Size([168, 168])
2017-05-04 00:17:31,007 : INFO : torch.Size([168])
2017-05-04 00:17:31,008 : INFO : torch.Size([168, 300])
2017-05-04 00:17:31,008 : INFO : torch.Size([168])
2017-05-04 00:17:31,008 : INFO : torch.Size([168, 168])
2017-05-04 00:17:31,008 : INFO : torch.Size([168])
2017-05-04 00:17:31,008 : INFO : torch.Size([168, 300])
2017-05-04 00:17:31,008 : INFO : torch.Size([168])
2017-05-04 00:17:31,008 : INFO : torch.Size([168, 168])
2017-05-04 00:17:31,009 : INFO : torch.Size([168])
2017-05-04 00:17:31,009 : INFO : torch.Size([168, 300])
2017-05-04 00:17:31,009 : INFO : torch.Size([168])
2017-05-04 00:17:31,009 : INFO : torch.Size([168, 168])
2017-05-04 00:17:31,009 : INFO : torch.Size([168])
2017-05-04 00:17:31,009 : INFO : torch.Size([3, 168])
2017-05-04 00:17:31,009 : INFO : torch.Size([3])
2017-05-04 00:17:31,010 : INFO : sum
2017-05-04 00:17:31,010 : INFO : 316347
2017-05-04 00:17:31,010 : INFO : ____________
2017-05-04 00:24:09,416 : INFO : LOG_FILE
2017-05-04 00:24:09,417 : INFO : _________________________________start___________________________________
2017-05-04 00:24:09,450 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-04 00:24:09,752 : INFO : ==> SST vocabulary size : 21705
2017-05-04 00:24:16,054 : INFO : _param count_
2017-05-04 00:24:16,056 : INFO : torch.Size([21705, 300])
2017-05-04 00:24:16,057 : INFO : torch.Size([168, 300])
2017-05-04 00:24:16,058 : INFO : torch.Size([168])
2017-05-04 00:24:16,058 : INFO : torch.Size([168, 168])
2017-05-04 00:24:16,059 : INFO : torch.Size([168])
2017-05-04 00:24:16,059 : INFO : torch.Size([168, 300])
2017-05-04 00:24:16,060 : INFO : torch.Size([168])
2017-05-04 00:24:16,060 : INFO : torch.Size([168, 168])
2017-05-04 00:24:16,061 : INFO : torch.Size([168])
2017-05-04 00:24:16,062 : INFO : torch.Size([168, 300])
2017-05-04 00:24:16,062 : INFO : torch.Size([168])
2017-05-04 00:24:16,063 : INFO : torch.Size([168, 168])
2017-05-04 00:24:16,063 : INFO : torch.Size([168])
2017-05-04 00:24:16,064 : INFO : torch.Size([168, 300])
2017-05-04 00:24:16,064 : INFO : torch.Size([168])
2017-05-04 00:24:16,065 : INFO : torch.Size([168, 168])
2017-05-04 00:24:16,065 : INFO : torch.Size([168])
2017-05-04 00:24:16,066 : INFO : torch.Size([3, 168])
2017-05-04 00:24:16,067 : INFO : torch.Size([3])
2017-05-04 00:24:16,067 : INFO : sum
2017-05-04 00:24:16,068 : INFO : 316347
2017-05-04 00:24:16,068 : INFO : ____________
2017-05-04 00:26:57,405 : INFO : LOG_FILE
2017-05-04 00:26:57,405 : INFO : _________________________________start___________________________________
2017-05-04 00:26:57,435 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-04 00:26:57,542 : INFO : ==> SST vocabulary size : 21705
2017-05-04 00:27:03,275 : INFO : _param count_
2017-05-04 00:27:03,276 : INFO : torch.Size([21705, 300])
2017-05-04 00:27:03,276 : INFO : torch.Size([168, 300])
2017-05-04 00:27:03,276 : INFO : torch.Size([168])
2017-05-04 00:27:03,276 : INFO : torch.Size([168, 168])
2017-05-04 00:27:03,276 : INFO : torch.Size([168])
2017-05-04 00:27:03,276 : INFO : torch.Size([168, 300])
2017-05-04 00:27:03,277 : INFO : torch.Size([168])
2017-05-04 00:27:03,277 : INFO : torch.Size([168, 168])
2017-05-04 00:27:03,277 : INFO : torch.Size([168])
2017-05-04 00:27:03,277 : INFO : torch.Size([168, 300])
2017-05-04 00:27:03,277 : INFO : torch.Size([168])
2017-05-04 00:27:03,277 : INFO : torch.Size([168, 168])
2017-05-04 00:27:03,277 : INFO : torch.Size([168])
2017-05-04 00:27:03,278 : INFO : torch.Size([168, 300])
2017-05-04 00:27:03,278 : INFO : torch.Size([168])
2017-05-04 00:27:03,278 : INFO : torch.Size([168, 168])
2017-05-04 00:27:03,278 : INFO : torch.Size([168])
2017-05-04 00:27:03,278 : INFO : torch.Size([3, 168])
2017-05-04 00:27:03,278 : INFO : torch.Size([3])
2017-05-04 00:27:03,278 : INFO : sum
2017-05-04 00:27:03,279 : INFO : 316347
2017-05-04 00:27:03,279 : INFO : ____________
2017-05-04 00:30:31,335 : INFO : ==> Train loss   : 17.821435
2017-05-04 00:30:31,335 : INFO : Epoch
2017-05-04 00:30:31,335 : INFO : 0
2017-05-04 00:30:31,335 : INFO : dev percentage
2017-05-04 00:30:31,335 : INFO : 0.905963302752
2017-05-04 00:30:31,335 : INFO : Epoch
2017-05-04 00:30:31,335 : INFO : 0
2017-05-04 00:30:31,336 : INFO : test percentage
2017-05-04 00:30:31,336 : INFO : 0.734211971444
2017-05-04 00:34:00,598 : INFO : ==> Train loss   : 8.225237
2017-05-04 00:34:00,598 : INFO : Epoch
2017-05-04 00:34:00,598 : INFO : 1
2017-05-04 00:34:00,598 : INFO : dev percentage
2017-05-04 00:34:00,598 : INFO : 0.951834862385
2017-05-04 00:34:00,599 : INFO : Epoch
2017-05-04 00:34:00,599 : INFO : 1
2017-05-04 00:34:00,599 : INFO : test percentage
2017-05-04 00:34:00,599 : INFO : 0.748489840747
2017-05-04 00:37:28,611 : INFO : ==> Train loss   : 6.401720
2017-05-04 00:37:28,611 : INFO : Epoch
2017-05-04 00:37:28,611 : INFO : 2
2017-05-04 00:37:28,611 : INFO : dev percentage
2017-05-04 00:37:28,611 : INFO : 0.987385321101
2017-05-04 00:37:28,612 : INFO : Epoch
2017-05-04 00:37:28,612 : INFO : 2
2017-05-04 00:37:28,612 : INFO : test percentage
2017-05-04 00:37:28,612 : INFO : 0.72981878089
2017-05-04 00:41:07,809 : INFO : LOG_FILE
2017-05-04 00:41:07,810 : INFO : _________________________________start___________________________________
2017-05-04 00:41:07,844 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-04 00:41:08,169 : INFO : ==> SST vocabulary size : 21705
2017-05-04 00:41:14,269 : INFO : _param count_
2017-05-04 00:41:14,271 : INFO : torch.Size([21705, 300])
2017-05-04 00:41:14,272 : INFO : torch.Size([168, 300])
2017-05-04 00:41:14,273 : INFO : torch.Size([168])
2017-05-04 00:41:14,273 : INFO : torch.Size([168, 168])
2017-05-04 00:41:14,274 : INFO : torch.Size([168])
2017-05-04 00:41:14,274 : INFO : torch.Size([168, 300])
2017-05-04 00:41:14,275 : INFO : torch.Size([168])
2017-05-04 00:41:14,275 : INFO : torch.Size([168, 168])
2017-05-04 00:41:14,276 : INFO : torch.Size([168])
2017-05-04 00:41:14,277 : INFO : torch.Size([168, 300])
2017-05-04 00:41:14,277 : INFO : torch.Size([168])
2017-05-04 00:41:14,278 : INFO : torch.Size([168, 168])
2017-05-04 00:41:14,278 : INFO : torch.Size([168])
2017-05-04 00:41:14,279 : INFO : torch.Size([168, 300])
2017-05-04 00:41:14,279 : INFO : torch.Size([168])
2017-05-04 00:41:14,280 : INFO : torch.Size([168, 168])
2017-05-04 00:41:14,280 : INFO : torch.Size([168])
2017-05-04 00:41:14,281 : INFO : torch.Size([3, 168])
2017-05-04 00:41:14,282 : INFO : torch.Size([3])
2017-05-04 00:41:14,282 : INFO : sum
2017-05-04 00:41:14,283 : INFO : 316347
2017-05-04 00:41:14,283 : INFO : ____________
2017-05-04 00:42:51,066 : INFO : LOG_FILE
2017-05-04 00:42:51,066 : INFO : _________________________________start___________________________________
2017-05-04 00:42:51,093 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=15, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-04 00:42:51,201 : INFO : ==> SST vocabulary size : 21705
2017-05-04 00:42:56,899 : INFO : _param count_
2017-05-04 00:42:56,899 : INFO : torch.Size([21705, 300])
2017-05-04 00:42:56,899 : INFO : torch.Size([168, 300])
2017-05-04 00:42:56,899 : INFO : torch.Size([168])
2017-05-04 00:42:56,900 : INFO : torch.Size([168, 168])
2017-05-04 00:42:56,900 : INFO : torch.Size([168])
2017-05-04 00:42:56,900 : INFO : torch.Size([168, 300])
2017-05-04 00:42:56,900 : INFO : torch.Size([168])
2017-05-04 00:42:56,900 : INFO : torch.Size([168, 168])
2017-05-04 00:42:56,900 : INFO : torch.Size([168])
2017-05-04 00:42:56,900 : INFO : torch.Size([168, 300])
2017-05-04 00:42:56,901 : INFO : torch.Size([168])
2017-05-04 00:42:56,901 : INFO : torch.Size([168, 168])
2017-05-04 00:42:56,901 : INFO : torch.Size([168])
2017-05-04 00:42:56,901 : INFO : torch.Size([168, 300])
2017-05-04 00:42:56,901 : INFO : torch.Size([168])
2017-05-04 00:42:56,901 : INFO : torch.Size([168, 168])
2017-05-04 00:42:56,901 : INFO : torch.Size([168])
2017-05-04 00:42:56,901 : INFO : torch.Size([3, 168])
2017-05-04 00:42:56,902 : INFO : torch.Size([3])
2017-05-04 00:42:56,902 : INFO : sum
2017-05-04 00:42:56,902 : INFO : 316347
2017-05-04 00:42:56,902 : INFO : ____________
2017-05-04 00:57:12,075 : INFO : ==> Train loss   : 10.099090
2017-05-04 00:57:12,075 : INFO : Epoch
2017-05-04 00:57:12,075 : INFO : 0
2017-05-04 00:57:12,076 : INFO : dev percentage
2017-05-04 00:57:12,076 : INFO : 0.794724770642
2017-05-04 00:57:12,076 : INFO : Epoch
2017-05-04 00:57:12,076 : INFO : 0
2017-05-04 00:57:12,076 : INFO : test percentage
2017-05-04 00:57:12,076 : INFO : 0.802855573861
2017-05-04 01:11:47,299 : INFO : ==> Train loss   : 7.568983
2017-05-04 01:11:47,299 : INFO : Epoch
2017-05-04 01:11:47,299 : INFO : 1
2017-05-04 01:11:47,299 : INFO : dev percentage
2017-05-04 01:11:47,300 : INFO : 0.798165137615
2017-05-04 01:11:47,300 : INFO : Epoch
2017-05-04 01:11:47,300 : INFO : 1
2017-05-04 01:11:47,300 : INFO : test percentage
2017-05-04 01:11:47,300 : INFO : 0.810543657331
2017-05-04 01:19:17,290 : INFO : LOG_FILE
2017-05-04 01:19:17,290 : INFO : _________________________________start___________________________________
2017-05-04 01:19:17,317 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-04 01:19:17,427 : INFO : ==> SST vocabulary size : 21705
2017-05-04 01:19:23,018 : INFO : _param count_
2017-05-04 01:19:23,018 : INFO : torch.Size([21705, 300])
2017-05-04 01:19:23,018 : INFO : torch.Size([168, 300])
2017-05-04 01:19:23,018 : INFO : torch.Size([168])
2017-05-04 01:19:23,019 : INFO : torch.Size([168, 168])
2017-05-04 01:19:23,019 : INFO : torch.Size([168])
2017-05-04 01:19:23,019 : INFO : torch.Size([168, 300])
2017-05-04 01:19:23,019 : INFO : torch.Size([168])
2017-05-04 01:19:23,019 : INFO : torch.Size([168, 168])
2017-05-04 01:19:23,019 : INFO : torch.Size([168])
2017-05-04 01:19:23,020 : INFO : torch.Size([168, 300])
2017-05-04 01:19:23,020 : INFO : torch.Size([168])
2017-05-04 01:19:23,020 : INFO : torch.Size([168, 168])
2017-05-04 01:19:23,020 : INFO : torch.Size([168])
2017-05-04 01:19:23,020 : INFO : torch.Size([168, 300])
2017-05-04 01:19:23,020 : INFO : torch.Size([168])
2017-05-04 01:19:23,021 : INFO : torch.Size([168, 168])
2017-05-04 01:19:23,021 : INFO : torch.Size([168])
2017-05-04 01:19:23,021 : INFO : torch.Size([3, 168])
2017-05-04 01:19:23,021 : INFO : torch.Size([3])
2017-05-04 01:19:23,021 : INFO : sum
2017-05-04 01:19:23,021 : INFO : 316347
2017-05-04 01:19:23,021 : INFO : ____________
2017-05-04 01:45:58,229 : INFO : ==> Train loss   : 7.568983
2017-05-04 01:45:58,229 : INFO : Epoch
2017-05-04 01:45:58,229 : INFO : 0
2017-05-04 01:45:58,230 : INFO : dev percentage
2017-05-04 01:45:58,230 : INFO : 0.798165137615
2017-05-04 01:45:58,230 : INFO : Epoch
2017-05-04 01:45:58,230 : INFO : 0
2017-05-04 01:45:58,230 : INFO : test percentage
2017-05-04 01:45:58,230 : INFO : 0.810543657331
2017-05-04 02:12:29,664 : INFO : ==> Train loss   : 6.081438
2017-05-04 02:12:29,664 : INFO : Epoch
2017-05-04 02:12:29,665 : INFO : 1
2017-05-04 02:12:29,665 : INFO : dev percentage
2017-05-04 02:12:29,665 : INFO : 0.772935779817
2017-05-04 02:12:29,665 : INFO : Epoch
2017-05-04 02:12:29,665 : INFO : 1
2017-05-04 02:12:29,665 : INFO : test percentage
2017-05-04 02:12:29,665 : INFO : 0.799011532125
2017-05-04 02:38:47,268 : INFO : ==> Train loss   : 5.484605
2017-05-04 02:38:47,268 : INFO : Epoch
2017-05-04 02:38:47,268 : INFO : 2
2017-05-04 02:38:47,268 : INFO : dev percentage
2017-05-04 02:38:47,268 : INFO : 0.782110091743
2017-05-04 02:38:47,268 : INFO : Epoch
2017-05-04 02:38:47,269 : INFO : 2
2017-05-04 02:38:47,269 : INFO : test percentage
2017-05-04 02:38:47,269 : INFO : 0.781987918726
2017-05-04 03:05:12,938 : INFO : ==> Train loss   : 5.160975
2017-05-04 03:05:12,938 : INFO : Epoch
2017-05-04 03:05:12,938 : INFO : 3
2017-05-04 03:05:12,938 : INFO : dev percentage
2017-05-04 03:05:12,938 : INFO : 0.780963302752
2017-05-04 03:05:12,939 : INFO : Epoch
2017-05-04 03:05:12,939 : INFO : 3
2017-05-04 03:05:12,939 : INFO : test percentage
2017-05-04 03:05:12,939 : INFO : 0.773750686436
2017-05-04 03:09:36,685 : INFO : LOG_FILE
2017-05-04 03:09:36,685 : INFO : _________________________________start___________________________________
2017-05-04 03:09:36,715 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=5e-05)
2017-05-04 03:09:36,822 : INFO : ==> SST vocabulary size : 21705
2017-05-04 03:09:42,444 : INFO : _param count_
2017-05-04 03:09:42,444 : INFO : torch.Size([21705, 300])
2017-05-04 03:09:42,445 : INFO : torch.Size([168, 300])
2017-05-04 03:09:42,445 : INFO : torch.Size([168])
2017-05-04 03:09:42,445 : INFO : torch.Size([168, 168])
2017-05-04 03:09:42,445 : INFO : torch.Size([168])
2017-05-04 03:09:42,445 : INFO : torch.Size([168, 300])
2017-05-04 03:09:42,445 : INFO : torch.Size([168])
2017-05-04 03:09:42,446 : INFO : torch.Size([168, 168])
2017-05-04 03:09:42,446 : INFO : torch.Size([168])
2017-05-04 03:09:42,446 : INFO : torch.Size([168, 300])
2017-05-04 03:09:42,446 : INFO : torch.Size([168])
2017-05-04 03:09:42,446 : INFO : torch.Size([168, 168])
2017-05-04 03:09:42,446 : INFO : torch.Size([168])
2017-05-04 03:09:42,446 : INFO : torch.Size([168, 300])
2017-05-04 03:09:42,447 : INFO : torch.Size([168])
2017-05-04 03:09:42,447 : INFO : torch.Size([168, 168])
2017-05-04 03:09:42,447 : INFO : torch.Size([168])
2017-05-04 03:09:42,447 : INFO : torch.Size([3, 168])
2017-05-04 03:09:42,447 : INFO : torch.Size([3])
2017-05-04 03:09:42,447 : INFO : sum
2017-05-04 03:09:42,447 : INFO : 316347
2017-05-04 03:09:42,448 : INFO : ____________
2017-05-04 03:23:44,580 : INFO : ==> Train loss   : 10.099113
2017-05-04 03:23:44,581 : INFO : Epoch
2017-05-04 03:23:44,583 : INFO : 0
2017-05-04 03:23:44,583 : INFO : dev percentage
2017-05-04 03:23:44,583 : INFO : 0.794724770642
2017-05-04 03:23:44,583 : INFO : Epoch
2017-05-04 03:23:44,583 : INFO : 0
2017-05-04 03:23:44,583 : INFO : test percentage
2017-05-04 03:23:44,583 : INFO : 0.80340472268
2017-05-04 03:37:36,137 : INFO : ==> Train loss   : 7.562848
2017-05-04 03:37:36,137 : INFO : Epoch
2017-05-04 03:37:36,137 : INFO : 1
2017-05-04 03:37:36,137 : INFO : dev percentage
2017-05-04 03:37:36,137 : INFO : 0.798165137615
2017-05-04 03:37:36,137 : INFO : Epoch
2017-05-04 03:37:36,137 : INFO : 1
2017-05-04 03:37:36,138 : INFO : test percentage
2017-05-04 03:37:36,138 : INFO : 0.812191103789
2017-05-04 03:51:06,531 : INFO : ==> Train loss   : 6.615690
2017-05-04 03:51:06,531 : INFO : Epoch
2017-05-04 03:51:06,531 : INFO : 2
2017-05-04 03:51:06,532 : INFO : dev percentage
2017-05-04 03:51:06,532 : INFO : 0.802752293578
2017-05-04 03:51:06,532 : INFO : Epoch
2017-05-04 03:51:06,532 : INFO : 2
2017-05-04 03:51:06,532 : INFO : test percentage
2017-05-04 03:51:06,532 : INFO : 0.801757276222
2017-05-04 04:04:37,015 : INFO : ==> Train loss   : 6.074832
2017-05-04 04:04:37,015 : INFO : Epoch
2017-05-04 04:04:37,017 : INFO : 3
2017-05-04 04:04:37,017 : INFO : dev percentage
2017-05-04 04:04:37,017 : INFO : 0.772935779817
2017-05-04 04:04:37,017 : INFO : Epoch
2017-05-04 04:04:37,017 : INFO : 3
2017-05-04 04:04:37,018 : INFO : test percentage
2017-05-04 04:04:37,018 : INFO : 0.795716639209
2017-05-04 04:18:06,991 : INFO : ==> Train loss   : 5.724350
2017-05-04 04:18:06,991 : INFO : Epoch
2017-05-04 04:18:06,991 : INFO : 4
2017-05-04 04:18:06,991 : INFO : dev percentage
2017-05-04 04:18:06,992 : INFO : 0.786697247706
2017-05-04 04:18:06,992 : INFO : Epoch
2017-05-04 04:18:06,992 : INFO : 4
2017-05-04 04:18:06,992 : INFO : test percentage
2017-05-04 04:18:06,992 : INFO : 0.788028555739
2017-05-04 04:31:33,336 : INFO : ==> Train loss   : 5.481237
2017-05-04 04:31:33,336 : INFO : Epoch
2017-05-04 04:31:33,336 : INFO : 5
2017-05-04 04:31:33,336 : INFO : dev percentage
2017-05-04 04:31:33,336 : INFO : 0.77752293578
2017-05-04 04:31:33,336 : INFO : Epoch
2017-05-04 04:31:33,337 : INFO : 5
2017-05-04 04:31:33,337 : INFO : test percentage
2017-05-04 04:31:33,337 : INFO : 0.779791323449
2017-05-04 04:44:53,386 : INFO : ==> Train loss   : 5.295741
2017-05-04 04:44:53,386 : INFO : Epoch
2017-05-04 04:44:53,387 : INFO : 6
2017-05-04 04:44:53,387 : INFO : dev percentage
2017-05-04 04:44:53,387 : INFO : 0.775229357798
2017-05-04 04:44:53,387 : INFO : Epoch
2017-05-04 04:44:53,387 : INFO : 6
2017-05-04 04:44:53,387 : INFO : test percentage
2017-05-04 04:44:53,387 : INFO : 0.786381109281
2017-05-04 04:58:17,826 : INFO : ==> Train loss   : 5.151600
2017-05-04 04:58:17,826 : INFO : Epoch
2017-05-04 04:58:17,827 : INFO : 7
2017-05-04 04:58:17,827 : INFO : dev percentage
2017-05-04 04:58:17,827 : INFO : 0.772935779817
2017-05-04 04:58:17,827 : INFO : Epoch
2017-05-04 04:58:17,827 : INFO : 7
2017-05-04 04:58:17,827 : INFO : test percentage
2017-05-04 04:58:17,827 : INFO : 0.774848984075
2017-05-04 05:11:48,796 : INFO : ==> Train loss   : 5.032896
2017-05-04 05:11:48,796 : INFO : Epoch
2017-05-04 05:11:48,796 : INFO : 8
2017-05-04 05:11:48,796 : INFO : dev percentage
2017-05-04 05:11:48,797 : INFO : 0.778669724771
2017-05-04 05:11:48,797 : INFO : Epoch
2017-05-04 05:11:48,797 : INFO : 8
2017-05-04 05:11:48,797 : INFO : test percentage
2017-05-04 05:11:48,797 : INFO : 0.781987918726
2017-05-04 05:25:17,197 : INFO : ==> Train loss   : 4.955141
2017-05-04 05:25:17,197 : INFO : Epoch
2017-05-04 05:25:17,198 : INFO : 9
2017-05-04 05:25:17,198 : INFO : dev percentage
2017-05-04 05:25:17,198 : INFO : 0.772935779817
2017-05-04 05:25:17,198 : INFO : Epoch
2017-05-04 05:25:17,198 : INFO : 9
2017-05-04 05:25:17,198 : INFO : test percentage
2017-05-04 05:25:17,198 : INFO : 0.784733662823
2017-05-04 05:38:44,151 : INFO : ==> Train loss   : 4.882662
2017-05-04 05:38:44,151 : INFO : Epoch
2017-05-04 05:38:44,151 : INFO : 10
2017-05-04 05:38:44,151 : INFO : dev percentage
2017-05-04 05:38:44,151 : INFO : 0.775229357798
2017-05-04 05:38:44,151 : INFO : Epoch
2017-05-04 05:38:44,151 : INFO : 10
2017-05-04 05:38:44,151 : INFO : test percentage
2017-05-04 05:38:44,152 : INFO : 0.783086216365
2017-05-04 05:52:12,873 : INFO : ==> Train loss   : 4.847219
2017-05-04 05:52:12,874 : INFO : Epoch
2017-05-04 05:52:12,874 : INFO : 11
2017-05-04 05:52:12,874 : INFO : dev percentage
2017-05-04 05:52:12,874 : INFO : 0.772935779817
2017-05-04 05:52:12,874 : INFO : Epoch
2017-05-04 05:52:12,874 : INFO : 11
2017-05-04 05:52:12,874 : INFO : test percentage
2017-05-04 05:52:12,874 : INFO : 0.780889621087
2017-05-04 06:05:42,610 : INFO : ==> Train loss   : 4.795444
2017-05-04 06:05:42,610 : INFO : Epoch
2017-05-04 06:05:42,610 : INFO : 12
2017-05-04 06:05:42,611 : INFO : dev percentage
2017-05-04 06:05:42,611 : INFO : 0.776376146789
2017-05-04 06:05:42,611 : INFO : Epoch
2017-05-04 06:05:42,611 : INFO : 12
2017-05-04 06:05:42,611 : INFO : test percentage
2017-05-04 06:05:42,611 : INFO : 0.784733662823
2017-05-04 06:19:12,467 : INFO : ==> Train loss   : 4.746472
2017-05-04 06:19:12,467 : INFO : Epoch
2017-05-04 06:19:12,468 : INFO : 13
2017-05-04 06:19:12,468 : INFO : dev percentage
2017-05-04 06:19:12,468 : INFO : 0.767201834862
2017-05-04 06:19:12,468 : INFO : Epoch
2017-05-04 06:19:12,468 : INFO : 13
2017-05-04 06:19:12,468 : INFO : test percentage
2017-05-04 06:19:12,468 : INFO : 0.782537067545
2017-05-04 06:32:44,266 : INFO : ==> Train loss   : 4.708991
2017-05-04 06:32:44,266 : INFO : Epoch
2017-05-04 06:32:44,266 : INFO : 14
2017-05-04 06:32:44,266 : INFO : dev percentage
2017-05-04 06:32:44,266 : INFO : 0.779816513761
2017-05-04 06:32:44,266 : INFO : Epoch
2017-05-04 06:32:44,267 : INFO : 14
2017-05-04 06:32:44,267 : INFO : test percentage
2017-05-04 06:32:44,267 : INFO : 0.774299835255
2017-05-04 06:46:16,304 : INFO : ==> Train loss   : 4.669028
2017-05-04 06:46:16,304 : INFO : Epoch
2017-05-04 06:46:16,304 : INFO : 15
2017-05-04 06:46:16,304 : INFO : dev percentage
2017-05-04 06:46:16,304 : INFO : 0.774082568807
2017-05-04 06:46:16,304 : INFO : Epoch
2017-05-04 06:46:16,304 : INFO : 15
2017-05-04 06:46:16,304 : INFO : test percentage
2017-05-04 06:46:16,305 : INFO : 0.775947281713
2017-05-04 06:59:48,547 : INFO : ==> Train loss   : 4.650626
2017-05-04 06:59:48,547 : INFO : Epoch
2017-05-04 06:59:48,547 : INFO : 16
2017-05-04 06:59:48,547 : INFO : dev percentage
2017-05-04 06:59:48,547 : INFO : 0.774082568807
2017-05-04 06:59:48,547 : INFO : Epoch
2017-05-04 06:59:48,547 : INFO : 16
2017-05-04 06:59:48,548 : INFO : test percentage
2017-05-04 06:59:48,548 : INFO : 0.774299835255
2017-05-04 07:13:13,983 : INFO : ==> Train loss   : 4.607530
2017-05-04 07:13:13,984 : INFO : Epoch
2017-05-04 07:13:13,984 : INFO : 17
2017-05-04 07:13:13,984 : INFO : dev percentage
2017-05-04 07:13:13,984 : INFO : 0.779816513761
2017-05-04 07:13:13,984 : INFO : Epoch
2017-05-04 07:13:13,984 : INFO : 17
2017-05-04 07:13:13,984 : INFO : test percentage
2017-05-04 07:13:13,984 : INFO : 0.772103239978
2017-05-04 07:26:35,897 : INFO : ==> Train loss   : 4.587785
2017-05-04 07:26:35,897 : INFO : Epoch
2017-05-04 07:26:35,897 : INFO : 18
2017-05-04 07:26:35,897 : INFO : dev percentage
2017-05-04 07:26:35,897 : INFO : 0.766055045872
2017-05-04 07:26:35,897 : INFO : Epoch
2017-05-04 07:26:35,897 : INFO : 18
2017-05-04 07:26:35,897 : INFO : test percentage
2017-05-04 07:26:35,898 : INFO : 0.765513454146
2017-05-04 07:39:56,898 : INFO : ==> Train loss   : 4.608520
2017-05-04 07:39:56,898 : INFO : Epoch
2017-05-04 07:39:56,899 : INFO : 19
2017-05-04 07:39:56,899 : INFO : dev percentage
2017-05-04 07:39:56,899 : INFO : 0.770642201835
2017-05-04 07:39:56,899 : INFO : Epoch
2017-05-04 07:39:56,899 : INFO : 19
2017-05-04 07:39:56,899 : INFO : test percentage
2017-05-04 07:39:56,899 : INFO : 0.769906644701
2017-05-04 07:53:27,744 : INFO : ==> Train loss   : 4.588335
2017-05-04 07:53:27,745 : INFO : Epoch
2017-05-04 07:53:27,745 : INFO : 20
2017-05-04 07:53:27,745 : INFO : dev percentage
2017-05-04 07:53:27,745 : INFO : 0.770642201835
2017-05-04 07:53:27,745 : INFO : Epoch
2017-05-04 07:53:27,745 : INFO : 20
2017-05-04 07:53:27,745 : INFO : test percentage
2017-05-04 07:53:27,746 : INFO : 0.767160900604
2017-05-04 08:07:02,128 : INFO : ==> Train loss   : 4.558626
2017-05-04 08:07:02,128 : INFO : Epoch
2017-05-04 08:07:02,128 : INFO : 21
2017-05-04 08:07:02,128 : INFO : dev percentage
2017-05-04 08:07:02,128 : INFO : 0.766055045872
2017-05-04 08:07:02,129 : INFO : Epoch
2017-05-04 08:07:02,129 : INFO : 21
2017-05-04 08:07:02,129 : INFO : test percentage
2017-05-04 08:07:02,129 : INFO : 0.767710049423
2017-05-04 08:20:29,238 : INFO : ==> Train loss   : 4.536865
2017-05-04 08:20:29,238 : INFO : Epoch
2017-05-04 08:20:29,239 : INFO : 22
2017-05-04 08:20:29,239 : INFO : dev percentage
2017-05-04 08:20:29,239 : INFO : 0.768348623853
2017-05-04 08:20:29,239 : INFO : Epoch
2017-05-04 08:20:29,239 : INFO : 22
2017-05-04 08:20:29,239 : INFO : test percentage
2017-05-04 08:20:29,239 : INFO : 0.766611751785
2017-05-04 08:33:51,289 : INFO : ==> Train loss   : 4.523031
2017-05-04 08:33:51,289 : INFO : Epoch
2017-05-04 08:33:51,289 : INFO : 23
2017-05-04 08:33:51,289 : INFO : dev percentage
2017-05-04 08:33:51,290 : INFO : 0.768348623853
2017-05-04 08:33:51,290 : INFO : Epoch
2017-05-04 08:33:51,290 : INFO : 23
2017-05-04 08:33:51,290 : INFO : test percentage
2017-05-04 08:33:51,290 : INFO : 0.768808347062
2017-05-04 08:47:18,705 : INFO : ==> Train loss   : 4.497836
2017-05-04 08:47:18,706 : INFO : Epoch
2017-05-04 08:47:18,706 : INFO : 24
2017-05-04 08:47:18,706 : INFO : dev percentage
2017-05-04 08:47:18,706 : INFO : 0.776376146789
2017-05-04 08:47:18,706 : INFO : Epoch
2017-05-04 08:47:18,706 : INFO : 24
2017-05-04 08:47:18,706 : INFO : test percentage
2017-05-04 08:47:18,707 : INFO : 0.760571114772
2017-05-04 09:00:44,376 : INFO : ==> Train loss   : 4.494974
2017-05-04 09:00:44,376 : INFO : Epoch
2017-05-04 09:00:44,376 : INFO : 25
2017-05-04 09:00:44,377 : INFO : dev percentage
2017-05-04 09:00:44,377 : INFO : 0.775229357798
2017-05-04 09:00:44,377 : INFO : Epoch
2017-05-04 09:00:44,377 : INFO : 25
2017-05-04 09:00:44,377 : INFO : test percentage
2017-05-04 09:00:44,377 : INFO : 0.767710049423
2017-05-04 09:14:07,989 : INFO : ==> Train loss   : 4.475430
2017-05-04 09:14:07,990 : INFO : Epoch
2017-05-04 09:14:07,990 : INFO : 26
2017-05-04 09:14:07,990 : INFO : dev percentage
2017-05-04 09:14:07,990 : INFO : 0.77752293578
2017-05-04 09:14:07,990 : INFO : Epoch
2017-05-04 09:14:07,990 : INFO : 26
2017-05-04 09:14:07,990 : INFO : test percentage
2017-05-04 09:14:07,991 : INFO : 0.766062602965
2017-05-04 09:27:34,004 : INFO : ==> Train loss   : 4.471067
2017-05-04 09:27:34,005 : INFO : Epoch
2017-05-04 09:27:34,005 : INFO : 27
2017-05-04 09:27:34,005 : INFO : dev percentage
2017-05-04 09:27:34,005 : INFO : 0.772935779817
2017-05-04 09:27:34,005 : INFO : Epoch
2017-05-04 09:27:34,005 : INFO : 27
2017-05-04 09:27:34,006 : INFO : test percentage
2017-05-04 09:27:34,006 : INFO : 0.762767710049
2017-05-04 09:41:03,500 : INFO : ==> Train loss   : 4.457366
2017-05-04 09:41:03,501 : INFO : Epoch
2017-05-04 09:41:03,501 : INFO : 28
2017-05-04 09:41:03,501 : INFO : dev percentage
2017-05-04 09:41:03,501 : INFO : 0.768348623853
2017-05-04 09:41:03,501 : INFO : Epoch
2017-05-04 09:41:03,501 : INFO : 28
2017-05-04 09:41:03,501 : INFO : test percentage
2017-05-04 09:41:03,501 : INFO : 0.768259198243
2017-05-04 09:54:31,571 : INFO : ==> Train loss   : 4.450541
2017-05-04 09:54:31,571 : INFO : Epoch
2017-05-04 09:54:31,571 : INFO : 29
2017-05-04 09:54:31,571 : INFO : dev percentage
2017-05-04 09:54:31,571 : INFO : 0.76376146789
2017-05-04 09:54:31,571 : INFO : Epoch
2017-05-04 09:54:31,572 : INFO : 29
2017-05-04 09:54:31,572 : INFO : test percentage
2017-05-04 09:54:31,572 : INFO : 0.767160900604
2017-05-04 10:08:00,899 : INFO : ==> Train loss   : 4.434891
2017-05-04 10:08:00,900 : INFO : Epoch
2017-05-04 10:08:00,900 : INFO : 30
2017-05-04 10:08:00,900 : INFO : dev percentage
2017-05-04 10:08:00,900 : INFO : 0.771788990826
2017-05-04 10:08:00,900 : INFO : Epoch
2017-05-04 10:08:00,900 : INFO : 30
2017-05-04 10:08:00,900 : INFO : test percentage
2017-05-04 10:08:00,900 : INFO : 0.766611751785
2017-05-04 10:26:33,085 : INFO : LOG_FILE
2017-05-04 10:26:33,085 : INFO : _________________________________start___________________________________
2017-05-04 10:26:33,114 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=5e-05)
2017-05-04 10:26:33,222 : INFO : ==> SST vocabulary size : 21705
2017-05-04 10:26:38,791 : INFO : _param count_
2017-05-04 10:26:38,791 : INFO : torch.Size([21705, 300])
2017-05-04 10:26:38,792 : INFO : torch.Size([168, 300])
2017-05-04 10:26:38,792 : INFO : torch.Size([168])
2017-05-04 10:26:38,792 : INFO : torch.Size([168, 168])
2017-05-04 10:26:38,792 : INFO : torch.Size([168])
2017-05-04 10:26:38,792 : INFO : torch.Size([168, 300])
2017-05-04 10:26:38,792 : INFO : torch.Size([168])
2017-05-04 10:26:38,792 : INFO : torch.Size([168, 168])
2017-05-04 10:26:38,793 : INFO : torch.Size([168])
2017-05-04 10:26:38,793 : INFO : torch.Size([168, 300])
2017-05-04 10:26:38,793 : INFO : torch.Size([168])
2017-05-04 10:26:38,793 : INFO : torch.Size([168, 168])
2017-05-04 10:26:38,793 : INFO : torch.Size([168])
2017-05-04 10:26:38,793 : INFO : torch.Size([168, 300])
2017-05-04 10:26:38,794 : INFO : torch.Size([168])
2017-05-04 10:26:38,794 : INFO : torch.Size([168, 168])
2017-05-04 10:26:38,794 : INFO : torch.Size([168])
2017-05-04 10:26:38,794 : INFO : torch.Size([3, 168])
2017-05-04 10:26:38,794 : INFO : torch.Size([3])
2017-05-04 10:26:38,794 : INFO : sum
2017-05-04 10:26:38,794 : INFO : 316347
2017-05-04 10:26:38,795 : INFO : ____________
2017-05-04 10:41:17,072 : INFO : ==> Train loss   : 9.545333
2017-05-04 10:41:17,073 : INFO : Epoch
2017-05-04 10:41:17,073 : INFO : 0
2017-05-04 10:41:17,073 : INFO : dev percentage
2017-05-04 10:41:17,073 : INFO : 0.790137614679
2017-05-04 10:41:17,073 : INFO : Epoch
2017-05-04 10:41:17,073 : INFO : 0
2017-05-04 10:41:17,073 : INFO : test percentage
2017-05-04 10:41:17,074 : INFO : 0.79516749039
2017-05-04 10:42:44,773 : INFO : LOG_FILE
2017-05-04 10:42:44,774 : INFO : _________________________________start___________________________________
2017-05-04 10:42:44,792 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=5e-05)
2017-05-04 10:42:45,116 : INFO : ==> SST vocabulary size : 21705
2017-05-04 10:42:51,241 : INFO : _param count_
2017-05-04 10:42:51,243 : INFO : torch.Size([21705, 300])
2017-05-04 10:42:51,244 : INFO : torch.Size([168, 300])
2017-05-04 10:42:51,245 : INFO : torch.Size([168])
2017-05-04 10:42:51,245 : INFO : torch.Size([168, 168])
2017-05-04 10:42:51,246 : INFO : torch.Size([168])
2017-05-04 10:42:51,246 : INFO : torch.Size([168, 300])
2017-05-04 10:42:51,247 : INFO : torch.Size([168])
2017-05-04 10:42:51,248 : INFO : torch.Size([168, 168])
2017-05-04 10:42:51,248 : INFO : torch.Size([168])
2017-05-04 10:42:51,249 : INFO : torch.Size([168, 300])
2017-05-04 10:42:51,249 : INFO : torch.Size([168])
2017-05-04 10:42:51,250 : INFO : torch.Size([168, 168])
2017-05-04 10:42:51,250 : INFO : torch.Size([168])
2017-05-04 10:42:51,251 : INFO : torch.Size([168, 300])
2017-05-04 10:42:51,251 : INFO : torch.Size([168])
2017-05-04 10:42:51,252 : INFO : torch.Size([168, 168])
2017-05-04 10:42:51,253 : INFO : torch.Size([168])
2017-05-04 10:42:51,253 : INFO : torch.Size([3, 168])
2017-05-04 10:42:51,254 : INFO : torch.Size([3])
2017-05-04 10:42:51,255 : INFO : sum
2017-05-04 10:42:51,256 : INFO : 316347
2017-05-04 10:42:51,256 : INFO : ____________
2017-05-04 10:55:51,945 : INFO : ==> Train loss   : 7.499290
2017-05-04 10:55:51,945 : INFO : Epoch
2017-05-04 10:55:51,946 : INFO : 1
2017-05-04 10:55:51,946 : INFO : dev percentage
2017-05-04 10:55:51,946 : INFO : 0.798165137615
2017-05-04 10:55:51,946 : INFO : Epoch
2017-05-04 10:55:51,946 : INFO : 1
2017-05-04 10:55:51,946 : INFO : test percentage
2017-05-04 10:55:51,946 : INFO : 0.816584294344
2017-05-04 11:10:12,268 : INFO : ==> Train loss   : 6.530951
2017-05-04 11:10:12,268 : INFO : Epoch
2017-05-04 11:10:12,268 : INFO : 2
2017-05-04 11:10:12,268 : INFO : dev percentage
2017-05-04 11:10:12,268 : INFO : 0.801605504587
2017-05-04 11:10:12,268 : INFO : Epoch
2017-05-04 11:10:12,269 : INFO : 2
2017-05-04 11:10:12,269 : INFO : test percentage
2017-05-04 11:10:12,269 : INFO : 0.80340472268
2017-05-04 11:20:48,256 : INFO : LOG_FILE
2017-05-04 11:20:48,256 : INFO : _________________________________start___________________________________
2017-05-04 11:20:48,262 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=5e-05)
2017-05-04 11:20:48,370 : INFO : ==> SST vocabulary size : 21705
2017-05-04 11:20:54,163 : INFO : _param count_
2017-05-04 11:20:54,163 : INFO : torch.Size([21705, 300])
2017-05-04 11:20:54,163 : INFO : torch.Size([168, 300])
2017-05-04 11:20:54,164 : INFO : torch.Size([168])
2017-05-04 11:20:54,164 : INFO : torch.Size([168, 168])
2017-05-04 11:20:54,164 : INFO : torch.Size([168])
2017-05-04 11:20:54,164 : INFO : torch.Size([168, 300])
2017-05-04 11:20:54,164 : INFO : torch.Size([168])
2017-05-04 11:20:54,164 : INFO : torch.Size([168, 168])
2017-05-04 11:20:54,164 : INFO : torch.Size([168])
2017-05-04 11:20:54,165 : INFO : torch.Size([168, 300])
2017-05-04 11:20:54,165 : INFO : torch.Size([168])
2017-05-04 11:20:54,165 : INFO : torch.Size([168, 168])
2017-05-04 11:20:54,165 : INFO : torch.Size([168])
2017-05-04 11:20:54,165 : INFO : torch.Size([3, 168])
2017-05-04 11:20:54,165 : INFO : torch.Size([3])
2017-05-04 11:20:54,165 : INFO : sum
2017-05-04 11:20:54,166 : INFO : 237387
2017-05-04 11:20:54,166 : INFO : ____________
2017-05-04 11:22:25,666 : INFO : LOG_FILE
2017-05-04 11:22:25,666 : INFO : _________________________________start___________________________________
2017-05-04 11:22:25,673 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=5e-05)
2017-05-04 11:22:25,785 : INFO : ==> SST vocabulary size : 21705
2017-05-04 11:22:31,395 : INFO : _param count_
2017-05-04 11:22:31,396 : INFO : torch.Size([21705, 300])
2017-05-04 11:22:31,396 : INFO : torch.Size([168, 300])
2017-05-04 11:22:31,396 : INFO : torch.Size([168])
2017-05-04 11:22:31,396 : INFO : torch.Size([168, 168])
2017-05-04 11:22:31,396 : INFO : torch.Size([168])
2017-05-04 11:22:31,396 : INFO : torch.Size([168, 300])
2017-05-04 11:22:31,396 : INFO : torch.Size([168])
2017-05-04 11:22:31,397 : INFO : torch.Size([168, 168])
2017-05-04 11:22:31,397 : INFO : torch.Size([168])
2017-05-04 11:22:31,397 : INFO : torch.Size([168, 300])
2017-05-04 11:22:31,397 : INFO : torch.Size([168])
2017-05-04 11:22:31,397 : INFO : torch.Size([168, 168])
2017-05-04 11:22:31,397 : INFO : torch.Size([168])
2017-05-04 11:22:31,397 : INFO : torch.Size([3, 168])
2017-05-04 11:22:31,398 : INFO : torch.Size([3])
2017-05-04 11:22:31,398 : INFO : sum
2017-05-04 11:22:31,398 : INFO : 237387
2017-05-04 11:22:31,398 : INFO : ____________
2017-05-04 11:26:00,146 : INFO : ==> Train loss   : 11.873843
2017-05-04 11:26:00,146 : INFO : Epoch
2017-05-04 11:26:00,146 : INFO : 0
2017-05-04 11:26:00,146 : INFO : dev percentage
2017-05-04 11:26:00,147 : INFO : 0.825688073394
2017-05-04 11:26:00,147 : INFO : Epoch
2017-05-04 11:26:00,147 : INFO : 0
2017-05-04 11:26:00,147 : INFO : test percentage
2017-05-04 11:26:00,147 : INFO : 0.701812191104
2017-05-04 11:29:25,774 : INFO : ==> Train loss   : 8.285907
2017-05-04 11:29:25,774 : INFO : Epoch
2017-05-04 11:29:25,774 : INFO : 1
2017-05-04 11:29:25,774 : INFO : dev percentage
2017-05-04 11:29:25,774 : INFO : 0.948394495413
2017-05-04 11:29:25,774 : INFO : Epoch
2017-05-04 11:29:25,774 : INFO : 1
2017-05-04 11:29:25,774 : INFO : test percentage
2017-05-04 11:29:25,775 : INFO : 0.750137287205
2017-05-04 11:32:52,153 : INFO : ==> Train loss   : 6.428447
2017-05-04 11:32:52,153 : INFO : Epoch
2017-05-04 11:32:52,153 : INFO : 2
2017-05-04 11:32:52,154 : INFO : dev percentage
2017-05-04 11:32:52,154 : INFO : 0.977064220183
2017-05-04 11:32:52,154 : INFO : Epoch
2017-05-04 11:32:52,154 : INFO : 2
2017-05-04 11:32:52,154 : INFO : test percentage
2017-05-04 11:32:52,154 : INFO : 0.724327292696
2017-05-04 11:36:18,647 : INFO : ==> Train loss   : 5.432369
2017-05-04 11:36:18,647 : INFO : Epoch
2017-05-04 11:36:18,647 : INFO : 3
2017-05-04 11:36:18,648 : INFO : dev percentage
2017-05-04 11:36:18,648 : INFO : 0.991972477064
2017-05-04 11:36:18,648 : INFO : Epoch
2017-05-04 11:36:18,648 : INFO : 3
2017-05-04 11:36:18,648 : INFO : test percentage
2017-05-04 11:36:18,648 : INFO : 0.727622185612
2017-05-04 11:39:42,853 : INFO : ==> Train loss   : 5.003665
2017-05-04 11:39:42,853 : INFO : Epoch
2017-05-04 11:39:42,853 : INFO : 4
2017-05-04 11:39:42,853 : INFO : dev percentage
2017-05-04 11:39:42,853 : INFO : 0.994266055046
2017-05-04 11:39:42,853 : INFO : Epoch
2017-05-04 11:39:42,853 : INFO : 4
2017-05-04 11:39:42,853 : INFO : test percentage
2017-05-04 11:39:42,854 : INFO : 0.725425590335
2017-05-04 11:43:09,781 : INFO : ==> Train loss   : 4.740399
2017-05-04 11:43:09,781 : INFO : Epoch
2017-05-04 11:43:09,782 : INFO : 5
2017-05-04 11:43:09,782 : INFO : dev percentage
2017-05-04 11:43:09,782 : INFO : 0.996559633028
2017-05-04 11:43:09,782 : INFO : Epoch
2017-05-04 11:43:09,782 : INFO : 5
2017-05-04 11:43:09,782 : INFO : test percentage
2017-05-04 11:43:09,782 : INFO : 0.709500274574
2017-05-04 11:46:36,985 : INFO : ==> Train loss   : 4.515411
2017-05-04 11:46:36,985 : INFO : Epoch
2017-05-04 11:46:36,985 : INFO : 6
2017-05-04 11:46:36,985 : INFO : dev percentage
2017-05-04 11:46:36,985 : INFO : 0.998853211009
2017-05-04 11:46:36,985 : INFO : Epoch
2017-05-04 11:46:36,985 : INFO : 6
2017-05-04 11:46:36,986 : INFO : test percentage
2017-05-04 11:46:36,986 : INFO : 0.718835804503
2017-05-04 11:50:02,976 : INFO : ==> Train loss   : 4.321506
2017-05-04 11:50:02,976 : INFO : Epoch
2017-05-04 11:50:02,976 : INFO : 7
2017-05-04 11:50:02,976 : INFO : dev percentage
2017-05-04 11:50:02,976 : INFO : 0.998853211009
2017-05-04 11:50:02,976 : INFO : Epoch
2017-05-04 11:50:02,976 : INFO : 7
2017-05-04 11:50:02,976 : INFO : test percentage
2017-05-04 11:50:02,977 : INFO : 0.72926963207
2017-05-04 11:53:31,346 : INFO : ==> Train loss   : 4.232302
2017-05-04 11:53:31,347 : INFO : Epoch
2017-05-04 11:53:31,347 : INFO : 8
2017-05-04 11:53:31,347 : INFO : dev percentage
2017-05-04 11:53:31,347 : INFO : 1.0
2017-05-04 11:53:31,347 : INFO : Epoch
2017-05-04 11:53:31,347 : INFO : 8
2017-05-04 11:53:31,347 : INFO : test percentage
2017-05-04 11:53:31,347 : INFO : 0.728720483251
2017-05-04 11:57:00,114 : INFO : ==> Train loss   : 4.142436
2017-05-04 11:57:00,114 : INFO : Epoch
2017-05-04 11:57:00,114 : INFO : 9
2017-05-04 11:57:00,114 : INFO : dev percentage
2017-05-04 11:57:00,114 : INFO : 1.0
2017-05-04 11:57:00,115 : INFO : Epoch
2017-05-04 11:57:00,115 : INFO : 9
2017-05-04 11:57:00,115 : INFO : test percentage
2017-05-04 11:57:00,115 : INFO : 0.724876441516
2017-05-04 12:00:32,958 : INFO : ==> Train loss   : 4.079235
2017-05-04 12:00:32,958 : INFO : Epoch
2017-05-04 12:00:32,959 : INFO : 10
2017-05-04 12:00:32,959 : INFO : dev percentage
2017-05-04 12:00:32,959 : INFO : 1.0
2017-05-04 12:00:32,959 : INFO : Epoch
2017-05-04 12:00:32,959 : INFO : 10
2017-05-04 12:00:32,959 : INFO : test percentage
2017-05-04 12:00:32,959 : INFO : 0.724327292696
2017-05-04 12:04:05,185 : INFO : ==> Train loss   : 4.033521
2017-05-04 12:04:05,185 : INFO : Epoch
2017-05-04 12:04:05,185 : INFO : 11
2017-05-04 12:04:05,185 : INFO : dev percentage
2017-05-04 12:04:05,185 : INFO : 1.0
2017-05-04 12:04:05,185 : INFO : Epoch
2017-05-04 12:04:05,186 : INFO : 11
2017-05-04 12:04:05,186 : INFO : test percentage
2017-05-04 12:04:05,186 : INFO : 0.724876441516
2017-05-04 12:07:35,189 : INFO : ==> Train loss   : 3.998123
2017-05-04 12:07:35,190 : INFO : Epoch
2017-05-04 12:07:35,190 : INFO : 12
2017-05-04 12:07:35,190 : INFO : dev percentage
2017-05-04 12:07:35,190 : INFO : 1.0
2017-05-04 12:07:35,190 : INFO : Epoch
2017-05-04 12:07:35,190 : INFO : 12
2017-05-04 12:07:35,190 : INFO : test percentage
2017-05-04 12:07:35,190 : INFO : 0.724876441516
2017-05-04 12:10:10,061 : INFO : LOG_FILE
2017-05-04 12:10:10,062 : INFO : _________________________________start___________________________________
2017-05-04 12:10:10,094 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=5e-05)
2017-05-04 12:10:10,390 : INFO : ==> SST vocabulary size : 21705
2017-05-04 12:10:16,534 : INFO : _param count_
2017-05-04 12:10:16,537 : INFO : torch.Size([21705, 300])
2017-05-04 12:10:16,537 : INFO : torch.Size([168, 300])
2017-05-04 12:10:16,538 : INFO : torch.Size([168])
2017-05-04 12:10:16,539 : INFO : torch.Size([168, 168])
2017-05-04 12:10:16,539 : INFO : torch.Size([168])
2017-05-04 12:10:16,540 : INFO : torch.Size([168, 300])
2017-05-04 12:10:16,540 : INFO : torch.Size([168])
2017-05-04 12:10:16,541 : INFO : torch.Size([168, 168])
2017-05-04 12:10:16,542 : INFO : torch.Size([168])
2017-05-04 12:10:16,542 : INFO : torch.Size([168, 300])
2017-05-04 12:10:16,543 : INFO : torch.Size([168])
2017-05-04 12:10:16,543 : INFO : torch.Size([168, 168])
2017-05-04 12:10:16,544 : INFO : torch.Size([168])
2017-05-04 12:10:16,544 : INFO : torch.Size([168, 168, 1])
2017-05-04 12:10:16,545 : INFO : torch.Size([168])
2017-05-04 12:10:16,546 : INFO : torch.Size([168, 168])
2017-05-04 12:10:16,546 : INFO : torch.Size([168])
2017-05-04 12:10:16,547 : INFO : torch.Size([3, 168])
2017-05-04 12:10:16,547 : INFO : torch.Size([3])
2017-05-04 12:10:16,548 : INFO : sum
2017-05-04 12:10:16,549 : INFO : 294171
2017-05-04 12:10:16,549 : INFO : ____________
2017-05-04 12:11:57,566 : INFO : LOG_FILE
2017-05-04 12:11:57,567 : INFO : _________________________________start___________________________________
2017-05-04 12:11:57,607 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=5e-05)
2017-05-04 12:11:57,912 : INFO : ==> SST vocabulary size : 21705
2017-05-04 12:12:03,971 : INFO : _param count_
2017-05-04 12:12:03,973 : INFO : torch.Size([21705, 300])
2017-05-04 12:12:03,974 : INFO : torch.Size([168, 300])
2017-05-04 12:12:03,974 : INFO : torch.Size([168])
2017-05-04 12:12:03,975 : INFO : torch.Size([168, 168])
2017-05-04 12:12:03,975 : INFO : torch.Size([168])
2017-05-04 12:12:03,976 : INFO : torch.Size([168, 300])
2017-05-04 12:12:03,977 : INFO : torch.Size([168])
2017-05-04 12:12:03,977 : INFO : torch.Size([168, 168])
2017-05-04 12:12:03,978 : INFO : torch.Size([168])
2017-05-04 12:12:03,978 : INFO : torch.Size([168, 300])
2017-05-04 12:12:03,979 : INFO : torch.Size([168])
2017-05-04 12:12:03,979 : INFO : torch.Size([168, 168])
2017-05-04 12:12:03,980 : INFO : torch.Size([168])
2017-05-04 12:12:03,980 : INFO : torch.Size([168, 168, 1])
2017-05-04 12:12:03,981 : INFO : torch.Size([168])
2017-05-04 12:12:03,981 : INFO : torch.Size([168, 168])
2017-05-04 12:12:03,982 : INFO : torch.Size([168])
2017-05-04 12:12:03,983 : INFO : torch.Size([3, 168])
2017-05-04 12:12:03,983 : INFO : torch.Size([3])
2017-05-04 12:12:03,984 : INFO : sum
2017-05-04 12:12:03,984 : INFO : 294171
2017-05-04 12:12:03,985 : INFO : ____________
2017-05-04 12:13:51,407 : INFO : LOG_FILE
2017-05-04 12:13:51,408 : INFO : _________________________________start___________________________________
2017-05-04 12:13:51,441 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=5e-05)
2017-05-04 12:13:51,734 : INFO : ==> SST vocabulary size : 21705
2017-05-04 12:13:57,675 : INFO : _param count_
2017-05-04 12:13:57,677 : INFO : torch.Size([21705, 300])
2017-05-04 12:13:57,678 : INFO : torch.Size([168, 300])
2017-05-04 12:13:57,679 : INFO : torch.Size([168])
2017-05-04 12:13:57,679 : INFO : torch.Size([168, 168])
2017-05-04 12:13:57,680 : INFO : torch.Size([168])
2017-05-04 12:13:57,680 : INFO : torch.Size([168, 300])
2017-05-04 12:13:57,681 : INFO : torch.Size([168])
2017-05-04 12:13:57,681 : INFO : torch.Size([168, 168])
2017-05-04 12:13:57,682 : INFO : torch.Size([168])
2017-05-04 12:13:57,683 : INFO : torch.Size([168, 300])
2017-05-04 12:13:57,683 : INFO : torch.Size([168])
2017-05-04 12:13:57,684 : INFO : torch.Size([168, 168])
2017-05-04 12:13:57,684 : INFO : torch.Size([168])
2017-05-04 12:13:57,685 : INFO : torch.Size([168, 168, 1])
2017-05-04 12:13:57,685 : INFO : torch.Size([168])
2017-05-04 12:13:57,686 : INFO : torch.Size([168, 168])
2017-05-04 12:13:57,686 : INFO : torch.Size([168])
2017-05-04 12:13:57,687 : INFO : torch.Size([3, 168])
2017-05-04 12:13:57,688 : INFO : torch.Size([3])
2017-05-04 12:13:57,688 : INFO : sum
2017-05-04 12:13:57,689 : INFO : 294171
2017-05-04 12:13:57,689 : INFO : ____________
2017-05-04 12:15:40,705 : INFO : LOG_FILE
2017-05-04 12:15:40,706 : INFO : _________________________________start___________________________________
2017-05-04 12:15:40,741 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=5e-05)
2017-05-04 12:15:41,038 : INFO : ==> SST vocabulary size : 21705
2017-05-04 12:15:47,240 : INFO : _param count_
2017-05-04 12:15:47,243 : INFO : torch.Size([21705, 300])
2017-05-04 12:15:47,243 : INFO : torch.Size([168, 300])
2017-05-04 12:15:47,244 : INFO : torch.Size([168])
2017-05-04 12:15:47,244 : INFO : torch.Size([168, 168])
2017-05-04 12:15:47,245 : INFO : torch.Size([168])
2017-05-04 12:15:47,246 : INFO : torch.Size([168, 300])
2017-05-04 12:15:47,246 : INFO : torch.Size([168])
2017-05-04 12:15:47,247 : INFO : torch.Size([168, 168])
2017-05-04 12:15:47,247 : INFO : torch.Size([168])
2017-05-04 12:15:47,248 : INFO : torch.Size([168, 300])
2017-05-04 12:15:47,248 : INFO : torch.Size([168])
2017-05-04 12:15:47,249 : INFO : torch.Size([168, 168])
2017-05-04 12:15:47,250 : INFO : torch.Size([168])
2017-05-04 12:15:47,250 : INFO : torch.Size([168, 168, 1])
2017-05-04 12:15:47,251 : INFO : torch.Size([168])
2017-05-04 12:15:47,251 : INFO : torch.Size([168, 168])
2017-05-04 12:15:47,252 : INFO : torch.Size([168])
2017-05-04 12:15:47,252 : INFO : torch.Size([3, 168])
2017-05-04 12:15:47,253 : INFO : torch.Size([3])
2017-05-04 12:15:47,253 : INFO : sum
2017-05-04 12:15:47,254 : INFO : 294171
2017-05-04 12:15:47,255 : INFO : ____________
2017-05-04 12:16:22,233 : INFO : LOG_FILE
2017-05-04 12:16:22,233 : INFO : _________________________________start___________________________________
2017-05-04 12:16:22,241 : INFO : Namespace(batchsize=25, cuda=False, data='data/sst/', epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=5e-05)
2017-05-04 12:16:22,552 : INFO : ==> SST vocabulary size : 21705
2017-05-04 12:16:26,354 : INFO : _param count_
2017-05-04 12:16:26,358 : INFO : torch.Size([21705, 300])
2017-05-04 12:16:26,359 : INFO : torch.Size([168, 300])
2017-05-04 12:16:26,360 : INFO : torch.Size([168])
2017-05-04 12:16:26,361 : INFO : torch.Size([168, 168])
2017-05-04 12:16:26,362 : INFO : torch.Size([168])
2017-05-04 12:16:26,363 : INFO : torch.Size([168, 300])
2017-05-04 12:16:26,363 : INFO : torch.Size([168])
2017-05-04 12:16:26,364 : INFO : torch.Size([168, 168])
2017-05-04 12:16:26,365 : INFO : torch.Size([168])
2017-05-04 12:16:26,366 : INFO : torch.Size([168, 300])
2017-05-04 12:16:26,367 : INFO : torch.Size([168])
2017-05-04 12:16:26,368 : INFO : torch.Size([168, 168])
2017-05-04 12:16:26,369 : INFO : torch.Size([168])
2017-05-04 12:16:26,370 : INFO : torch.Size([168, 168, 1])
2017-05-04 12:16:26,371 : INFO : torch.Size([168])
2017-05-04 12:16:26,372 : INFO : torch.Size([168, 168])
2017-05-04 12:16:26,373 : INFO : torch.Size([168])
2017-05-04 12:16:26,374 : INFO : torch.Size([3, 168])
2017-05-04 12:16:26,375 : INFO : torch.Size([3])
2017-05-04 12:16:26,376 : INFO : sum
2017-05-04 12:16:26,376 : INFO : 294171
2017-05-04 12:16:26,377 : INFO : ____________
2017-05-04 12:17:13,845 : INFO : LOG_FILE
2017-05-04 12:17:13,846 : INFO : _________________________________start___________________________________
2017-05-04 12:17:13,854 : INFO : Namespace(batchsize=25, cuda=False, data='data/sst/', epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=5e-05)
2017-05-04 12:17:14,151 : INFO : ==> SST vocabulary size : 21705
2017-05-04 12:17:18,102 : INFO : _param count_
2017-05-04 12:17:18,106 : INFO : torch.Size([21705, 300])
2017-05-04 12:17:18,107 : INFO : torch.Size([168, 300])
2017-05-04 12:17:18,108 : INFO : torch.Size([168])
2017-05-04 12:17:18,108 : INFO : torch.Size([168, 168])
2017-05-04 12:17:18,109 : INFO : torch.Size([168])
2017-05-04 12:17:18,110 : INFO : torch.Size([168, 300])
2017-05-04 12:17:18,111 : INFO : torch.Size([168])
2017-05-04 12:17:18,111 : INFO : torch.Size([168, 168])
2017-05-04 12:17:18,112 : INFO : torch.Size([168])
2017-05-04 12:17:18,113 : INFO : torch.Size([168, 300])
2017-05-04 12:17:18,114 : INFO : torch.Size([168])
2017-05-04 12:17:18,115 : INFO : torch.Size([168, 168])
2017-05-04 12:17:18,115 : INFO : torch.Size([168])
2017-05-04 12:17:18,116 : INFO : torch.Size([168, 168, 1])
2017-05-04 12:17:18,117 : INFO : torch.Size([168])
2017-05-04 12:17:18,118 : INFO : torch.Size([168, 168])
2017-05-04 12:17:18,119 : INFO : torch.Size([168])
2017-05-04 12:17:18,119 : INFO : torch.Size([3, 168])
2017-05-04 12:17:18,120 : INFO : torch.Size([3])
2017-05-04 12:17:18,121 : INFO : sum
2017-05-04 12:17:18,122 : INFO : 294171
2017-05-04 12:17:18,123 : INFO : ____________
2017-05-04 12:19:12,273 : INFO : LOG_FILE
2017-05-04 12:19:12,274 : INFO : _________________________________start___________________________________
2017-05-04 12:19:12,281 : INFO : Namespace(batchsize=25, cuda=False, data='data/sst/', epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=5e-05)
2017-05-04 12:19:12,576 : INFO : ==> SST vocabulary size : 21705
2017-05-04 12:19:16,391 : INFO : _param count_
2017-05-04 12:19:16,395 : INFO : torch.Size([21705, 300])
2017-05-04 12:19:16,396 : INFO : torch.Size([168, 300])
2017-05-04 12:19:16,397 : INFO : torch.Size([168])
2017-05-04 12:19:16,398 : INFO : torch.Size([168, 168])
2017-05-04 12:19:16,398 : INFO : torch.Size([168])
2017-05-04 12:19:16,399 : INFO : torch.Size([168, 300])
2017-05-04 12:19:16,400 : INFO : torch.Size([168])
2017-05-04 12:19:16,401 : INFO : torch.Size([168, 168])
2017-05-04 12:19:16,401 : INFO : torch.Size([168])
2017-05-04 12:19:16,402 : INFO : torch.Size([168, 300])
2017-05-04 12:19:16,403 : INFO : torch.Size([168])
2017-05-04 12:19:16,404 : INFO : torch.Size([168, 168])
2017-05-04 12:19:16,405 : INFO : torch.Size([168])
2017-05-04 12:19:16,405 : INFO : torch.Size([168, 168, 1])
2017-05-04 12:19:16,406 : INFO : torch.Size([168])
2017-05-04 12:19:16,407 : INFO : torch.Size([168, 168])
2017-05-04 12:19:16,408 : INFO : torch.Size([168])
2017-05-04 12:19:16,409 : INFO : torch.Size([3, 168])
2017-05-04 12:19:16,409 : INFO : torch.Size([3])
2017-05-04 12:19:16,410 : INFO : sum
2017-05-04 12:19:16,411 : INFO : 294171
2017-05-04 12:19:16,412 : INFO : ____________
2017-05-04 12:19:34,184 : INFO : LOG_FILE
2017-05-04 12:19:34,184 : INFO : _________________________________start___________________________________
2017-05-04 12:19:34,192 : INFO : Namespace(batchsize=25, cuda=False, data='data/sst/', epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=5e-05)
2017-05-04 12:19:34,479 : INFO : ==> SST vocabulary size : 21705
2017-05-04 12:19:38,294 : INFO : _param count_
2017-05-04 12:19:38,298 : INFO : torch.Size([21705, 300])
2017-05-04 12:19:38,299 : INFO : torch.Size([168, 300])
2017-05-04 12:19:38,300 : INFO : torch.Size([168])
2017-05-04 12:19:38,301 : INFO : torch.Size([168, 168])
2017-05-04 12:19:38,302 : INFO : torch.Size([168])
2017-05-04 12:19:38,303 : INFO : torch.Size([168, 300])
2017-05-04 12:19:38,303 : INFO : torch.Size([168])
2017-05-04 12:19:38,304 : INFO : torch.Size([168, 168])
2017-05-04 12:19:38,306 : INFO : torch.Size([168])
2017-05-04 12:19:38,307 : INFO : torch.Size([168, 300])
2017-05-04 12:19:38,308 : INFO : torch.Size([168])
2017-05-04 12:19:38,309 : INFO : torch.Size([168, 168])
2017-05-04 12:19:38,309 : INFO : torch.Size([168])
2017-05-04 12:19:38,310 : INFO : torch.Size([168, 168, 1])
2017-05-04 12:19:38,311 : INFO : torch.Size([168])
2017-05-04 12:19:38,312 : INFO : torch.Size([168, 168])
2017-05-04 12:19:38,313 : INFO : torch.Size([168])
2017-05-04 12:19:38,314 : INFO : torch.Size([3, 168])
2017-05-04 12:19:38,314 : INFO : torch.Size([3])
2017-05-04 12:19:38,315 : INFO : sum
2017-05-04 12:19:38,316 : INFO : 294171
2017-05-04 12:19:38,317 : INFO : ____________
2017-05-04 12:20:34,191 : INFO : LOG_FILE
2017-05-04 12:20:34,192 : INFO : _________________________________start___________________________________
2017-05-04 12:20:34,199 : INFO : Namespace(batchsize=25, cuda=False, data='data/sst/', epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=5e-05)
2017-05-04 12:20:34,497 : INFO : ==> SST vocabulary size : 21705
2017-05-04 12:20:38,339 : INFO : _param count_
2017-05-04 12:20:38,342 : INFO : torch.Size([21705, 300])
2017-05-04 12:20:38,343 : INFO : torch.Size([168, 300])
2017-05-04 12:20:38,344 : INFO : torch.Size([168])
2017-05-04 12:20:38,345 : INFO : torch.Size([168, 168])
2017-05-04 12:20:38,346 : INFO : torch.Size([168])
2017-05-04 12:20:38,347 : INFO : torch.Size([168, 300])
2017-05-04 12:20:38,348 : INFO : torch.Size([168])
2017-05-04 12:20:38,349 : INFO : torch.Size([168, 168])
2017-05-04 12:20:38,350 : INFO : torch.Size([168])
2017-05-04 12:20:38,351 : INFO : torch.Size([168, 300])
2017-05-04 12:20:38,352 : INFO : torch.Size([168])
2017-05-04 12:20:38,353 : INFO : torch.Size([168, 168])
2017-05-04 12:20:38,354 : INFO : torch.Size([168])
2017-05-04 12:20:38,355 : INFO : torch.Size([168, 168, 1])
2017-05-04 12:20:38,356 : INFO : torch.Size([168])
2017-05-04 12:20:38,357 : INFO : torch.Size([168, 168])
2017-05-04 12:20:38,357 : INFO : torch.Size([168])
2017-05-04 12:20:38,358 : INFO : torch.Size([3, 168])
2017-05-04 12:20:38,359 : INFO : torch.Size([3])
2017-05-04 12:20:38,360 : INFO : sum
2017-05-04 12:20:38,361 : INFO : 294171
2017-05-04 12:20:38,362 : INFO : ____________
2017-05-04 12:21:09,003 : INFO : LOG_FILE
2017-05-04 12:21:09,003 : INFO : _________________________________start___________________________________
2017-05-04 12:21:09,005 : INFO : Namespace(batchsize=25, cuda=False, data='data/sst/', epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=5e-05)
2017-05-04 12:21:09,114 : INFO : ==> SST vocabulary size : 21705
2017-05-04 12:21:14,020 : INFO : LOG_FILE
2017-05-04 12:21:14,021 : INFO : _________________________________start___________________________________
2017-05-04 12:21:14,028 : INFO : Namespace(batchsize=25, cuda=False, data='data/sst/', epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=5e-05)
2017-05-04 12:21:14,323 : INFO : ==> SST vocabulary size : 21705
2017-05-04 12:21:18,143 : INFO : _param count_
2017-05-04 12:21:18,147 : INFO : torch.Size([21705, 300])
2017-05-04 12:21:18,148 : INFO : torch.Size([168, 300])
2017-05-04 12:21:18,149 : INFO : torch.Size([168])
2017-05-04 12:21:18,150 : INFO : torch.Size([168, 168])
2017-05-04 12:21:18,150 : INFO : torch.Size([168])
2017-05-04 12:21:18,151 : INFO : torch.Size([168, 300])
2017-05-04 12:21:18,152 : INFO : torch.Size([168])
2017-05-04 12:21:18,153 : INFO : torch.Size([168, 168])
2017-05-04 12:21:18,153 : INFO : torch.Size([168])
2017-05-04 12:21:18,154 : INFO : torch.Size([168, 300])
2017-05-04 12:21:18,155 : INFO : torch.Size([168])
2017-05-04 12:21:18,156 : INFO : torch.Size([168, 168])
2017-05-04 12:21:18,157 : INFO : torch.Size([168])
2017-05-04 12:21:18,157 : INFO : torch.Size([168, 168, 1])
2017-05-04 12:21:18,158 : INFO : torch.Size([168])
2017-05-04 12:21:18,159 : INFO : torch.Size([168, 168])
2017-05-04 12:21:18,160 : INFO : torch.Size([168])
2017-05-04 12:21:18,161 : INFO : torch.Size([3, 168])
2017-05-04 12:21:18,161 : INFO : torch.Size([3])
2017-05-04 12:21:18,162 : INFO : sum
2017-05-04 12:21:18,163 : INFO : 294171
2017-05-04 12:21:18,164 : INFO : ____________
2017-05-04 12:22:04,407 : INFO : LOG_FILE
2017-05-04 12:22:04,407 : INFO : _________________________________start___________________________________
2017-05-04 12:22:04,415 : INFO : Namespace(batchsize=25, cuda=False, data='data/sst/', epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=5e-05)
2017-05-04 12:22:04,708 : INFO : ==> SST vocabulary size : 21705
2017-05-04 12:22:08,549 : INFO : _param count_
2017-05-04 12:22:08,553 : INFO : torch.Size([21705, 300])
2017-05-04 12:22:08,558 : INFO : torch.Size([168, 300])
2017-05-04 12:22:08,560 : INFO : torch.Size([168])
2017-05-04 12:22:08,562 : INFO : torch.Size([168, 168])
2017-05-04 12:22:08,563 : INFO : torch.Size([168])
2017-05-04 12:22:08,564 : INFO : torch.Size([168, 300])
2017-05-04 12:22:08,568 : INFO : torch.Size([168])
2017-05-04 12:22:08,570 : INFO : torch.Size([168, 168])
2017-05-04 12:22:08,571 : INFO : torch.Size([168])
2017-05-04 12:22:08,572 : INFO : torch.Size([168, 300])
2017-05-04 12:22:08,575 : INFO : torch.Size([168])
2017-05-04 12:22:08,575 : INFO : torch.Size([168, 168])
2017-05-04 12:22:08,576 : INFO : torch.Size([168])
2017-05-04 12:22:08,577 : INFO : torch.Size([168, 168, 1])
2017-05-04 12:22:08,578 : INFO : torch.Size([168])
2017-05-04 12:22:08,583 : INFO : torch.Size([168, 168])
2017-05-04 12:22:08,584 : INFO : torch.Size([168])
2017-05-04 12:22:08,585 : INFO : torch.Size([3, 168])
2017-05-04 12:22:08,586 : INFO : torch.Size([3])
2017-05-04 12:22:08,587 : INFO : sum
2017-05-04 12:22:08,587 : INFO : 294171
2017-05-04 12:22:08,588 : INFO : ____________
2017-05-04 12:25:32,745 : INFO : LOG_FILE
2017-05-04 12:25:32,746 : INFO : _________________________________start___________________________________
2017-05-04 12:25:32,754 : INFO : Namespace(batchsize=25, cuda=False, data='data/sst/', epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=5e-05)
2017-05-04 12:25:33,059 : INFO : ==> SST vocabulary size : 21705
2017-05-04 12:25:36,893 : INFO : _param count_
2017-05-04 12:25:36,897 : INFO : torch.Size([21705, 300])
2017-05-04 12:25:36,898 : INFO : torch.Size([168, 300])
2017-05-04 12:25:36,899 : INFO : torch.Size([168])
2017-05-04 12:25:36,899 : INFO : torch.Size([168, 168])
2017-05-04 12:25:36,900 : INFO : torch.Size([168])
2017-05-04 12:25:36,901 : INFO : torch.Size([168, 300])
2017-05-04 12:25:36,902 : INFO : torch.Size([168])
2017-05-04 12:25:36,903 : INFO : torch.Size([168, 168])
2017-05-04 12:25:36,903 : INFO : torch.Size([168])
2017-05-04 12:25:36,904 : INFO : torch.Size([168, 300])
2017-05-04 12:25:36,905 : INFO : torch.Size([168])
2017-05-04 12:25:36,906 : INFO : torch.Size([168, 168])
2017-05-04 12:25:36,907 : INFO : torch.Size([168])
2017-05-04 12:25:36,908 : INFO : torch.Size([168, 168])
2017-05-04 12:25:36,908 : INFO : torch.Size([168])
2017-05-04 12:25:36,909 : INFO : torch.Size([3, 168])
2017-05-04 12:25:36,910 : INFO : torch.Size([3])
2017-05-04 12:25:36,911 : INFO : sum
2017-05-04 12:25:36,912 : INFO : 265779
2017-05-04 12:25:36,913 : INFO : ____________
2017-05-04 12:25:56,069 : INFO : LOG_FILE
2017-05-04 12:25:56,069 : INFO : _________________________________start___________________________________
2017-05-04 12:25:56,078 : INFO : Namespace(batchsize=25, cuda=False, data='data/sst/', epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=5e-05)
2017-05-04 12:25:56,372 : INFO : ==> SST vocabulary size : 21705
2017-05-04 12:26:00,185 : INFO : _param count_
2017-05-04 12:26:00,187 : INFO : torch.Size([21705, 300])
2017-05-04 12:26:00,188 : INFO : torch.Size([168, 300])
2017-05-04 12:26:00,188 : INFO : torch.Size([168])
2017-05-04 12:26:00,189 : INFO : torch.Size([168, 168])
2017-05-04 12:26:00,190 : INFO : torch.Size([168])
2017-05-04 12:26:00,190 : INFO : torch.Size([168, 300])
2017-05-04 12:26:00,191 : INFO : torch.Size([168])
2017-05-04 12:26:00,192 : INFO : torch.Size([168, 168])
2017-05-04 12:26:00,192 : INFO : torch.Size([168])
2017-05-04 12:26:00,193 : INFO : torch.Size([168, 300])
2017-05-04 12:26:00,194 : INFO : torch.Size([168])
2017-05-04 12:26:00,195 : INFO : torch.Size([168, 168])
2017-05-04 12:26:00,196 : INFO : torch.Size([168])
2017-05-04 12:26:00,197 : INFO : torch.Size([168, 168])
2017-05-04 12:26:00,198 : INFO : torch.Size([168])
2017-05-04 12:26:00,199 : INFO : torch.Size([3, 168])
2017-05-04 12:26:00,200 : INFO : torch.Size([3])
2017-05-04 12:26:00,201 : INFO : sum
2017-05-04 12:26:00,202 : INFO : 265779
2017-05-04 12:26:00,203 : INFO : ____________
2017-05-04 12:26:28,142 : INFO : LOG_FILE
2017-05-04 12:26:28,143 : INFO : _________________________________start___________________________________
2017-05-04 12:26:28,151 : INFO : Namespace(batchsize=25, cuda=False, data='data/sst/', epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=5e-05)
2017-05-04 12:26:28,447 : INFO : ==> SST vocabulary size : 21705
2017-05-04 12:26:32,330 : INFO : _param count_
2017-05-04 12:26:32,334 : INFO : torch.Size([21705, 300])
2017-05-04 12:26:32,335 : INFO : torch.Size([168, 300])
2017-05-04 12:26:32,336 : INFO : torch.Size([168])
2017-05-04 12:26:32,336 : INFO : torch.Size([168, 168])
2017-05-04 12:26:32,337 : INFO : torch.Size([168])
2017-05-04 12:26:32,338 : INFO : torch.Size([168, 300])
2017-05-04 12:26:32,339 : INFO : torch.Size([168])
2017-05-04 12:26:32,340 : INFO : torch.Size([168, 168])
2017-05-04 12:26:32,340 : INFO : torch.Size([168])
2017-05-04 12:26:32,341 : INFO : torch.Size([168, 300])
2017-05-04 12:26:32,342 : INFO : torch.Size([168])
2017-05-04 12:26:32,343 : INFO : torch.Size([168, 168])
2017-05-04 12:26:32,344 : INFO : torch.Size([168])
2017-05-04 12:26:32,345 : INFO : torch.Size([168, 168])
2017-05-04 12:26:32,345 : INFO : torch.Size([168])
2017-05-04 12:26:32,346 : INFO : torch.Size([3, 168])
2017-05-04 12:26:32,347 : INFO : torch.Size([3])
2017-05-04 12:26:32,348 : INFO : sum
2017-05-04 12:26:32,349 : INFO : 265779
2017-05-04 12:26:32,349 : INFO : ____________
2017-05-04 12:29:14,609 : INFO : LOG_FILE
2017-05-04 12:29:14,610 : INFO : _________________________________start___________________________________
2017-05-04 12:29:14,618 : INFO : Namespace(batchsize=25, cuda=False, data='data/sst/', epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=5e-05)
2017-05-04 12:29:14,913 : INFO : ==> SST vocabulary size : 21705
2017-05-04 12:29:18,730 : INFO : _param count_
2017-05-04 12:29:18,733 : INFO : torch.Size([21705, 300])
2017-05-04 12:29:18,734 : INFO : torch.Size([168, 300])
2017-05-04 12:29:18,735 : INFO : torch.Size([168])
2017-05-04 12:29:18,736 : INFO : torch.Size([168, 168])
2017-05-04 12:29:18,736 : INFO : torch.Size([168])
2017-05-04 12:29:18,737 : INFO : torch.Size([168, 300])
2017-05-04 12:29:18,738 : INFO : torch.Size([168])
2017-05-04 12:29:18,739 : INFO : torch.Size([168, 168])
2017-05-04 12:29:18,740 : INFO : torch.Size([168])
2017-05-04 12:29:18,740 : INFO : torch.Size([168, 300])
2017-05-04 12:29:18,741 : INFO : torch.Size([168])
2017-05-04 12:29:18,742 : INFO : torch.Size([168, 168])
2017-05-04 12:29:18,743 : INFO : torch.Size([168])
2017-05-04 12:29:18,744 : INFO : torch.Size([168, 168])
2017-05-04 12:29:18,744 : INFO : torch.Size([168])
2017-05-04 12:29:18,745 : INFO : torch.Size([3, 168])
2017-05-04 12:29:18,746 : INFO : torch.Size([3])
2017-05-04 12:29:18,747 : INFO : sum
2017-05-04 12:29:18,748 : INFO : 265779
2017-05-04 12:29:18,748 : INFO : ____________
2017-05-04 12:30:01,825 : INFO : LOG_FILE
2017-05-04 12:30:01,825 : INFO : _________________________________start___________________________________
2017-05-04 12:30:01,833 : INFO : Namespace(batchsize=25, cuda=False, data='data/sst/', epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=5e-05)
2017-05-04 12:30:02,132 : INFO : ==> SST vocabulary size : 21705
2017-05-04 12:30:05,957 : INFO : _param count_
2017-05-04 12:30:05,961 : INFO : torch.Size([21705, 300])
2017-05-04 12:30:05,962 : INFO : torch.Size([168, 300])
2017-05-04 12:30:05,963 : INFO : torch.Size([168])
2017-05-04 12:30:05,964 : INFO : torch.Size([168, 168])
2017-05-04 12:30:05,964 : INFO : torch.Size([168])
2017-05-04 12:30:05,965 : INFO : torch.Size([168, 300])
2017-05-04 12:30:05,966 : INFO : torch.Size([168])
2017-05-04 12:30:05,967 : INFO : torch.Size([168, 168])
2017-05-04 12:30:05,968 : INFO : torch.Size([168])
2017-05-04 12:30:05,969 : INFO : torch.Size([168, 300])
2017-05-04 12:30:05,970 : INFO : torch.Size([168])
2017-05-04 12:30:05,970 : INFO : torch.Size([168, 168])
2017-05-04 12:30:05,971 : INFO : torch.Size([168])
2017-05-04 12:30:05,972 : INFO : torch.Size([168, 168, 1])
2017-05-04 12:30:05,973 : INFO : torch.Size([168])
2017-05-04 12:30:05,974 : INFO : torch.Size([168, 168])
2017-05-04 12:30:05,974 : INFO : torch.Size([168])
2017-05-04 12:30:05,975 : INFO : torch.Size([3, 168])
2017-05-04 12:30:05,976 : INFO : torch.Size([3])
2017-05-04 12:30:05,977 : INFO : sum
2017-05-04 12:30:05,978 : INFO : 294171
2017-05-04 12:30:05,979 : INFO : ____________
2017-05-04 12:56:12,036 : INFO : LOG_FILE
2017-05-04 12:56:12,037 : INFO : _________________________________start___________________________________
2017-05-04 12:56:12,045 : INFO : Namespace(batchsize=25, cuda=False, data='data/sst/', epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=5e-05)
2017-05-04 12:56:12,343 : INFO : ==> SST vocabulary size : 21705
2017-05-04 12:56:16,189 : INFO : _param count_
2017-05-04 12:56:16,193 : INFO : torch.Size([21705, 300])
2017-05-04 12:56:16,194 : INFO : torch.Size([168, 300])
2017-05-04 12:56:16,194 : INFO : torch.Size([168])
2017-05-04 12:56:16,195 : INFO : torch.Size([168, 168])
2017-05-04 12:56:16,196 : INFO : torch.Size([168])
2017-05-04 12:56:16,197 : INFO : torch.Size([168, 300])
2017-05-04 12:56:16,198 : INFO : torch.Size([168])
2017-05-04 12:56:16,199 : INFO : torch.Size([168, 168])
2017-05-04 12:56:16,200 : INFO : torch.Size([168])
2017-05-04 12:56:16,201 : INFO : torch.Size([168, 300])
2017-05-04 12:56:16,202 : INFO : torch.Size([168])
2017-05-04 12:56:16,203 : INFO : torch.Size([168, 168])
2017-05-04 12:56:16,206 : INFO : torch.Size([168])
2017-05-04 12:56:16,207 : INFO : torch.Size([168, 168])
2017-05-04 12:56:16,208 : INFO : torch.Size([168])
2017-05-04 12:56:16,209 : INFO : torch.Size([168, 168])
2017-05-04 12:56:16,209 : INFO : torch.Size([168])
2017-05-04 12:56:16,210 : INFO : torch.Size([3, 168])
2017-05-04 12:56:16,211 : INFO : torch.Size([3])
2017-05-04 12:56:16,213 : INFO : sum
2017-05-04 12:56:16,213 : INFO : 294171
2017-05-04 12:56:16,214 : INFO : ____________
2017-05-04 12:56:55,512 : INFO : LOG_FILE
2017-05-04 12:56:55,512 : INFO : _________________________________start___________________________________
2017-05-04 12:56:55,521 : INFO : Namespace(batchsize=25, cuda=False, data='data/sst/', epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=5e-05)
2017-05-04 12:56:55,818 : INFO : ==> SST vocabulary size : 21705
2017-05-04 12:56:59,670 : INFO : _param count_
2017-05-04 12:56:59,674 : INFO : torch.Size([21705, 300])
2017-05-04 12:56:59,675 : INFO : torch.Size([168, 300])
2017-05-04 12:56:59,676 : INFO : torch.Size([168])
2017-05-04 12:56:59,677 : INFO : torch.Size([168, 168])
2017-05-04 12:56:59,677 : INFO : torch.Size([168])
2017-05-04 12:56:59,678 : INFO : torch.Size([168, 300])
2017-05-04 12:56:59,679 : INFO : torch.Size([168])
2017-05-04 12:56:59,680 : INFO : torch.Size([168, 168])
2017-05-04 12:56:59,681 : INFO : torch.Size([168])
2017-05-04 12:56:59,681 : INFO : torch.Size([168, 300])
2017-05-04 12:56:59,682 : INFO : torch.Size([168])
2017-05-04 12:56:59,683 : INFO : torch.Size([168, 168])
2017-05-04 12:56:59,684 : INFO : torch.Size([168])
2017-05-04 12:56:59,685 : INFO : torch.Size([168, 168])
2017-05-04 12:56:59,686 : INFO : torch.Size([168])
2017-05-04 12:56:59,686 : INFO : torch.Size([168, 168])
2017-05-04 12:56:59,687 : INFO : torch.Size([168])
2017-05-04 12:56:59,688 : INFO : torch.Size([3, 168])
2017-05-04 12:56:59,689 : INFO : torch.Size([3])
2017-05-04 12:56:59,690 : INFO : sum
2017-05-04 12:56:59,691 : INFO : 294171
2017-05-04 12:56:59,691 : INFO : ____________
2017-05-04 12:58:03,721 : INFO : LOG_FILE
2017-05-04 12:58:03,722 : INFO : _________________________________start___________________________________
2017-05-04 12:58:03,730 : INFO : Namespace(batchsize=25, cuda=False, data='data/sst/', epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=5e-05)
2017-05-04 12:58:04,030 : INFO : ==> SST vocabulary size : 21705
2017-05-04 12:58:07,910 : INFO : _param count_
2017-05-04 12:58:07,914 : INFO : torch.Size([21705, 300])
2017-05-04 12:58:07,915 : INFO : torch.Size([168, 300])
2017-05-04 12:58:07,916 : INFO : torch.Size([168])
2017-05-04 12:58:07,917 : INFO : torch.Size([168, 168])
2017-05-04 12:58:07,917 : INFO : torch.Size([168])
2017-05-04 12:58:07,918 : INFO : torch.Size([168, 300])
2017-05-04 12:58:07,921 : INFO : torch.Size([168])
2017-05-04 12:58:07,922 : INFO : torch.Size([168, 168])
2017-05-04 12:58:07,922 : INFO : torch.Size([168])
2017-05-04 12:58:07,923 : INFO : torch.Size([168, 300])
2017-05-04 12:58:07,924 : INFO : torch.Size([168])
2017-05-04 12:58:07,925 : INFO : torch.Size([168, 168])
2017-05-04 12:58:07,926 : INFO : torch.Size([168])
2017-05-04 12:58:07,926 : INFO : torch.Size([168, 168])
2017-05-04 12:58:07,927 : INFO : torch.Size([168])
2017-05-04 12:58:07,928 : INFO : torch.Size([168, 168])
2017-05-04 12:58:07,929 : INFO : torch.Size([168])
2017-05-04 12:58:07,930 : INFO : torch.Size([3, 168])
2017-05-04 12:58:07,931 : INFO : torch.Size([3])
2017-05-04 12:58:07,931 : INFO : sum
2017-05-04 12:58:07,932 : INFO : 294171
2017-05-04 12:58:07,933 : INFO : ____________
2017-05-04 13:01:36,321 : INFO : LOG_FILE
2017-05-04 13:01:36,322 : INFO : _________________________________start___________________________________
2017-05-04 13:01:36,330 : INFO : Namespace(batchsize=25, cuda=False, data='data/sst/', epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=5e-05)
2017-05-04 13:01:36,623 : INFO : ==> SST vocabulary size : 21705
2017-05-04 13:01:40,470 : INFO : _param count_
2017-05-04 13:01:40,474 : INFO : torch.Size([21705, 300])
2017-05-04 13:01:40,475 : INFO : torch.Size([168, 300])
2017-05-04 13:01:40,476 : INFO : torch.Size([168])
2017-05-04 13:01:40,477 : INFO : torch.Size([168, 168])
2017-05-04 13:01:40,478 : INFO : torch.Size([168])
2017-05-04 13:01:40,478 : INFO : torch.Size([168, 300])
2017-05-04 13:01:40,479 : INFO : torch.Size([168])
2017-05-04 13:01:40,480 : INFO : torch.Size([168, 168])
2017-05-04 13:01:40,481 : INFO : torch.Size([168])
2017-05-04 13:01:40,482 : INFO : torch.Size([168, 300])
2017-05-04 13:01:40,482 : INFO : torch.Size([168])
2017-05-04 13:01:40,483 : INFO : torch.Size([168, 168])
2017-05-04 13:01:40,484 : INFO : torch.Size([168])
2017-05-04 13:01:40,485 : INFO : torch.Size([168, 168])
2017-05-04 13:01:40,486 : INFO : torch.Size([168])
2017-05-04 13:01:40,487 : INFO : torch.Size([168, 168])
2017-05-04 13:01:40,487 : INFO : torch.Size([168])
2017-05-04 13:01:40,488 : INFO : torch.Size([3, 168])
2017-05-04 13:01:40,489 : INFO : torch.Size([3])
2017-05-04 13:01:40,490 : INFO : sum
2017-05-04 13:01:40,491 : INFO : 294171
2017-05-04 13:01:40,492 : INFO : ____________
2017-05-04 13:02:07,165 : INFO : LOG_FILE
2017-05-04 13:02:07,165 : INFO : _________________________________start___________________________________
2017-05-04 13:02:07,173 : INFO : Namespace(batchsize=25, cuda=False, data='data/sst/', epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=5e-05)
2017-05-04 13:02:07,464 : INFO : ==> SST vocabulary size : 21705
2017-05-04 13:02:11,322 : INFO : _param count_
2017-05-04 13:02:11,325 : INFO : torch.Size([21705, 300])
2017-05-04 13:02:11,326 : INFO : torch.Size([168, 300])
2017-05-04 13:02:11,327 : INFO : torch.Size([168])
2017-05-04 13:02:11,327 : INFO : torch.Size([168, 168])
2017-05-04 13:02:11,328 : INFO : torch.Size([168])
2017-05-04 13:02:11,329 : INFO : torch.Size([168, 300])
2017-05-04 13:02:11,329 : INFO : torch.Size([168])
2017-05-04 13:02:11,330 : INFO : torch.Size([168, 168])
2017-05-04 13:02:11,331 : INFO : torch.Size([168])
2017-05-04 13:02:11,332 : INFO : torch.Size([168, 300])
2017-05-04 13:02:11,332 : INFO : torch.Size([168])
2017-05-04 13:02:11,333 : INFO : torch.Size([168, 168])
2017-05-04 13:02:11,333 : INFO : torch.Size([168])
2017-05-04 13:02:11,334 : INFO : torch.Size([168, 168])
2017-05-04 13:02:11,335 : INFO : torch.Size([168])
2017-05-04 13:02:11,336 : INFO : torch.Size([168, 168])
2017-05-04 13:02:11,337 : INFO : torch.Size([168])
2017-05-04 13:02:11,338 : INFO : torch.Size([3, 168])
2017-05-04 13:02:11,339 : INFO : torch.Size([3])
2017-05-04 13:02:11,339 : INFO : sum
2017-05-04 13:02:11,340 : INFO : 294171
2017-05-04 13:02:11,341 : INFO : ____________
2017-05-04 13:02:17,241 : INFO : LOG_FILE
2017-05-04 13:02:17,241 : INFO : _________________________________start___________________________________
2017-05-04 13:02:17,249 : INFO : Namespace(batchsize=25, cuda=False, data='data/sst/', epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=5e-05)
2017-05-04 13:02:17,550 : INFO : ==> SST vocabulary size : 21705
2017-05-04 13:02:21,348 : INFO : _param count_
2017-05-04 13:02:21,352 : INFO : torch.Size([21705, 300])
2017-05-04 13:02:21,353 : INFO : torch.Size([168, 300])
2017-05-04 13:02:21,354 : INFO : torch.Size([168])
2017-05-04 13:02:21,355 : INFO : torch.Size([168, 168])
2017-05-04 13:02:21,355 : INFO : torch.Size([168])
2017-05-04 13:02:21,356 : INFO : torch.Size([168, 300])
2017-05-04 13:02:21,357 : INFO : torch.Size([168])
2017-05-04 13:02:21,358 : INFO : torch.Size([168, 168])
2017-05-04 13:02:21,359 : INFO : torch.Size([168])
2017-05-04 13:02:21,360 : INFO : torch.Size([168, 300])
2017-05-04 13:02:21,360 : INFO : torch.Size([168])
2017-05-04 13:02:21,361 : INFO : torch.Size([168, 168])
2017-05-04 13:02:21,362 : INFO : torch.Size([168])
2017-05-04 13:02:21,363 : INFO : torch.Size([168, 168])
2017-05-04 13:02:21,364 : INFO : torch.Size([168])
2017-05-04 13:02:21,365 : INFO : torch.Size([168, 168])
2017-05-04 13:02:21,365 : INFO : torch.Size([168])
2017-05-04 13:02:21,366 : INFO : torch.Size([3, 168])
2017-05-04 13:02:21,367 : INFO : torch.Size([3])
2017-05-04 13:02:21,368 : INFO : sum
2017-05-04 13:02:21,369 : INFO : 294171
2017-05-04 13:02:21,369 : INFO : ____________
2017-05-04 13:06:16,906 : INFO : LOG_FILE
2017-05-04 13:06:16,907 : INFO : _________________________________start___________________________________
2017-05-04 13:06:16,914 : INFO : Namespace(batchsize=25, cuda=False, data='data/sst/', epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=5e-05)
2017-05-04 13:06:17,209 : INFO : ==> SST vocabulary size : 21705
2017-05-04 13:06:21,030 : INFO : _param count_
2017-05-04 13:06:21,034 : INFO : torch.Size([21705, 300])
2017-05-04 13:06:21,034 : INFO : torch.Size([168, 300])
2017-05-04 13:06:21,035 : INFO : torch.Size([168])
2017-05-04 13:06:21,036 : INFO : torch.Size([168, 168])
2017-05-04 13:06:21,036 : INFO : torch.Size([168])
2017-05-04 13:06:21,037 : INFO : torch.Size([168, 300])
2017-05-04 13:06:21,037 : INFO : torch.Size([168])
2017-05-04 13:06:21,038 : INFO : torch.Size([168, 168])
2017-05-04 13:06:21,039 : INFO : torch.Size([168])
2017-05-04 13:06:21,039 : INFO : torch.Size([168, 300])
2017-05-04 13:06:21,040 : INFO : torch.Size([168])
2017-05-04 13:06:21,040 : INFO : torch.Size([168, 168])
2017-05-04 13:06:21,041 : INFO : torch.Size([168])
2017-05-04 13:06:21,042 : INFO : torch.Size([168, 168])
2017-05-04 13:06:21,042 : INFO : torch.Size([168])
2017-05-04 13:06:21,043 : INFO : torch.Size([168, 168])
2017-05-04 13:06:21,044 : INFO : torch.Size([168])
2017-05-04 13:06:21,045 : INFO : torch.Size([3, 168])
2017-05-04 13:06:21,046 : INFO : torch.Size([3])
2017-05-04 13:06:21,047 : INFO : sum
2017-05-04 13:06:21,047 : INFO : 294171
2017-05-04 13:06:21,048 : INFO : ____________
2017-05-04 13:07:05,386 : INFO : LOG_FILE
2017-05-04 13:07:05,386 : INFO : _________________________________start___________________________________
2017-05-04 13:07:05,395 : INFO : Namespace(batchsize=25, cuda=False, data='data/sst/', epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=5e-05)
2017-05-04 13:07:05,690 : INFO : ==> SST vocabulary size : 21705
2017-05-04 13:07:30,095 : INFO : LOG_FILE
2017-05-04 13:07:30,096 : INFO : _________________________________start___________________________________
2017-05-04 13:07:30,104 : INFO : Namespace(batchsize=25, cuda=False, data='data/sst/', epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=5e-05)
2017-05-04 13:07:30,397 : INFO : ==> SST vocabulary size : 21705
2017-05-04 13:07:52,102 : INFO : LOG_FILE
2017-05-04 13:07:52,102 : INFO : _________________________________start___________________________________
2017-05-04 13:07:52,110 : INFO : Namespace(batchsize=25, cuda=False, data='data/sst/', epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=5e-05)
2017-05-04 13:07:52,409 : INFO : ==> SST vocabulary size : 21705
2017-05-04 13:07:56,235 : INFO : _param count_
2017-05-04 13:07:56,242 : INFO : torch.Size([21705, 300])
2017-05-04 13:07:56,244 : INFO : torch.Size([168, 300])
2017-05-04 13:07:56,245 : INFO : torch.Size([168])
2017-05-04 13:07:56,247 : INFO : torch.Size([168, 168])
2017-05-04 13:07:56,248 : INFO : torch.Size([168])
2017-05-04 13:07:56,250 : INFO : torch.Size([168, 300])
2017-05-04 13:07:56,252 : INFO : torch.Size([168])
2017-05-04 13:07:56,253 : INFO : torch.Size([168, 168])
2017-05-04 13:07:56,255 : INFO : torch.Size([168])
2017-05-04 13:07:56,256 : INFO : torch.Size([168, 300])
2017-05-04 13:07:56,258 : INFO : torch.Size([168])
2017-05-04 13:07:56,259 : INFO : torch.Size([168, 168])
2017-05-04 13:07:56,261 : INFO : torch.Size([168])
2017-05-04 13:07:56,263 : INFO : torch.Size([168, 168])
2017-05-04 13:07:56,264 : INFO : torch.Size([168])
2017-05-04 13:07:56,266 : INFO : torch.Size([168, 300])
2017-05-04 13:07:56,267 : INFO : torch.Size([168])
2017-05-04 13:07:56,269 : INFO : torch.Size([3, 168])
2017-05-04 13:07:56,270 : INFO : torch.Size([3])
2017-05-04 13:07:56,271 : INFO : sum
2017-05-04 13:07:56,271 : INFO : 316347
2017-05-04 13:07:56,272 : INFO : ____________
2017-05-04 13:08:52,780 : INFO : LOG_FILE
2017-05-04 13:08:52,781 : INFO : _________________________________start___________________________________
2017-05-04 13:08:52,789 : INFO : Namespace(batchsize=25, cuda=False, data='data/sst/', epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=5e-05)
2017-05-04 13:08:53,088 : INFO : ==> SST vocabulary size : 21705
2017-05-04 13:08:56,907 : INFO : _param count_
2017-05-04 13:08:56,911 : INFO : torch.Size([21705, 300])
2017-05-04 13:08:56,912 : INFO : torch.Size([168, 300])
2017-05-04 13:08:56,913 : INFO : torch.Size([168])
2017-05-04 13:08:56,913 : INFO : torch.Size([168, 168])
2017-05-04 13:08:56,914 : INFO : torch.Size([168])
2017-05-04 13:08:56,915 : INFO : torch.Size([168, 300])
2017-05-04 13:08:56,916 : INFO : torch.Size([168])
2017-05-04 13:08:56,917 : INFO : torch.Size([168, 168])
2017-05-04 13:08:56,918 : INFO : torch.Size([168])
2017-05-04 13:08:56,919 : INFO : torch.Size([168, 300])
2017-05-04 13:08:56,919 : INFO : torch.Size([168])
2017-05-04 13:08:56,920 : INFO : torch.Size([168, 168])
2017-05-04 13:08:56,921 : INFO : torch.Size([168])
2017-05-04 13:08:56,922 : INFO : torch.Size([168, 168])
2017-05-04 13:08:56,923 : INFO : torch.Size([168])
2017-05-04 13:08:56,924 : INFO : torch.Size([168, 300])
2017-05-04 13:08:56,925 : INFO : torch.Size([168])
2017-05-04 13:08:56,925 : INFO : torch.Size([3, 168])
2017-05-04 13:08:56,926 : INFO : torch.Size([3])
2017-05-04 13:08:56,927 : INFO : sum
2017-05-04 13:08:56,928 : INFO : 316347
2017-05-04 13:08:56,929 : INFO : ____________
2017-05-04 13:28:35,938 : INFO : LOG_FILE
2017-05-04 13:28:35,938 : INFO : _________________________________start___________________________________
2017-05-04 13:28:35,940 : INFO : Namespace(batchsize=25, cuda=False, data='data/sst/', epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=5e-05)
2017-05-04 13:28:36,043 : INFO : ==> SST vocabulary size : 21705
2017-05-04 13:28:39,385 : INFO : _param count_
2017-05-04 13:28:39,388 : INFO : torch.Size([21705, 300])
2017-05-04 13:28:39,388 : INFO : torch.Size([168, 300])
2017-05-04 13:28:39,388 : INFO : torch.Size([168])
2017-05-04 13:28:39,389 : INFO : torch.Size([168, 168])
2017-05-04 13:28:39,389 : INFO : torch.Size([168])
2017-05-04 13:28:39,389 : INFO : torch.Size([168, 300])
2017-05-04 13:28:39,389 : INFO : torch.Size([168])
2017-05-04 13:28:39,390 : INFO : torch.Size([168, 168])
2017-05-04 13:28:39,390 : INFO : torch.Size([168])
2017-05-04 13:28:39,390 : INFO : torch.Size([168, 300])
2017-05-04 13:28:39,390 : INFO : torch.Size([168])
2017-05-04 13:28:39,390 : INFO : torch.Size([168, 168])
2017-05-04 13:28:39,391 : INFO : torch.Size([168])
2017-05-04 13:28:39,391 : INFO : torch.Size([168, 300])
2017-05-04 13:28:39,391 : INFO : torch.Size([168])
2017-05-04 13:28:39,391 : INFO : torch.Size([168, 168])
2017-05-04 13:28:39,391 : INFO : torch.Size([168])
2017-05-04 13:28:39,392 : INFO : torch.Size([3, 168])
2017-05-04 13:28:39,392 : INFO : torch.Size([3])
2017-05-04 13:28:39,392 : INFO : sum
2017-05-04 13:28:39,392 : INFO : 316347
2017-05-04 13:28:39,392 : INFO : ____________
2017-05-04 13:29:37,762 : INFO : LOG_FILE
2017-05-04 13:29:37,762 : INFO : _________________________________start___________________________________
2017-05-04 13:29:37,794 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=5e-05)
2017-05-04 13:29:37,925 : INFO : ==> SST vocabulary size : 21705
2017-05-04 13:29:43,516 : INFO : _param count_
2017-05-04 13:29:43,516 : INFO : torch.Size([21705, 300])
2017-05-04 13:29:43,516 : INFO : torch.Size([168, 300])
2017-05-04 13:29:43,516 : INFO : torch.Size([168])
2017-05-04 13:29:43,516 : INFO : torch.Size([168, 168])
2017-05-04 13:29:43,517 : INFO : torch.Size([168])
2017-05-04 13:29:43,517 : INFO : torch.Size([168, 300])
2017-05-04 13:29:43,517 : INFO : torch.Size([168])
2017-05-04 13:29:43,517 : INFO : torch.Size([168, 168])
2017-05-04 13:29:43,517 : INFO : torch.Size([168])
2017-05-04 13:29:43,517 : INFO : torch.Size([168, 300])
2017-05-04 13:29:43,517 : INFO : torch.Size([168])
2017-05-04 13:29:43,518 : INFO : torch.Size([168, 168])
2017-05-04 13:29:43,518 : INFO : torch.Size([168])
2017-05-04 13:29:43,518 : INFO : torch.Size([168, 300])
2017-05-04 13:29:43,518 : INFO : torch.Size([168])
2017-05-04 13:29:43,518 : INFO : torch.Size([168, 168])
2017-05-04 13:29:43,518 : INFO : torch.Size([168])
2017-05-04 13:29:43,518 : INFO : torch.Size([3, 168])
2017-05-04 13:29:43,518 : INFO : torch.Size([3])
2017-05-04 13:29:43,519 : INFO : sum
2017-05-04 13:29:43,519 : INFO : 316347
2017-05-04 13:29:43,519 : INFO : ____________
2017-05-04 13:43:56,400 : INFO : ==> Train loss   : 9.910530
2017-05-04 13:43:56,400 : INFO : Epoch
2017-05-04 13:43:56,400 : INFO : 0
2017-05-04 13:43:56,400 : INFO : dev percentage
2017-05-04 13:43:56,400 : INFO : 0.801605504587
2017-05-04 13:43:56,400 : INFO : Epoch
2017-05-04 13:43:56,400 : INFO : 0
2017-05-04 13:43:56,401 : INFO : test percentage
2017-05-04 13:43:56,401 : INFO : 0.808347062054
2017-05-04 13:58:13,166 : INFO : ==> Train loss   : 7.415758
2017-05-04 13:58:13,166 : INFO : Epoch
2017-05-04 13:58:13,166 : INFO : 1
2017-05-04 13:58:13,166 : INFO : dev percentage
2017-05-04 13:58:13,167 : INFO : 0.808486238532
2017-05-04 13:58:13,167 : INFO : Epoch
2017-05-04 13:58:13,167 : INFO : 1
2017-05-04 13:58:13,167 : INFO : test percentage
2017-05-04 13:58:13,167 : INFO : 0.813289401428
2017-05-04 14:12:45,989 : INFO : ==> Train loss   : 6.458031
2017-05-04 14:12:45,989 : INFO : Epoch
2017-05-04 14:12:45,989 : INFO : 2
2017-05-04 14:12:45,990 : INFO : dev percentage
2017-05-04 14:12:45,990 : INFO : 0.785550458716
2017-05-04 14:12:45,990 : INFO : Epoch
2017-05-04 14:12:45,990 : INFO : 2
2017-05-04 14:12:45,990 : INFO : test percentage
2017-05-04 14:12:45,990 : INFO : 0.800109829764
2017-05-04 14:21:25,734 : INFO : LOG_FILE
2017-05-04 14:21:25,734 : INFO : _________________________________start___________________________________
2017-05-04 14:21:25,767 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=5e-05)
2017-05-04 14:21:26,069 : INFO : ==> SST vocabulary size : 21705
2017-05-04 14:21:33,828 : INFO : LOG_FILE
2017-05-04 14:21:33,829 : INFO : _________________________________start___________________________________
2017-05-04 14:21:33,856 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=5e-05)
2017-05-04 14:21:33,960 : INFO : ==> SST vocabulary size : 21705
2017-05-04 14:21:39,401 : INFO : _param count_
2017-05-04 14:21:39,402 : INFO : torch.Size([21705, 300])
2017-05-04 14:21:39,402 : INFO : torch.Size([168, 300])
2017-05-04 14:21:39,402 : INFO : torch.Size([168])
2017-05-04 14:21:39,402 : INFO : torch.Size([168, 168])
2017-05-04 14:21:39,402 : INFO : torch.Size([168])
2017-05-04 14:21:39,403 : INFO : torch.Size([168, 300])
2017-05-04 14:21:39,403 : INFO : torch.Size([168])
2017-05-04 14:21:39,403 : INFO : torch.Size([168, 168])
2017-05-04 14:21:39,403 : INFO : torch.Size([168])
2017-05-04 14:21:39,403 : INFO : torch.Size([168, 300])
2017-05-04 14:21:39,403 : INFO : torch.Size([168])
2017-05-04 14:21:39,403 : INFO : torch.Size([168, 168])
2017-05-04 14:21:39,403 : INFO : torch.Size([168])
2017-05-04 14:21:39,404 : INFO : torch.Size([168, 300])
2017-05-04 14:21:39,404 : INFO : torch.Size([168])
2017-05-04 14:21:39,404 : INFO : torch.Size([168, 168])
2017-05-04 14:21:39,404 : INFO : torch.Size([168])
2017-05-04 14:21:39,404 : INFO : torch.Size([3, 168])
2017-05-04 14:21:39,404 : INFO : torch.Size([3])
2017-05-04 14:21:39,404 : INFO : sum
2017-05-04 14:21:39,405 : INFO : 316347
2017-05-04 14:21:39,405 : INFO : ____________
2017-05-04 14:36:56,954 : INFO : LOG_FILE
2017-05-04 14:36:56,954 : INFO : _________________________________start___________________________________
2017-05-04 14:36:56,981 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=5e-05)
2017-05-04 14:36:57,085 : INFO : ==> SST vocabulary size : 21705
2017-05-04 14:41:10,379 : INFO : LOG_FILE
2017-05-04 14:41:10,379 : INFO : _________________________________start___________________________________
2017-05-04 14:41:10,409 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=5e-05)
2017-05-04 14:41:10,515 : INFO : ==> SST vocabulary size : 21705
2017-05-04 14:41:16,064 : INFO : _param count_
2017-05-04 14:41:16,065 : INFO : torch.Size([21705, 300])
2017-05-04 14:41:16,065 : INFO : torch.Size([168, 300])
2017-05-04 14:41:16,065 : INFO : torch.Size([168])
2017-05-04 14:41:16,065 : INFO : torch.Size([168, 168])
2017-05-04 14:41:16,065 : INFO : torch.Size([168])
2017-05-04 14:41:16,066 : INFO : torch.Size([168, 300])
2017-05-04 14:41:16,066 : INFO : torch.Size([168])
2017-05-04 14:41:16,066 : INFO : torch.Size([168, 168])
2017-05-04 14:41:16,066 : INFO : torch.Size([168])
2017-05-04 14:41:16,066 : INFO : torch.Size([168, 300])
2017-05-04 14:41:16,066 : INFO : torch.Size([168])
2017-05-04 14:41:16,067 : INFO : torch.Size([168, 168])
2017-05-04 14:41:16,067 : INFO : torch.Size([168])
2017-05-04 14:41:16,067 : INFO : torch.Size([168, 300])
2017-05-04 14:41:16,067 : INFO : torch.Size([168])
2017-05-04 14:41:16,067 : INFO : torch.Size([168, 168])
2017-05-04 14:41:16,067 : INFO : torch.Size([168])
2017-05-04 14:41:16,067 : INFO : torch.Size([3, 168])
2017-05-04 14:41:16,068 : INFO : torch.Size([3])
2017-05-04 14:41:16,068 : INFO : sum
2017-05-04 14:41:16,068 : INFO : 316347
2017-05-04 14:41:16,068 : INFO : ____________
2017-05-04 14:58:54,593 : INFO : ==> Train loss   : 0.570765
2017-05-04 14:58:54,593 : INFO : Epoch
2017-05-04 14:58:54,593 : INFO : 0
2017-05-04 14:58:54,594 : INFO : train percentage
2017-05-04 14:58:54,594 : INFO : 0.810115606936
2017-05-04 14:58:54,594 : INFO : Epoch
2017-05-04 14:58:54,594 : INFO : 0
2017-05-04 14:58:54,594 : INFO : dev percentage
2017-05-04 14:58:54,594 : INFO : 0.795871559633
2017-05-04 14:58:54,594 : INFO : Epoch
2017-05-04 14:58:54,594 : INFO : 0
2017-05-04 14:58:54,595 : INFO : test percentage
2017-05-04 14:58:54,595 : INFO : 0.804503020319
2017-05-04 15:15:46,245 : INFO : ==> Train loss   : 0.378343
2017-05-04 15:15:46,245 : INFO : Epoch
2017-05-04 15:15:46,245 : INFO : 1
2017-05-04 15:15:46,245 : INFO : train percentage
2017-05-04 15:15:46,246 : INFO : 0.847398843931
2017-05-04 15:15:46,246 : INFO : Epoch
2017-05-04 15:15:46,246 : INFO : 1
2017-05-04 15:15:46,246 : INFO : dev percentage
2017-05-04 15:15:46,246 : INFO : 0.813073394495
2017-05-04 15:15:46,246 : INFO : Epoch
2017-05-04 15:15:46,246 : INFO : 1
2017-05-04 15:15:46,246 : INFO : test percentage
2017-05-04 15:15:46,247 : INFO : 0.831411312466
2017-05-04 15:33:31,431 : INFO : ==> Train loss   : 0.371149
2017-05-04 15:33:31,431 : INFO : Epoch
2017-05-04 15:33:31,432 : INFO : 2
2017-05-04 15:33:31,432 : INFO : train percentage
2017-05-04 15:33:31,432 : INFO : 0.857080924855
2017-05-04 15:33:31,432 : INFO : Epoch
2017-05-04 15:33:31,432 : INFO : 2
2017-05-04 15:33:31,432 : INFO : dev percentage
2017-05-04 15:33:31,432 : INFO : 0.811926605505
2017-05-04 15:33:31,432 : INFO : Epoch
2017-05-04 15:33:31,432 : INFO : 2
2017-05-04 15:33:31,433 : INFO : test percentage
2017-05-04 15:33:31,433 : INFO : 0.827018121911
2017-05-04 15:50:59,905 : INFO : ==> Train loss   : 0.318173
2017-05-04 15:50:59,905 : INFO : Epoch
2017-05-04 15:50:59,905 : INFO : 3
2017-05-04 15:50:59,905 : INFO : train percentage
2017-05-04 15:50:59,905 : INFO : 0.881502890173
2017-05-04 15:50:59,905 : INFO : Epoch
2017-05-04 15:50:59,905 : INFO : 3
2017-05-04 15:50:59,906 : INFO : dev percentage
2017-05-04 15:50:59,906 : INFO : 0.821100917431
2017-05-04 15:50:59,906 : INFO : Epoch
2017-05-04 15:50:59,906 : INFO : 3
2017-05-04 15:50:59,906 : INFO : test percentage
2017-05-04 15:50:59,906 : INFO : 0.833058758924
2017-05-04 16:08:41,787 : INFO : ==> Train loss   : 0.286858
2017-05-04 16:08:41,788 : INFO : Epoch
2017-05-04 16:08:41,788 : INFO : 4
2017-05-04 16:08:41,788 : INFO : train percentage
2017-05-04 16:08:41,788 : INFO : 0.890028901734
2017-05-04 16:08:41,788 : INFO : Epoch
2017-05-04 16:08:41,788 : INFO : 4
2017-05-04 16:08:41,789 : INFO : dev percentage
2017-05-04 16:08:41,789 : INFO : 0.825688073394
2017-05-04 16:08:41,789 : INFO : Epoch
2017-05-04 16:08:41,789 : INFO : 4
2017-05-04 16:08:41,789 : INFO : test percentage
2017-05-04 16:08:41,789 : INFO : 0.820428336079
2017-05-04 16:26:05,035 : INFO : ==> Train loss   : 0.224527
2017-05-04 16:26:05,036 : INFO : Epoch
2017-05-04 16:26:05,036 : INFO : 5
2017-05-04 16:26:05,036 : INFO : train percentage
2017-05-04 16:26:05,036 : INFO : 0.92210982659
2017-05-04 16:26:05,036 : INFO : Epoch
2017-05-04 16:26:05,036 : INFO : 5
2017-05-04 16:26:05,036 : INFO : dev percentage
2017-05-04 16:26:05,037 : INFO : 0.821100917431
2017-05-04 16:26:05,037 : INFO : Epoch
2017-05-04 16:26:05,037 : INFO : 5
2017-05-04 16:26:05,037 : INFO : test percentage
2017-05-04 16:26:05,037 : INFO : 0.831960461285
2017-05-04 16:43:20,105 : INFO : ==> Train loss   : 0.208367
2017-05-04 16:43:20,105 : INFO : Epoch
2017-05-04 16:43:20,105 : INFO : 6
2017-05-04 16:43:20,105 : INFO : train percentage
2017-05-04 16:43:20,105 : INFO : 0.934248554913
2017-05-04 16:43:20,105 : INFO : Epoch
2017-05-04 16:43:20,106 : INFO : 6
2017-05-04 16:43:20,106 : INFO : dev percentage
2017-05-04 16:43:20,106 : INFO : 0.813073394495
2017-05-04 16:43:20,106 : INFO : Epoch
2017-05-04 16:43:20,106 : INFO : 6
2017-05-04 16:43:20,106 : INFO : test percentage
2017-05-04 16:43:20,106 : INFO : 0.823723228995
2017-05-04 17:00:51,814 : INFO : ==> Train loss   : 0.193350
2017-05-04 17:00:51,814 : INFO : Epoch
2017-05-04 17:00:51,814 : INFO : 7
2017-05-04 17:00:51,815 : INFO : train percentage
2017-05-04 17:00:51,815 : INFO : 0.938583815029
2017-05-04 17:00:51,815 : INFO : Epoch
2017-05-04 17:00:51,815 : INFO : 7
2017-05-04 17:00:51,815 : INFO : dev percentage
2017-05-04 17:00:51,815 : INFO : 0.810779816514
2017-05-04 17:00:51,815 : INFO : Epoch
2017-05-04 17:00:51,815 : INFO : 7
2017-05-04 17:00:51,816 : INFO : test percentage
2017-05-04 17:00:51,816 : INFO : 0.823174080176
2017-05-04 17:18:49,306 : INFO : ==> Train loss   : 0.133996
2017-05-04 17:18:49,307 : INFO : Epoch
2017-05-04 17:18:49,307 : INFO : 8
2017-05-04 17:18:49,307 : INFO : train percentage
2017-05-04 17:18:49,307 : INFO : 0.957369942197
2017-05-04 17:18:49,307 : INFO : Epoch
2017-05-04 17:18:49,307 : INFO : 8
2017-05-04 17:18:49,307 : INFO : dev percentage
2017-05-04 17:18:49,308 : INFO : 0.810779816514
2017-05-04 17:18:49,308 : INFO : Epoch
2017-05-04 17:18:49,308 : INFO : 8
2017-05-04 17:18:49,308 : INFO : test percentage
2017-05-04 17:18:49,308 : INFO : 0.823174080176
2017-05-04 17:36:20,330 : INFO : ==> Train loss   : 0.123991
2017-05-04 17:36:20,330 : INFO : Epoch
2017-05-04 17:36:20,331 : INFO : 9
2017-05-04 17:36:20,331 : INFO : train percentage
2017-05-04 17:36:20,331 : INFO : 0.965173410405
2017-05-04 17:36:20,331 : INFO : Epoch
2017-05-04 17:36:20,331 : INFO : 9
2017-05-04 17:36:20,331 : INFO : dev percentage
2017-05-04 17:36:20,331 : INFO : 0.813073394495
2017-05-04 17:36:20,332 : INFO : Epoch
2017-05-04 17:36:20,332 : INFO : 9
2017-05-04 17:36:20,332 : INFO : test percentage
2017-05-04 17:36:20,332 : INFO : 0.81987918726
2017-05-04 17:38:04,356 : INFO : LOG_FILE
2017-05-04 17:38:04,356 : INFO : _________________________________start___________________________________
2017-05-04 17:38:04,383 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-04 17:38:04,497 : INFO : ==> SST vocabulary size : 21705
2017-05-04 17:38:38,289 : INFO : LOG_FILE
2017-05-04 17:38:38,289 : INFO : _________________________________start___________________________________
2017-05-04 17:38:38,318 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-04 17:38:38,424 : INFO : ==> SST vocabulary size : 21705
2017-05-04 17:38:58,769 : INFO : LOG_FILE
2017-05-04 17:38:58,769 : INFO : _________________________________start___________________________________
2017-05-04 17:38:58,798 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-04 17:38:58,913 : INFO : ==> SST vocabulary size : 21705
2017-05-04 17:39:35,578 : INFO : LOG_FILE
2017-05-04 17:39:35,578 : INFO : _________________________________start___________________________________
2017-05-04 17:39:35,608 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-04 17:39:35,713 : INFO : ==> SST vocabulary size : 21705
2017-05-04 17:40:25,008 : INFO : LOG_FILE
2017-05-04 17:40:25,008 : INFO : _________________________________start___________________________________
2017-05-04 17:40:25,037 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-04 17:40:25,142 : INFO : ==> SST vocabulary size : 21705
2017-05-04 17:40:30,685 : INFO : _param count_
2017-05-04 17:40:30,685 : INFO : torch.Size([168, 300])
2017-05-04 17:40:30,685 : INFO : torch.Size([168])
2017-05-04 17:40:30,685 : INFO : torch.Size([168, 168])
2017-05-04 17:40:30,685 : INFO : torch.Size([168])
2017-05-04 17:40:30,685 : INFO : torch.Size([168, 300])
2017-05-04 17:40:30,686 : INFO : torch.Size([168])
2017-05-04 17:40:30,686 : INFO : torch.Size([168, 168])
2017-05-04 17:40:30,686 : INFO : torch.Size([168])
2017-05-04 17:40:30,686 : INFO : torch.Size([168, 300])
2017-05-04 17:40:30,686 : INFO : torch.Size([168])
2017-05-04 17:40:30,686 : INFO : torch.Size([168, 168])
2017-05-04 17:40:30,686 : INFO : torch.Size([168])
2017-05-04 17:40:30,687 : INFO : torch.Size([168, 300])
2017-05-04 17:40:30,687 : INFO : torch.Size([168])
2017-05-04 17:40:30,687 : INFO : torch.Size([168, 168])
2017-05-04 17:40:30,687 : INFO : torch.Size([168])
2017-05-04 17:40:30,687 : INFO : torch.Size([3, 168])
2017-05-04 17:40:30,687 : INFO : torch.Size([3])
2017-05-04 17:40:30,687 : INFO : sum
2017-05-04 17:40:30,687 : INFO : 265947
2017-05-04 17:40:30,688 : INFO : ____________
2017-05-04 17:41:59,147 : INFO : LOG_FILE
2017-05-04 17:41:59,147 : INFO : _________________________________start___________________________________
2017-05-04 17:41:59,177 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-04 17:41:59,281 : INFO : ==> SST vocabulary size : 21705
2017-05-04 17:42:04,888 : INFO : _param count_
2017-05-04 17:42:04,888 : INFO : torch.Size([168, 300])
2017-05-04 17:42:04,888 : INFO : torch.Size([168])
2017-05-04 17:42:04,889 : INFO : torch.Size([168, 168])
2017-05-04 17:42:04,889 : INFO : torch.Size([168])
2017-05-04 17:42:04,889 : INFO : torch.Size([168, 300])
2017-05-04 17:42:04,889 : INFO : torch.Size([168])
2017-05-04 17:42:04,889 : INFO : torch.Size([168, 168])
2017-05-04 17:42:04,890 : INFO : torch.Size([168])
2017-05-04 17:42:04,890 : INFO : torch.Size([168, 300])
2017-05-04 17:42:04,890 : INFO : torch.Size([168])
2017-05-04 17:42:04,890 : INFO : torch.Size([168, 168])
2017-05-04 17:42:04,890 : INFO : torch.Size([168])
2017-05-04 17:42:04,890 : INFO : torch.Size([168, 300])
2017-05-04 17:42:04,890 : INFO : torch.Size([168])
2017-05-04 17:42:04,891 : INFO : torch.Size([168, 168])
2017-05-04 17:42:04,891 : INFO : torch.Size([168])
2017-05-04 17:42:04,891 : INFO : torch.Size([3, 168])
2017-05-04 17:42:04,891 : INFO : torch.Size([3])
2017-05-04 17:42:04,891 : INFO : sum
2017-05-04 17:42:04,891 : INFO : 265947
2017-05-04 17:42:04,891 : INFO : ____________
2017-05-04 17:42:27,450 : INFO : LOG_FILE
2017-05-04 17:42:27,450 : INFO : _________________________________start___________________________________
2017-05-04 17:42:27,481 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-04 17:42:27,586 : INFO : ==> SST vocabulary size : 21705
2017-05-04 17:42:33,245 : INFO : _param count_
2017-05-04 17:42:33,246 : INFO : torch.Size([168, 300])
2017-05-04 17:42:33,246 : INFO : torch.Size([168])
2017-05-04 17:42:33,246 : INFO : torch.Size([168, 168])
2017-05-04 17:42:33,246 : INFO : torch.Size([168])
2017-05-04 17:42:33,246 : INFO : torch.Size([168, 300])
2017-05-04 17:42:33,246 : INFO : torch.Size([168])
2017-05-04 17:42:33,246 : INFO : torch.Size([168, 168])
2017-05-04 17:42:33,247 : INFO : torch.Size([168])
2017-05-04 17:42:33,247 : INFO : torch.Size([168, 300])
2017-05-04 17:42:33,247 : INFO : torch.Size([168])
2017-05-04 17:42:33,247 : INFO : torch.Size([168, 168])
2017-05-04 17:42:33,247 : INFO : torch.Size([168])
2017-05-04 17:42:33,247 : INFO : torch.Size([168, 300])
2017-05-04 17:42:33,247 : INFO : torch.Size([168])
2017-05-04 17:42:33,247 : INFO : torch.Size([168, 168])
2017-05-04 17:42:33,248 : INFO : torch.Size([168])
2017-05-04 17:42:33,248 : INFO : torch.Size([3, 168])
2017-05-04 17:42:33,248 : INFO : torch.Size([3])
2017-05-04 17:42:33,248 : INFO : sum
2017-05-04 17:42:33,248 : INFO : 265947
2017-05-04 17:42:33,248 : INFO : ____________
2017-05-04 17:44:43,618 : INFO : ==> Train loss   : 16.682853
2017-05-04 17:44:43,618 : INFO : Epoch
2017-05-04 17:44:43,619 : INFO : 0
2017-05-04 17:44:43,619 : INFO : dev percentage
2017-05-04 17:44:43,619 : INFO : 0.86123853211
2017-05-04 17:46:51,273 : INFO : ==> Train loss   : 9.576105
2017-05-04 17:46:51,273 : INFO : Epoch
2017-05-04 17:46:51,273 : INFO : 1
2017-05-04 17:46:51,273 : INFO : dev percentage
2017-05-04 17:46:51,273 : INFO : 0.94495412844
2017-05-04 17:48:58,730 : INFO : ==> Train loss   : 7.453477
2017-05-04 17:48:58,730 : INFO : Epoch
2017-05-04 17:48:58,730 : INFO : 2
2017-05-04 17:48:58,731 : INFO : dev percentage
2017-05-04 17:48:58,731 : INFO : 0.975917431193
2017-05-04 17:51:05,327 : INFO : ==> Train loss   : 6.608928
2017-05-04 17:51:05,327 : INFO : Epoch
2017-05-04 17:51:05,328 : INFO : 3
2017-05-04 17:51:05,328 : INFO : dev percentage
2017-05-04 17:51:05,328 : INFO : 0.990825688073
2017-05-04 17:52:34,927 : INFO : LOG_FILE
2017-05-04 17:52:34,927 : INFO : _________________________________start___________________________________
2017-05-04 17:52:34,957 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-04 17:52:35,060 : INFO : ==> SST vocabulary size : 21705
2017-05-04 17:52:40,588 : INFO : _param count_
2017-05-04 17:52:40,588 : INFO : torch.Size([168, 300])
2017-05-04 17:52:40,588 : INFO : torch.Size([168])
2017-05-04 17:52:40,589 : INFO : torch.Size([168, 168])
2017-05-04 17:52:40,589 : INFO : torch.Size([168])
2017-05-04 17:52:40,589 : INFO : torch.Size([168, 300])
2017-05-04 17:52:40,589 : INFO : torch.Size([168])
2017-05-04 17:52:40,589 : INFO : torch.Size([168, 168])
2017-05-04 17:52:40,589 : INFO : torch.Size([168])
2017-05-04 17:52:40,589 : INFO : torch.Size([168, 300])
2017-05-04 17:52:40,590 : INFO : torch.Size([168])
2017-05-04 17:52:40,590 : INFO : torch.Size([168, 168])
2017-05-04 17:52:40,590 : INFO : torch.Size([168])
2017-05-04 17:52:40,590 : INFO : torch.Size([168, 300])
2017-05-04 17:52:40,590 : INFO : torch.Size([168])
2017-05-04 17:52:40,590 : INFO : torch.Size([168, 168])
2017-05-04 17:52:40,590 : INFO : torch.Size([168])
2017-05-04 17:52:40,590 : INFO : torch.Size([3, 168])
2017-05-04 17:52:40,591 : INFO : torch.Size([3])
2017-05-04 17:52:40,591 : INFO : sum
2017-05-04 17:52:40,591 : INFO : 265947
2017-05-04 17:52:40,591 : INFO : ____________
2017-05-04 17:54:12,161 : INFO : LOG_FILE
2017-05-04 17:54:12,162 : INFO : _________________________________start___________________________________
2017-05-04 17:54:12,194 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-04 17:54:12,490 : INFO : ==> SST vocabulary size : 21705
2017-05-04 17:54:19,208 : INFO : _param count_
2017-05-04 17:54:19,211 : INFO : torch.Size([21705, 300])
2017-05-04 17:54:19,212 : INFO : torch.Size([168, 300])
2017-05-04 17:54:19,212 : INFO : torch.Size([168])
2017-05-04 17:54:19,213 : INFO : torch.Size([168, 168])
2017-05-04 17:54:19,213 : INFO : torch.Size([168])
2017-05-04 17:54:19,214 : INFO : torch.Size([168, 300])
2017-05-04 17:54:19,214 : INFO : torch.Size([168])
2017-05-04 17:54:19,215 : INFO : torch.Size([168, 168])
2017-05-04 17:54:19,215 : INFO : torch.Size([168])
2017-05-04 17:54:19,216 : INFO : torch.Size([168, 300])
2017-05-04 17:54:19,216 : INFO : torch.Size([168])
2017-05-04 17:54:19,217 : INFO : torch.Size([168, 168])
2017-05-04 17:54:19,217 : INFO : torch.Size([168])
2017-05-04 17:54:19,218 : INFO : torch.Size([168, 300])
2017-05-04 17:54:19,219 : INFO : torch.Size([168])
2017-05-04 17:54:19,219 : INFO : torch.Size([168, 168])
2017-05-04 17:54:19,220 : INFO : torch.Size([168])
2017-05-04 17:54:19,220 : INFO : torch.Size([3, 168])
2017-05-04 17:54:19,221 : INFO : torch.Size([3])
2017-05-04 17:54:19,221 : INFO : sum
2017-05-04 17:54:19,222 : INFO : 316347
2017-05-04 17:54:19,222 : INFO : ____________
2017-05-04 17:54:52,097 : INFO : LOG_FILE
2017-05-04 17:54:52,097 : INFO : _________________________________start___________________________________
2017-05-04 17:54:52,128 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-04 17:54:52,235 : INFO : ==> SST vocabulary size : 21705
2017-05-04 17:54:57,885 : INFO : _param count_
2017-05-04 17:54:57,885 : INFO : torch.Size([168, 300])
2017-05-04 17:54:57,885 : INFO : torch.Size([168])
2017-05-04 17:54:57,886 : INFO : torch.Size([168, 168])
2017-05-04 17:54:57,886 : INFO : torch.Size([168])
2017-05-04 17:54:57,886 : INFO : torch.Size([168, 300])
2017-05-04 17:54:57,886 : INFO : torch.Size([168])
2017-05-04 17:54:57,886 : INFO : torch.Size([168, 168])
2017-05-04 17:54:57,886 : INFO : torch.Size([168])
2017-05-04 17:54:57,886 : INFO : torch.Size([168, 300])
2017-05-04 17:54:57,887 : INFO : torch.Size([168])
2017-05-04 17:54:57,887 : INFO : torch.Size([168, 168])
2017-05-04 17:54:57,887 : INFO : torch.Size([168])
2017-05-04 17:54:57,887 : INFO : torch.Size([168, 300])
2017-05-04 17:54:57,887 : INFO : torch.Size([168])
2017-05-04 17:54:57,887 : INFO : torch.Size([168, 168])
2017-05-04 17:54:57,887 : INFO : torch.Size([168])
2017-05-04 17:54:57,888 : INFO : torch.Size([3, 168])
2017-05-04 17:54:57,888 : INFO : torch.Size([3])
2017-05-04 17:54:57,888 : INFO : sum
2017-05-04 17:54:57,888 : INFO : 316347
2017-05-04 17:54:57,888 : INFO : ____________
2017-05-04 18:13:31,171 : INFO : ==> Train loss   : 0.549521
2017-05-04 18:13:31,172 : INFO : Epoch
2017-05-04 18:13:31,172 : INFO : 0
2017-05-04 18:13:31,172 : INFO : train percentage
2017-05-04 18:13:31,172 : INFO : 0.846242774566
2017-05-04 18:13:31,172 : INFO : Epoch
2017-05-04 18:13:31,172 : INFO : 0
2017-05-04 18:13:31,172 : INFO : dev percentage
2017-05-04 18:13:31,172 : INFO : 0.745412844037
2017-05-04 18:13:31,172 : INFO : Epoch
2017-05-04 18:13:31,173 : INFO : 0
2017-05-04 18:13:31,173 : INFO : test percentage
2017-05-04 18:13:31,173 : INFO : 0.728720483251
2017-05-04 18:32:07,170 : INFO : ==> Train loss   : 0.282773
2017-05-04 18:32:07,170 : INFO : Epoch
2017-05-04 18:32:07,170 : INFO : 1
2017-05-04 18:32:07,170 : INFO : train percentage
2017-05-04 18:32:07,170 : INFO : 0.920953757225
2017-05-04 18:32:07,170 : INFO : Epoch
2017-05-04 18:32:07,170 : INFO : 1
2017-05-04 18:32:07,171 : INFO : dev percentage
2017-05-04 18:32:07,171 : INFO : 0.782110091743
2017-05-04 18:32:07,171 : INFO : Epoch
2017-05-04 18:32:07,171 : INFO : 1
2017-05-04 18:32:07,171 : INFO : test percentage
2017-05-04 18:32:07,171 : INFO : 0.783086216365
2017-05-04 18:50:44,038 : INFO : ==> Train loss   : 0.223778
2017-05-04 18:50:44,038 : INFO : Epoch
2017-05-04 18:50:44,038 : INFO : 2
2017-05-04 18:50:44,038 : INFO : train percentage
2017-05-04 18:50:44,038 : INFO : 0.944797687861
2017-05-04 18:50:44,039 : INFO : Epoch
2017-05-04 18:50:44,039 : INFO : 2
2017-05-04 18:50:44,039 : INFO : dev percentage
2017-05-04 18:50:44,039 : INFO : 0.783256880734
2017-05-04 18:50:44,039 : INFO : Epoch
2017-05-04 18:50:44,039 : INFO : 2
2017-05-04 18:50:44,039 : INFO : test percentage
2017-05-04 18:50:44,040 : INFO : 0.785282811642
2017-05-04 19:07:19,696 : INFO : LOG_FILE
2017-05-04 19:07:19,696 : INFO : _________________________________start___________________________________
2017-05-04 19:07:19,713 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-04 19:07:42,910 : INFO : LOG_FILE
2017-05-04 19:07:42,911 : INFO : _________________________________start___________________________________
2017-05-04 19:07:42,923 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-04 19:09:20,901 : INFO : ==> Train loss   : 0.189118
2017-05-04 19:09:20,902 : INFO : Epoch
2017-05-04 19:09:20,902 : INFO : 3
2017-05-04 19:09:20,902 : INFO : train percentage
2017-05-04 19:09:20,902 : INFO : 0.953323699422
2017-05-04 19:09:20,902 : INFO : Epoch
2017-05-04 19:09:20,902 : INFO : 3
2017-05-04 19:09:20,903 : INFO : dev percentage
2017-05-04 19:09:20,903 : INFO : 0.780963302752
2017-05-04 19:09:20,903 : INFO : Epoch
2017-05-04 19:09:20,903 : INFO : 3
2017-05-04 19:09:20,903 : INFO : test percentage
2017-05-04 19:09:20,903 : INFO : 0.79516749039
2017-05-04 19:12:53,000 : INFO : LOG_FILE
2017-05-04 19:12:53,001 : INFO : _________________________________start___________________________________
2017-05-04 19:12:53,014 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-04 19:12:53,418 : INFO : ==> SST vocabulary size : 21705
2017-05-04 19:12:53,419 : INFO : ==> SST rel vocabulary size : 48
2017-05-04 19:12:53,420 : INFO : ==> SST tag vocabulary size : 47
2017-05-04 19:27:46,187 : INFO : ==> Train loss   : 0.160672
2017-05-04 19:27:46,187 : INFO : Epoch
2017-05-04 19:27:46,187 : INFO : 4
2017-05-04 19:27:46,187 : INFO : train percentage
2017-05-04 19:27:46,187 : INFO : 0.961271676301
2017-05-04 19:27:46,187 : INFO : Epoch
2017-05-04 19:27:46,187 : INFO : 4
2017-05-04 19:27:46,188 : INFO : dev percentage
2017-05-04 19:27:46,188 : INFO : 0.782110091743
2017-05-04 19:27:46,188 : INFO : Epoch
2017-05-04 19:27:46,188 : INFO : 4
2017-05-04 19:27:46,188 : INFO : test percentage
2017-05-04 19:27:46,188 : INFO : 0.785282811642
2017-05-04 19:46:01,544 : INFO : ==> Train loss   : 0.135951
2017-05-04 19:46:01,544 : INFO : Epoch
2017-05-04 19:46:01,544 : INFO : 5
2017-05-04 19:46:01,545 : INFO : train percentage
2017-05-04 19:46:01,545 : INFO : 0.969219653179
2017-05-04 19:46:01,545 : INFO : Epoch
2017-05-04 19:46:01,545 : INFO : 5
2017-05-04 19:46:01,545 : INFO : dev percentage
2017-05-04 19:46:01,545 : INFO : 0.778669724771
2017-05-04 19:46:01,545 : INFO : Epoch
2017-05-04 19:46:01,545 : INFO : 5
2017-05-04 19:46:01,546 : INFO : test percentage
2017-05-04 19:46:01,546 : INFO : 0.785282811642
2017-05-04 20:04:47,175 : INFO : ==> Train loss   : 0.121479
2017-05-04 20:04:47,175 : INFO : Epoch
2017-05-04 20:04:47,175 : INFO : 6
2017-05-04 20:04:47,175 : INFO : train percentage
2017-05-04 20:04:47,175 : INFO : 0.974566473988
2017-05-04 20:04:47,175 : INFO : Epoch
2017-05-04 20:04:47,175 : INFO : 6
2017-05-04 20:04:47,176 : INFO : dev percentage
2017-05-04 20:04:47,176 : INFO : 0.77752293578
2017-05-04 20:04:47,176 : INFO : Epoch
2017-05-04 20:04:47,176 : INFO : 6
2017-05-04 20:04:47,176 : INFO : test percentage
2017-05-04 20:04:47,176 : INFO : 0.784184514003
2017-05-04 20:23:55,497 : INFO : ==> Train loss   : 0.106062
2017-05-04 20:23:55,498 : INFO : Epoch
2017-05-04 20:23:55,498 : INFO : 7
2017-05-04 20:23:55,498 : INFO : train percentage
2017-05-04 20:23:55,498 : INFO : 0.975289017341
2017-05-04 20:23:55,498 : INFO : Epoch
2017-05-04 20:23:55,498 : INFO : 7
2017-05-04 20:23:55,498 : INFO : dev percentage
2017-05-04 20:23:55,498 : INFO : 0.770642201835
2017-05-04 20:23:55,499 : INFO : Epoch
2017-05-04 20:23:55,499 : INFO : 7
2017-05-04 20:23:55,499 : INFO : test percentage
2017-05-04 20:23:55,499 : INFO : 0.783086216365
2017-05-04 20:43:07,681 : INFO : ==> Train loss   : 0.100508
2017-05-04 20:43:07,681 : INFO : Epoch
2017-05-04 20:43:07,681 : INFO : 8
2017-05-04 20:43:07,682 : INFO : train percentage
2017-05-04 20:43:07,682 : INFO : 0.978034682081
2017-05-04 20:43:07,682 : INFO : Epoch
2017-05-04 20:43:07,682 : INFO : 8
2017-05-04 20:43:07,682 : INFO : dev percentage
2017-05-04 20:43:07,682 : INFO : 0.760321100917
2017-05-04 20:43:07,682 : INFO : Epoch
2017-05-04 20:43:07,682 : INFO : 8
2017-05-04 20:43:07,683 : INFO : test percentage
2017-05-04 20:43:07,683 : INFO : 0.783635365184
2017-05-04 21:01:52,489 : INFO : ==> Train loss   : 0.085978
2017-05-04 21:01:52,489 : INFO : Epoch
2017-05-04 21:01:52,489 : INFO : 9
2017-05-04 21:01:52,490 : INFO : train percentage
2017-05-04 21:01:52,490 : INFO : 0.98063583815
2017-05-04 21:01:52,490 : INFO : Epoch
2017-05-04 21:01:52,490 : INFO : 9
2017-05-04 21:01:52,490 : INFO : dev percentage
2017-05-04 21:01:52,490 : INFO : 0.772935779817
2017-05-04 21:01:52,490 : INFO : Epoch
2017-05-04 21:01:52,490 : INFO : 9
2017-05-04 21:01:52,491 : INFO : test percentage
2017-05-04 21:01:52,491 : INFO : 0.788577704558
2017-05-04 21:19:11,438 : INFO : ==> Train loss   : 0.087751
2017-05-04 21:19:11,438 : INFO : Epoch
2017-05-04 21:19:11,439 : INFO : 10
2017-05-04 21:19:11,439 : INFO : train percentage
2017-05-04 21:19:11,439 : INFO : 0.98323699422
2017-05-04 21:19:11,439 : INFO : Epoch
2017-05-04 21:19:11,439 : INFO : 10
2017-05-04 21:19:11,439 : INFO : dev percentage
2017-05-04 21:19:11,439 : INFO : 0.767201834862
2017-05-04 21:19:11,440 : INFO : Epoch
2017-05-04 21:19:11,440 : INFO : 10
2017-05-04 21:19:11,440 : INFO : test percentage
2017-05-04 21:19:11,440 : INFO : 0.796265788029
2017-05-04 21:36:42,686 : INFO : ==> Train loss   : 0.079244
2017-05-04 21:36:42,686 : INFO : Epoch
2017-05-04 21:36:42,686 : INFO : 11
2017-05-04 21:36:42,686 : INFO : train percentage
2017-05-04 21:36:42,687 : INFO : 0.98338150289
2017-05-04 21:36:42,687 : INFO : Epoch
2017-05-04 21:36:42,687 : INFO : 11
2017-05-04 21:36:42,687 : INFO : dev percentage
2017-05-04 21:36:42,687 : INFO : 0.766055045872
2017-05-04 21:36:42,687 : INFO : Epoch
2017-05-04 21:36:42,687 : INFO : 11
2017-05-04 21:36:42,688 : INFO : test percentage
2017-05-04 21:36:42,688 : INFO : 0.788028555739
2017-05-04 22:27:57,672 : INFO : LOG_FILE
2017-05-04 22:27:57,673 : INFO : _________________________________start___________________________________
2017-05-04 22:27:57,708 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-04 22:27:58,118 : INFO : ==> SST vocabulary size : 21705
2017-05-04 22:27:58,119 : INFO : ==> SST rel vocabulary size : 48
2017-05-04 22:27:58,120 : INFO : ==> SST tag vocabulary size : 47
2017-05-04 22:28:45,936 : INFO : LOG_FILE
2017-05-04 22:28:45,936 : INFO : _________________________________start___________________________________
2017-05-04 22:28:45,970 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-04 22:28:46,376 : INFO : ==> SST vocabulary size : 21705
2017-05-04 22:28:46,377 : INFO : ==> SST rel vocabulary size : 48
2017-05-04 22:28:46,377 : INFO : ==> SST tag vocabulary size : 47
2017-05-04 22:29:11,947 : INFO : LOG_FILE
2017-05-04 22:29:11,948 : INFO : _________________________________start___________________________________
2017-05-04 22:29:11,982 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-04 22:29:12,393 : INFO : ==> SST vocabulary size : 21705
2017-05-04 22:29:12,393 : INFO : ==> SST rel vocabulary size : 48
2017-05-04 22:29:12,394 : INFO : ==> SST tag vocabulary size : 47
2017-05-04 22:29:18,536 : INFO : _param count_
2017-05-04 22:29:18,539 : INFO : torch.Size([168, 300])
2017-05-04 22:29:18,540 : INFO : torch.Size([168])
2017-05-04 22:29:18,540 : INFO : torch.Size([168, 168])
2017-05-04 22:29:18,541 : INFO : torch.Size([168])
2017-05-04 22:29:18,541 : INFO : torch.Size([168, 300])
2017-05-04 22:29:18,542 : INFO : torch.Size([168])
2017-05-04 22:29:18,543 : INFO : torch.Size([168, 168])
2017-05-04 22:29:18,543 : INFO : torch.Size([168])
2017-05-04 22:29:18,544 : INFO : torch.Size([168, 300])
2017-05-04 22:29:18,544 : INFO : torch.Size([168])
2017-05-04 22:29:18,545 : INFO : torch.Size([168, 168])
2017-05-04 22:29:18,546 : INFO : torch.Size([168])
2017-05-04 22:29:18,546 : INFO : torch.Size([168, 300])
2017-05-04 22:29:18,547 : INFO : torch.Size([168])
2017-05-04 22:29:18,547 : INFO : torch.Size([168, 168])
2017-05-04 22:29:18,548 : INFO : torch.Size([168])
2017-05-04 22:29:18,548 : INFO : torch.Size([3, 168])
2017-05-04 22:29:18,549 : INFO : torch.Size([3])
2017-05-04 22:29:18,550 : INFO : torch.Size([47, 300])
2017-05-04 22:29:18,550 : INFO : torch.Size([48, 300])
2017-05-04 22:29:18,551 : INFO : sum
2017-05-04 22:29:18,551 : INFO : 344847
2017-05-04 22:29:18,552 : INFO : ____________
2017-05-04 22:39:28,353 : INFO : LOG_FILE
2017-05-04 22:39:28,354 : INFO : _________________________________start___________________________________
2017-05-04 22:39:28,387 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-04 22:39:28,795 : INFO : ==> SST vocabulary size : 21705
2017-05-04 22:39:28,796 : INFO : ==> SST rel vocabulary size : 48
2017-05-04 22:39:28,797 : INFO : ==> SST tag vocabulary size : 47
2017-05-04 22:39:34,777 : INFO : _param count_
2017-05-04 22:39:34,779 : INFO : torch.Size([168, 300])
2017-05-04 22:39:34,780 : INFO : torch.Size([168])
2017-05-04 22:39:34,780 : INFO : torch.Size([168, 168])
2017-05-04 22:39:34,781 : INFO : torch.Size([168])
2017-05-04 22:39:34,782 : INFO : torch.Size([168, 300])
2017-05-04 22:39:34,782 : INFO : torch.Size([168])
2017-05-04 22:39:34,783 : INFO : torch.Size([168, 168])
2017-05-04 22:39:34,783 : INFO : torch.Size([168])
2017-05-04 22:39:34,784 : INFO : torch.Size([168, 300])
2017-05-04 22:39:34,785 : INFO : torch.Size([168])
2017-05-04 22:39:34,785 : INFO : torch.Size([168, 168])
2017-05-04 22:39:34,786 : INFO : torch.Size([168])
2017-05-04 22:39:34,786 : INFO : torch.Size([168, 300])
2017-05-04 22:39:34,787 : INFO : torch.Size([168])
2017-05-04 22:39:34,787 : INFO : torch.Size([168, 168])
2017-05-04 22:39:34,788 : INFO : torch.Size([168])
2017-05-04 22:39:34,788 : INFO : torch.Size([3, 168])
2017-05-04 22:39:34,789 : INFO : torch.Size([3])
2017-05-04 22:39:34,790 : INFO : torch.Size([47, 300])
2017-05-04 22:39:34,790 : INFO : torch.Size([48, 300])
2017-05-04 22:39:34,791 : INFO : sum
2017-05-04 22:39:34,791 : INFO : 344847
2017-05-04 22:39:34,792 : INFO : ____________
2017-05-04 22:39:44,904 : INFO : LOG_FILE
2017-05-04 22:39:44,905 : INFO : _________________________________start___________________________________
2017-05-04 22:39:44,939 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-04 22:39:45,351 : INFO : ==> SST vocabulary size : 21705
2017-05-04 22:39:45,352 : INFO : ==> SST rel vocabulary size : 48
2017-05-04 22:39:45,353 : INFO : ==> SST tag vocabulary size : 47
2017-05-04 22:48:14,377 : INFO : LOG_FILE
2017-05-04 22:48:14,378 : INFO : _________________________________start___________________________________
2017-05-04 22:48:14,413 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-04 22:48:14,836 : INFO : ==> SST vocabulary size : 21705
2017-05-04 22:48:14,837 : INFO : ==> SST rel vocabulary size : 48
2017-05-04 22:48:14,837 : INFO : ==> SST tag vocabulary size : 47
2017-05-04 22:51:30,058 : INFO : LOG_FILE
2017-05-04 22:51:30,058 : INFO : _________________________________start___________________________________
2017-05-04 22:51:30,095 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-04 22:51:30,508 : INFO : ==> SST vocabulary size : 21705
2017-05-04 22:51:30,508 : INFO : ==> SST rel vocabulary size : 48
2017-05-04 22:51:30,509 : INFO : ==> SST tag vocabulary size : 47
2017-05-04 23:06:02,746 : INFO : LOG_FILE
2017-05-04 23:06:02,746 : INFO : _________________________________start___________________________________
2017-05-04 23:06:02,783 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-04 23:06:03,192 : INFO : ==> SST vocabulary size : 21705
2017-05-04 23:06:03,193 : INFO : ==> SST rel vocabulary size : 48
2017-05-04 23:06:03,194 : INFO : ==> SST tag vocabulary size : 47
2017-05-04 23:11:02,016 : INFO : LOG_FILE
2017-05-04 23:11:02,016 : INFO : _________________________________start___________________________________
2017-05-04 23:11:02,051 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-04 23:11:02,456 : INFO : ==> SST vocabulary size : 21705
2017-05-04 23:11:02,456 : INFO : ==> SST rel vocabulary size : 48
2017-05-04 23:11:02,457 : INFO : ==> SST tag vocabulary size : 47
2017-05-04 23:14:48,986 : INFO : LOG_FILE
2017-05-04 23:14:48,987 : INFO : _________________________________start___________________________________
2017-05-04 23:14:49,020 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-04 23:14:49,428 : INFO : ==> SST vocabulary size : 21705
2017-05-04 23:14:49,428 : INFO : ==> SST rel vocabulary size : 48
2017-05-04 23:14:49,429 : INFO : ==> SST tag vocabulary size : 47
2017-05-04 23:16:04,683 : INFO : LOG_FILE
2017-05-04 23:16:04,683 : INFO : _________________________________start___________________________________
2017-05-04 23:16:04,716 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-04 23:16:05,127 : INFO : ==> SST vocabulary size : 21705
2017-05-04 23:16:05,127 : INFO : ==> SST rel vocabulary size : 48
2017-05-04 23:16:05,128 : INFO : ==> SST tag vocabulary size : 47
2017-05-04 23:19:08,308 : INFO : LOG_FILE
2017-05-04 23:19:08,308 : INFO : _________________________________start___________________________________
2017-05-04 23:19:08,344 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-04 23:19:08,570 : INFO : ==> SST vocabulary size : 21705
2017-05-04 23:19:08,570 : INFO : ==> SST rel vocabulary size : 48
2017-05-04 23:19:08,570 : INFO : ==> SST tag vocabulary size : 47
2017-05-04 23:19:49,210 : INFO : LOG_FILE
2017-05-04 23:19:49,211 : INFO : _________________________________start___________________________________
2017-05-04 23:19:49,238 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-04 23:19:49,451 : INFO : ==> SST vocabulary size : 21705
2017-05-04 23:19:49,451 : INFO : ==> SST rel vocabulary size : 48
2017-05-04 23:19:49,451 : INFO : ==> SST tag vocabulary size : 47
2017-05-04 23:20:41,148 : INFO : LOG_FILE
2017-05-04 23:20:41,149 : INFO : _________________________________start___________________________________
2017-05-04 23:20:41,176 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-04 23:20:41,385 : INFO : ==> SST vocabulary size : 21705
2017-05-04 23:20:41,385 : INFO : ==> SST rel vocabulary size : 48
2017-05-04 23:20:41,385 : INFO : ==> SST tag vocabulary size : 47
2017-05-04 23:20:50,104 : INFO : _param count_
2017-05-04 23:20:50,104 : INFO : torch.Size([168, 300])
2017-05-04 23:20:50,105 : INFO : torch.Size([168])
2017-05-04 23:20:50,105 : INFO : torch.Size([168, 168])
2017-05-04 23:20:50,105 : INFO : torch.Size([168])
2017-05-04 23:20:50,105 : INFO : torch.Size([168, 300])
2017-05-04 23:20:50,105 : INFO : torch.Size([168])
2017-05-04 23:20:50,105 : INFO : torch.Size([168, 168])
2017-05-04 23:20:50,105 : INFO : torch.Size([168])
2017-05-04 23:20:50,106 : INFO : torch.Size([168, 300])
2017-05-04 23:20:50,106 : INFO : torch.Size([168])
2017-05-04 23:20:50,106 : INFO : torch.Size([168, 168])
2017-05-04 23:20:50,106 : INFO : torch.Size([168])
2017-05-04 23:20:50,106 : INFO : torch.Size([168, 300])
2017-05-04 23:20:50,106 : INFO : torch.Size([168])
2017-05-04 23:20:50,106 : INFO : torch.Size([168, 168])
2017-05-04 23:20:50,106 : INFO : torch.Size([168])
2017-05-04 23:20:50,107 : INFO : torch.Size([3, 168])
2017-05-04 23:20:50,107 : INFO : torch.Size([3])
2017-05-04 23:20:50,107 : INFO : torch.Size([47, 300])
2017-05-04 23:20:50,107 : INFO : torch.Size([48, 300])
2017-05-04 23:20:50,107 : INFO : sum
2017-05-04 23:20:50,107 : INFO : 344847
2017-05-04 23:20:50,107 : INFO : ____________
2017-05-04 23:20:50,107 : INFO : ==> File found, loading to memory
2017-05-04 23:20:56,105 : INFO : ==> GLOVE vocabulary size: 2196016
2017-05-04 23:20:56,820 : INFO : done creating emb, quit
2017-05-04 23:20:56,820 : INFO : quit program due to memory leak during preprocess data, please rerun sentiment.py
2017-05-04 23:46:01,494 : INFO : LOG_FILE
2017-05-04 23:46:01,494 : INFO : _________________________________start___________________________________
2017-05-04 23:46:01,525 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-04 23:46:01,738 : INFO : ==> SST vocabulary size : 21705
2017-05-04 23:46:01,738 : INFO : ==> SST rel vocabulary size : 48
2017-05-04 23:46:01,738 : INFO : ==> SST tag vocabulary size : 47
2017-05-04 23:47:46,396 : INFO : LOG_FILE
2017-05-04 23:47:46,397 : INFO : _________________________________start___________________________________
2017-05-04 23:47:46,427 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-04 23:47:46,637 : INFO : ==> SST vocabulary size : 21705
2017-05-04 23:47:46,637 : INFO : ==> SST rel vocabulary size : 48
2017-05-04 23:47:46,637 : INFO : ==> SST tag vocabulary size : 47
2017-05-04 23:48:41,246 : INFO : LOG_FILE
2017-05-04 23:48:41,246 : INFO : _________________________________start___________________________________
2017-05-04 23:48:41,278 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-04 23:48:41,487 : INFO : ==> SST vocabulary size : 21705
2017-05-04 23:48:41,487 : INFO : ==> SST rel vocabulary size : 48
2017-05-04 23:48:41,487 : INFO : ==> SST tag vocabulary size : 47
2017-05-04 23:48:47,825 : INFO : _param count_
2017-05-04 23:48:47,826 : INFO : torch.Size([168, 300])
2017-05-04 23:48:47,826 : INFO : torch.Size([168])
2017-05-04 23:48:47,826 : INFO : torch.Size([168, 168])
2017-05-04 23:48:47,827 : INFO : torch.Size([168])
2017-05-04 23:48:47,827 : INFO : torch.Size([168, 300])
2017-05-04 23:48:47,827 : INFO : torch.Size([168])
2017-05-04 23:48:47,827 : INFO : torch.Size([168, 168])
2017-05-04 23:48:47,827 : INFO : torch.Size([168])
2017-05-04 23:48:47,827 : INFO : torch.Size([168, 300])
2017-05-04 23:48:47,828 : INFO : torch.Size([168])
2017-05-04 23:48:47,828 : INFO : torch.Size([168, 168])
2017-05-04 23:48:47,828 : INFO : torch.Size([168])
2017-05-04 23:48:47,828 : INFO : torch.Size([168, 300])
2017-05-04 23:48:47,828 : INFO : torch.Size([168])
2017-05-04 23:48:47,828 : INFO : torch.Size([168, 168])
2017-05-04 23:48:47,828 : INFO : torch.Size([168])
2017-05-04 23:48:47,829 : INFO : torch.Size([3, 168])
2017-05-04 23:48:47,829 : INFO : torch.Size([3])
2017-05-04 23:48:47,829 : INFO : torch.Size([21705, 300])
2017-05-04 23:48:47,829 : INFO : torch.Size([47, 300])
2017-05-04 23:48:47,829 : INFO : torch.Size([48, 300])
2017-05-04 23:48:47,829 : INFO : sum
2017-05-04 23:48:47,829 : INFO : 6856347
2017-05-04 23:48:47,830 : INFO : ____________
2017-05-04 23:49:49,237 : INFO : LOG_FILE
2017-05-04 23:49:49,238 : INFO : _________________________________start___________________________________
2017-05-04 23:49:49,273 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-04 23:49:49,686 : INFO : ==> SST vocabulary size : 21705
2017-05-04 23:49:49,687 : INFO : ==> SST rel vocabulary size : 48
2017-05-04 23:49:49,687 : INFO : ==> SST tag vocabulary size : 47
2017-05-04 23:49:57,557 : INFO : _param count_
2017-05-04 23:49:57,560 : INFO : torch.Size([168, 300])
2017-05-04 23:49:57,561 : INFO : torch.Size([168])
2017-05-04 23:49:57,561 : INFO : torch.Size([168, 168])
2017-05-04 23:49:57,562 : INFO : torch.Size([168])
2017-05-04 23:49:57,562 : INFO : torch.Size([168, 300])
2017-05-04 23:49:57,563 : INFO : torch.Size([168])
2017-05-04 23:49:57,564 : INFO : torch.Size([168, 168])
2017-05-04 23:49:57,564 : INFO : torch.Size([168])
2017-05-04 23:49:57,565 : INFO : torch.Size([168, 300])
2017-05-04 23:49:57,565 : INFO : torch.Size([168])
2017-05-04 23:49:57,566 : INFO : torch.Size([168, 168])
2017-05-04 23:49:57,566 : INFO : torch.Size([168])
2017-05-04 23:49:57,567 : INFO : torch.Size([168, 300])
2017-05-04 23:49:57,568 : INFO : torch.Size([168])
2017-05-04 23:49:57,568 : INFO : torch.Size([168, 168])
2017-05-04 23:49:57,569 : INFO : torch.Size([168])
2017-05-04 23:49:57,569 : INFO : torch.Size([3, 168])
2017-05-04 23:49:57,570 : INFO : torch.Size([3])
2017-05-04 23:49:57,571 : INFO : torch.Size([21705, 300])
2017-05-04 23:49:57,571 : INFO : torch.Size([47, 300])
2017-05-04 23:49:57,572 : INFO : torch.Size([48, 300])
2017-05-04 23:49:57,572 : INFO : sum
2017-05-04 23:49:57,573 : INFO : 6856347
2017-05-04 23:49:57,573 : INFO : ____________
2017-05-04 23:50:43,491 : INFO : LOG_FILE
2017-05-04 23:50:43,492 : INFO : _________________________________start___________________________________
2017-05-04 23:50:43,524 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-04 23:50:43,940 : INFO : ==> SST vocabulary size : 21705
2017-05-04 23:50:43,940 : INFO : ==> SST rel vocabulary size : 48
2017-05-04 23:50:43,941 : INFO : ==> SST tag vocabulary size : 47
2017-05-04 23:50:51,699 : INFO : _param count_
2017-05-04 23:50:51,702 : INFO : torch.Size([168, 300])
2017-05-04 23:50:51,703 : INFO : torch.Size([168])
2017-05-04 23:50:51,704 : INFO : torch.Size([168, 168])
2017-05-04 23:50:51,704 : INFO : torch.Size([168])
2017-05-04 23:50:51,705 : INFO : torch.Size([168, 300])
2017-05-04 23:50:51,705 : INFO : torch.Size([168])
2017-05-04 23:50:51,706 : INFO : torch.Size([168, 168])
2017-05-04 23:50:51,706 : INFO : torch.Size([168])
2017-05-04 23:50:51,707 : INFO : torch.Size([168, 300])
2017-05-04 23:50:51,708 : INFO : torch.Size([168])
2017-05-04 23:50:51,708 : INFO : torch.Size([168, 168])
2017-05-04 23:50:51,709 : INFO : torch.Size([168])
2017-05-04 23:50:51,709 : INFO : torch.Size([168, 300])
2017-05-04 23:50:51,710 : INFO : torch.Size([168])
2017-05-04 23:50:51,711 : INFO : torch.Size([168, 168])
2017-05-04 23:50:51,711 : INFO : torch.Size([168])
2017-05-04 23:50:51,712 : INFO : torch.Size([3, 168])
2017-05-04 23:50:51,712 : INFO : torch.Size([3])
2017-05-04 23:50:51,713 : INFO : torch.Size([21705, 300])
2017-05-04 23:50:51,713 : INFO : torch.Size([47, 300])
2017-05-04 23:50:51,714 : INFO : torch.Size([48, 300])
2017-05-04 23:50:51,715 : INFO : sum
2017-05-04 23:50:51,715 : INFO : 6856347
2017-05-04 23:50:51,716 : INFO : ____________
2017-05-04 23:51:32,893 : INFO : LOG_FILE
2017-05-04 23:51:32,894 : INFO : _________________________________start___________________________________
2017-05-04 23:51:32,928 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-04 23:51:33,349 : INFO : ==> SST vocabulary size : 21705
2017-05-04 23:51:33,350 : INFO : ==> SST rel vocabulary size : 48
2017-05-04 23:51:33,351 : INFO : ==> SST tag vocabulary size : 47
2017-05-04 23:51:40,970 : INFO : _param count_
2017-05-04 23:51:40,973 : INFO : torch.Size([168, 300])
2017-05-04 23:51:40,973 : INFO : torch.Size([168])
2017-05-04 23:51:40,974 : INFO : torch.Size([168, 168])
2017-05-04 23:51:40,975 : INFO : torch.Size([168])
2017-05-04 23:51:40,975 : INFO : torch.Size([168, 300])
2017-05-04 23:51:40,976 : INFO : torch.Size([168])
2017-05-04 23:51:40,976 : INFO : torch.Size([168, 168])
2017-05-04 23:51:40,977 : INFO : torch.Size([168])
2017-05-04 23:51:40,977 : INFO : torch.Size([168, 300])
2017-05-04 23:51:40,978 : INFO : torch.Size([168])
2017-05-04 23:51:40,978 : INFO : torch.Size([168, 168])
2017-05-04 23:51:40,979 : INFO : torch.Size([168])
2017-05-04 23:51:40,979 : INFO : torch.Size([168, 300])
2017-05-04 23:51:40,980 : INFO : torch.Size([168])
2017-05-04 23:51:40,981 : INFO : torch.Size([168, 168])
2017-05-04 23:51:40,981 : INFO : torch.Size([168])
2017-05-04 23:51:40,982 : INFO : torch.Size([3, 168])
2017-05-04 23:51:40,982 : INFO : torch.Size([3])
2017-05-04 23:51:40,983 : INFO : torch.Size([21705, 300])
2017-05-04 23:51:40,983 : INFO : torch.Size([47, 300])
2017-05-04 23:51:40,984 : INFO : torch.Size([48, 300])
2017-05-04 23:51:40,985 : INFO : sum
2017-05-04 23:51:40,985 : INFO : 6856347
2017-05-04 23:51:40,986 : INFO : ____________
2017-05-04 23:52:56,518 : INFO : LOG_FILE
2017-05-04 23:52:56,519 : INFO : _________________________________start___________________________________
2017-05-04 23:52:56,552 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-04 23:52:56,966 : INFO : ==> SST vocabulary size : 21705
2017-05-04 23:52:56,967 : INFO : ==> SST rel vocabulary size : 48
2017-05-04 23:52:56,967 : INFO : ==> SST tag vocabulary size : 47
2017-05-04 23:53:04,550 : INFO : _param count_
2017-05-04 23:53:04,553 : INFO : torch.Size([168, 300])
2017-05-04 23:53:04,554 : INFO : torch.Size([168])
2017-05-04 23:53:04,554 : INFO : torch.Size([168, 168])
2017-05-04 23:53:04,555 : INFO : torch.Size([168])
2017-05-04 23:53:04,555 : INFO : torch.Size([168, 300])
2017-05-04 23:53:04,556 : INFO : torch.Size([168])
2017-05-04 23:53:04,557 : INFO : torch.Size([168, 168])
2017-05-04 23:53:04,557 : INFO : torch.Size([168])
2017-05-04 23:53:04,558 : INFO : torch.Size([168, 300])
2017-05-04 23:53:04,558 : INFO : torch.Size([168])
2017-05-04 23:53:04,559 : INFO : torch.Size([168, 168])
2017-05-04 23:53:04,559 : INFO : torch.Size([168])
2017-05-04 23:53:04,560 : INFO : torch.Size([168, 300])
2017-05-04 23:53:04,560 : INFO : torch.Size([168])
2017-05-04 23:53:04,561 : INFO : torch.Size([168, 168])
2017-05-04 23:53:04,562 : INFO : torch.Size([168])
2017-05-04 23:53:04,562 : INFO : torch.Size([3, 168])
2017-05-04 23:53:04,563 : INFO : torch.Size([3])
2017-05-04 23:53:04,563 : INFO : torch.Size([21705, 300])
2017-05-04 23:53:04,564 : INFO : torch.Size([47, 300])
2017-05-04 23:53:04,564 : INFO : torch.Size([48, 300])
2017-05-04 23:53:04,565 : INFO : sum
2017-05-04 23:53:04,565 : INFO : 6856347
2017-05-04 23:53:04,566 : INFO : ____________
2017-05-04 23:59:47,964 : INFO : LOG_FILE
2017-05-04 23:59:47,964 : INFO : _________________________________start___________________________________
2017-05-04 23:59:47,992 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-04 23:59:48,205 : INFO : ==> SST vocabulary size : 21705
2017-05-04 23:59:48,205 : INFO : ==> SST rel vocabulary size : 48
2017-05-04 23:59:48,206 : INFO : ==> SST tag vocabulary size : 47
2017-05-04 23:59:54,436 : INFO : _param count_
2017-05-04 23:59:54,437 : INFO : torch.Size([168, 300])
2017-05-04 23:59:54,437 : INFO : torch.Size([168])
2017-05-04 23:59:54,437 : INFO : torch.Size([168, 168])
2017-05-04 23:59:54,437 : INFO : torch.Size([168])
2017-05-04 23:59:54,437 : INFO : torch.Size([168, 300])
2017-05-04 23:59:54,437 : INFO : torch.Size([168])
2017-05-04 23:59:54,438 : INFO : torch.Size([168, 168])
2017-05-04 23:59:54,438 : INFO : torch.Size([168])
2017-05-04 23:59:54,438 : INFO : torch.Size([168, 300])
2017-05-04 23:59:54,438 : INFO : torch.Size([168])
2017-05-04 23:59:54,438 : INFO : torch.Size([168, 168])
2017-05-04 23:59:54,438 : INFO : torch.Size([168])
2017-05-04 23:59:54,438 : INFO : torch.Size([168, 300])
2017-05-04 23:59:54,438 : INFO : torch.Size([168])
2017-05-04 23:59:54,439 : INFO : torch.Size([168, 168])
2017-05-04 23:59:54,439 : INFO : torch.Size([168])
2017-05-04 23:59:54,439 : INFO : torch.Size([3, 168])
2017-05-04 23:59:54,439 : INFO : torch.Size([3])
2017-05-04 23:59:54,439 : INFO : torch.Size([21705, 300])
2017-05-04 23:59:54,439 : INFO : torch.Size([47, 300])
2017-05-04 23:59:54,439 : INFO : torch.Size([48, 300])
2017-05-04 23:59:54,440 : INFO : sum
2017-05-04 23:59:54,440 : INFO : 6856347
2017-05-04 23:59:54,440 : INFO : ____________
2017-05-05 00:50:30,841 : INFO : LOG_FILE
2017-05-05 00:50:30,841 : INFO : _________________________________start___________________________________
2017-05-05 00:50:30,874 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-05 00:50:31,292 : INFO : ==> SST vocabulary size : 21705
2017-05-05 00:50:31,293 : INFO : ==> SST rel vocabulary size : 48
2017-05-05 00:50:31,294 : INFO : ==> SST tag vocabulary size : 47
2017-05-05 00:50:38,910 : INFO : _param count_
2017-05-05 00:50:38,913 : INFO : torch.Size([168, 300])
2017-05-05 00:50:38,914 : INFO : torch.Size([168])
2017-05-05 00:50:38,914 : INFO : torch.Size([168, 168])
2017-05-05 00:50:38,915 : INFO : torch.Size([168])
2017-05-05 00:50:38,915 : INFO : torch.Size([168, 300])
2017-05-05 00:50:38,916 : INFO : torch.Size([168])
2017-05-05 00:50:38,916 : INFO : torch.Size([168, 168])
2017-05-05 00:50:38,917 : INFO : torch.Size([168])
2017-05-05 00:50:38,918 : INFO : torch.Size([168, 300])
2017-05-05 00:50:38,918 : INFO : torch.Size([168])
2017-05-05 00:50:38,919 : INFO : torch.Size([168, 168])
2017-05-05 00:50:38,919 : INFO : torch.Size([168])
2017-05-05 00:50:38,920 : INFO : torch.Size([168, 300])
2017-05-05 00:50:38,920 : INFO : torch.Size([168])
2017-05-05 00:50:38,921 : INFO : torch.Size([168, 168])
2017-05-05 00:50:38,921 : INFO : torch.Size([168])
2017-05-05 00:50:38,922 : INFO : torch.Size([3, 168])
2017-05-05 00:50:38,923 : INFO : torch.Size([3])
2017-05-05 00:50:38,923 : INFO : torch.Size([21705, 300])
2017-05-05 00:50:38,924 : INFO : torch.Size([47, 300])
2017-05-05 00:50:38,924 : INFO : torch.Size([48, 300])
2017-05-05 00:50:38,925 : INFO : sum
2017-05-05 00:50:38,926 : INFO : 6856347
2017-05-05 00:50:38,927 : INFO : ____________
2017-05-05 01:00:14,515 : INFO : LOG_FILE
2017-05-05 01:00:14,516 : INFO : _________________________________start___________________________________
2017-05-05 01:00:14,553 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-05 01:00:14,968 : INFO : ==> SST vocabulary size : 21705
2017-05-05 01:00:14,969 : INFO : ==> SST rel vocabulary size : 48
2017-05-05 01:00:14,969 : INFO : ==> SST tag vocabulary size : 47
2017-05-05 01:00:23,013 : INFO : _param count_
2017-05-05 01:00:23,015 : INFO : torch.Size([168, 300])
2017-05-05 01:00:23,016 : INFO : torch.Size([168])
2017-05-05 01:00:23,017 : INFO : torch.Size([168, 168])
2017-05-05 01:00:23,017 : INFO : torch.Size([168])
2017-05-05 01:00:23,018 : INFO : torch.Size([168, 300])
2017-05-05 01:00:23,018 : INFO : torch.Size([168])
2017-05-05 01:00:23,019 : INFO : torch.Size([168, 168])
2017-05-05 01:00:23,019 : INFO : torch.Size([168])
2017-05-05 01:00:23,020 : INFO : torch.Size([168, 300])
2017-05-05 01:00:23,020 : INFO : torch.Size([168])
2017-05-05 01:00:23,021 : INFO : torch.Size([168, 168])
2017-05-05 01:00:23,022 : INFO : torch.Size([168])
2017-05-05 01:00:23,022 : INFO : torch.Size([168, 300])
2017-05-05 01:00:23,023 : INFO : torch.Size([168])
2017-05-05 01:00:23,023 : INFO : torch.Size([168, 168])
2017-05-05 01:00:23,024 : INFO : torch.Size([168])
2017-05-05 01:00:23,025 : INFO : torch.Size([3, 168])
2017-05-05 01:00:23,025 : INFO : torch.Size([3])
2017-05-05 01:00:23,026 : INFO : torch.Size([21705, 300])
2017-05-05 01:00:23,026 : INFO : torch.Size([47, 300])
2017-05-05 01:00:23,027 : INFO : torch.Size([48, 300])
2017-05-05 01:00:23,028 : INFO : sum
2017-05-05 01:00:23,028 : INFO : 6856347
2017-05-05 01:00:23,029 : INFO : ____________
2017-05-05 01:00:40,112 : INFO : LOG_FILE
2017-05-05 01:00:40,113 : INFO : _________________________________start___________________________________
2017-05-05 01:00:40,146 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', seed=123, wd=0.0001)
2017-05-05 01:00:40,554 : INFO : ==> SST vocabulary size : 21705
2017-05-05 01:00:40,555 : INFO : ==> SST rel vocabulary size : 48
2017-05-05 01:00:40,555 : INFO : ==> SST tag vocabulary size : 47
2017-05-05 01:00:48,281 : INFO : _param count_
2017-05-05 01:00:48,283 : INFO : torch.Size([168, 300])
2017-05-05 01:00:48,284 : INFO : torch.Size([168])
2017-05-05 01:00:48,285 : INFO : torch.Size([168, 168])
2017-05-05 01:00:48,285 : INFO : torch.Size([168])
2017-05-05 01:00:48,286 : INFO : torch.Size([168, 300])
2017-05-05 01:00:48,286 : INFO : torch.Size([168])
2017-05-05 01:00:48,287 : INFO : torch.Size([168, 168])
2017-05-05 01:00:48,287 : INFO : torch.Size([168])
2017-05-05 01:00:48,288 : INFO : torch.Size([168, 300])
2017-05-05 01:00:48,289 : INFO : torch.Size([168])
2017-05-05 01:00:48,289 : INFO : torch.Size([168, 168])
2017-05-05 01:00:48,290 : INFO : torch.Size([168])
2017-05-05 01:00:48,290 : INFO : torch.Size([168, 300])
2017-05-05 01:00:48,291 : INFO : torch.Size([168])
2017-05-05 01:00:48,291 : INFO : torch.Size([168, 168])
2017-05-05 01:00:48,292 : INFO : torch.Size([168])
2017-05-05 01:00:48,293 : INFO : torch.Size([3, 168])
2017-05-05 01:00:48,293 : INFO : torch.Size([3])
2017-05-05 01:00:48,294 : INFO : torch.Size([21705, 300])
2017-05-05 01:00:48,294 : INFO : torch.Size([47, 300])
2017-05-05 01:00:48,295 : INFO : torch.Size([48, 300])
2017-05-05 01:00:48,295 : INFO : sum
2017-05-05 01:00:48,296 : INFO : 6856347
2017-05-05 01:00:48,296 : INFO : ____________
2017-05-05 01:07:00,746 : INFO : LOG_FILE
2017-05-05 01:07:00,747 : INFO : _________________________________start___________________________________
2017-05-05 01:07:00,782 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-05 01:07:01,190 : INFO : ==> SST vocabulary size : 21705
2017-05-05 01:07:01,191 : INFO : ==> SST rel vocabulary size : 48
2017-05-05 01:07:01,192 : INFO : ==> SST tag vocabulary size : 47
2017-05-05 01:07:08,766 : INFO : _param count_
2017-05-05 01:07:08,769 : INFO : torch.Size([168, 300])
2017-05-05 01:07:08,770 : INFO : torch.Size([168])
2017-05-05 01:07:08,770 : INFO : torch.Size([168, 168])
2017-05-05 01:07:08,771 : INFO : torch.Size([168])
2017-05-05 01:07:08,771 : INFO : torch.Size([168, 300])
2017-05-05 01:07:08,772 : INFO : torch.Size([168])
2017-05-05 01:07:08,772 : INFO : torch.Size([168, 168])
2017-05-05 01:07:08,773 : INFO : torch.Size([168])
2017-05-05 01:07:08,774 : INFO : torch.Size([168, 300])
2017-05-05 01:07:08,774 : INFO : torch.Size([168])
2017-05-05 01:07:08,775 : INFO : torch.Size([168, 168])
2017-05-05 01:07:08,775 : INFO : torch.Size([168])
2017-05-05 01:07:08,776 : INFO : torch.Size([168, 300])
2017-05-05 01:07:08,777 : INFO : torch.Size([168])
2017-05-05 01:07:08,777 : INFO : torch.Size([168, 168])
2017-05-05 01:07:08,778 : INFO : torch.Size([168])
2017-05-05 01:07:08,778 : INFO : torch.Size([3, 168])
2017-05-05 01:07:08,779 : INFO : torch.Size([3])
2017-05-05 01:07:08,779 : INFO : torch.Size([21705, 300])
2017-05-05 01:07:08,780 : INFO : torch.Size([47, 300])
2017-05-05 01:07:08,780 : INFO : torch.Size([48, 300])
2017-05-05 01:07:08,781 : INFO : sum
2017-05-05 01:07:08,782 : INFO : 6856347
2017-05-05 01:07:08,782 : INFO : ____________
2017-05-05 01:11:37,694 : INFO : LOG_FILE
2017-05-05 01:11:37,694 : INFO : _________________________________start___________________________________
2017-05-05 01:11:37,723 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-05 01:11:37,932 : INFO : ==> SST vocabulary size : 21705
2017-05-05 01:11:37,932 : INFO : ==> SST rel vocabulary size : 48
2017-05-05 01:11:37,932 : INFO : ==> SST tag vocabulary size : 47
2017-05-05 01:11:51,610 : INFO : _param count_
2017-05-05 01:11:51,611 : INFO : torch.Size([168, 300])
2017-05-05 01:11:51,611 : INFO : torch.Size([168])
2017-05-05 01:11:51,611 : INFO : torch.Size([168, 168])
2017-05-05 01:11:51,611 : INFO : torch.Size([168])
2017-05-05 01:11:51,611 : INFO : torch.Size([168, 300])
2017-05-05 01:11:51,611 : INFO : torch.Size([168])
2017-05-05 01:11:51,612 : INFO : torch.Size([168, 168])
2017-05-05 01:11:51,612 : INFO : torch.Size([168])
2017-05-05 01:11:51,612 : INFO : torch.Size([168, 300])
2017-05-05 01:11:51,612 : INFO : torch.Size([168])
2017-05-05 01:11:51,612 : INFO : torch.Size([168, 168])
2017-05-05 01:11:51,612 : INFO : torch.Size([168])
2017-05-05 01:11:51,612 : INFO : torch.Size([168, 300])
2017-05-05 01:11:51,613 : INFO : torch.Size([168])
2017-05-05 01:11:51,613 : INFO : torch.Size([168, 168])
2017-05-05 01:11:51,613 : INFO : torch.Size([168])
2017-05-05 01:11:51,613 : INFO : torch.Size([3, 168])
2017-05-05 01:11:51,613 : INFO : torch.Size([3])
2017-05-05 01:11:51,613 : INFO : torch.Size([21705, 300])
2017-05-05 01:11:51,613 : INFO : torch.Size([47, 300])
2017-05-05 01:11:51,613 : INFO : torch.Size([48, 300])
2017-05-05 01:11:51,614 : INFO : sum
2017-05-05 01:11:51,614 : INFO : 6856347
2017-05-05 01:11:51,614 : INFO : ____________
2017-05-05 01:11:51,614 : INFO : ==> File found, loading to memory
2017-05-05 01:11:57,145 : INFO : ==> GLOVE vocabulary size: 2196016
2017-05-05 01:11:57,782 : INFO : done creating emb, quit
2017-05-05 01:11:57,782 : INFO : quit program due to memory leak during preprocess data, please rerun sentiment.py
2017-05-05 01:13:15,515 : INFO : LOG_FILE
2017-05-05 01:13:15,515 : INFO : _________________________________start___________________________________
2017-05-05 01:13:15,544 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-05 01:13:15,751 : INFO : ==> SST vocabulary size : 21705
2017-05-05 01:13:15,751 : INFO : ==> SST rel vocabulary size : 48
2017-05-05 01:13:15,751 : INFO : ==> SST tag vocabulary size : 47
2017-05-05 01:13:21,864 : INFO : _param count_
2017-05-05 01:13:21,864 : INFO : torch.Size([168, 300])
2017-05-05 01:13:21,864 : INFO : torch.Size([168])
2017-05-05 01:13:21,865 : INFO : torch.Size([168, 168])
2017-05-05 01:13:21,865 : INFO : torch.Size([168])
2017-05-05 01:13:21,865 : INFO : torch.Size([168, 300])
2017-05-05 01:13:21,865 : INFO : torch.Size([168])
2017-05-05 01:13:21,865 : INFO : torch.Size([168, 168])
2017-05-05 01:13:21,865 : INFO : torch.Size([168])
2017-05-05 01:13:21,865 : INFO : torch.Size([168, 300])
2017-05-05 01:13:21,866 : INFO : torch.Size([168])
2017-05-05 01:13:21,866 : INFO : torch.Size([168, 168])
2017-05-05 01:13:21,866 : INFO : torch.Size([168])
2017-05-05 01:13:21,866 : INFO : torch.Size([168, 300])
2017-05-05 01:13:21,866 : INFO : torch.Size([168])
2017-05-05 01:13:21,866 : INFO : torch.Size([168, 168])
2017-05-05 01:13:21,866 : INFO : torch.Size([168])
2017-05-05 01:13:21,867 : INFO : torch.Size([3, 168])
2017-05-05 01:13:21,867 : INFO : torch.Size([3])
2017-05-05 01:13:21,867 : INFO : torch.Size([21705, 300])
2017-05-05 01:13:21,867 : INFO : torch.Size([47, 300])
2017-05-05 01:13:21,867 : INFO : torch.Size([48, 300])
2017-05-05 01:13:21,867 : INFO : sum
2017-05-05 01:13:21,867 : INFO : 6856347
2017-05-05 01:13:21,867 : INFO : ____________
2017-05-05 01:29:35,299 : INFO : LOG_FILE
2017-05-05 01:29:35,299 : INFO : _________________________________start___________________________________
2017-05-05 01:29:35,332 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-05 01:29:35,542 : INFO : ==> SST vocabulary size : 21705
2017-05-05 01:29:35,543 : INFO : ==> SST rel vocabulary size : 48
2017-05-05 01:29:35,543 : INFO : ==> SST tag vocabulary size : 47
2017-05-05 01:29:41,773 : INFO : _param count_
2017-05-05 01:29:41,774 : INFO : torch.Size([168, 300])
2017-05-05 01:29:41,774 : INFO : torch.Size([168])
2017-05-05 01:29:41,774 : INFO : torch.Size([168, 168])
2017-05-05 01:29:41,774 : INFO : torch.Size([168])
2017-05-05 01:29:41,774 : INFO : torch.Size([168, 300])
2017-05-05 01:29:41,775 : INFO : torch.Size([168])
2017-05-05 01:29:41,775 : INFO : torch.Size([168, 168])
2017-05-05 01:29:41,775 : INFO : torch.Size([168])
2017-05-05 01:29:41,775 : INFO : torch.Size([168, 300])
2017-05-05 01:29:41,775 : INFO : torch.Size([168])
2017-05-05 01:29:41,775 : INFO : torch.Size([168, 168])
2017-05-05 01:29:41,775 : INFO : torch.Size([168])
2017-05-05 01:29:41,776 : INFO : torch.Size([168, 300])
2017-05-05 01:29:41,776 : INFO : torch.Size([168])
2017-05-05 01:29:41,776 : INFO : torch.Size([168, 168])
2017-05-05 01:29:41,776 : INFO : torch.Size([168])
2017-05-05 01:29:41,776 : INFO : torch.Size([3, 168])
2017-05-05 01:29:41,776 : INFO : torch.Size([3])
2017-05-05 01:29:41,776 : INFO : torch.Size([21705, 300])
2017-05-05 01:29:41,776 : INFO : torch.Size([47, 300])
2017-05-05 01:29:41,777 : INFO : torch.Size([48, 300])
2017-05-05 01:29:41,777 : INFO : sum
2017-05-05 01:29:41,777 : INFO : 6856347
2017-05-05 01:29:41,777 : INFO : ____________
2017-05-05 02:02:52,634 : INFO : LOG_FILE
2017-05-05 02:02:52,634 : INFO : _________________________________start___________________________________
2017-05-05 02:02:52,665 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-05 02:02:52,876 : INFO : ==> SST vocabulary size : 21705
2017-05-05 02:02:52,876 : INFO : ==> SST rel vocabulary size : 48
2017-05-05 02:02:52,876 : INFO : ==> SST tag vocabulary size : 47
2017-05-05 02:02:59,135 : INFO : _param count_
2017-05-05 02:02:59,136 : INFO : torch.Size([168, 300])
2017-05-05 02:02:59,136 : INFO : torch.Size([168])
2017-05-05 02:02:59,136 : INFO : torch.Size([168, 168])
2017-05-05 02:02:59,136 : INFO : torch.Size([168])
2017-05-05 02:02:59,136 : INFO : torch.Size([168, 300])
2017-05-05 02:02:59,136 : INFO : torch.Size([168])
2017-05-05 02:02:59,137 : INFO : torch.Size([168, 168])
2017-05-05 02:02:59,137 : INFO : torch.Size([168])
2017-05-05 02:02:59,137 : INFO : torch.Size([168, 300])
2017-05-05 02:02:59,137 : INFO : torch.Size([168])
2017-05-05 02:02:59,137 : INFO : torch.Size([168, 168])
2017-05-05 02:02:59,137 : INFO : torch.Size([168])
2017-05-05 02:02:59,137 : INFO : torch.Size([168, 300])
2017-05-05 02:02:59,138 : INFO : torch.Size([168])
2017-05-05 02:02:59,138 : INFO : torch.Size([168, 168])
2017-05-05 02:02:59,138 : INFO : torch.Size([168])
2017-05-05 02:02:59,138 : INFO : torch.Size([3, 168])
2017-05-05 02:02:59,138 : INFO : torch.Size([3])
2017-05-05 02:02:59,138 : INFO : torch.Size([21705, 300])
2017-05-05 02:02:59,138 : INFO : torch.Size([47, 300])
2017-05-05 02:02:59,139 : INFO : torch.Size([48, 300])
2017-05-05 02:02:59,139 : INFO : sum
2017-05-05 02:02:59,139 : INFO : 6856347
2017-05-05 02:02:59,139 : INFO : ____________
2017-05-05 02:05:11,139 : INFO : LOG_FILE
2017-05-05 02:05:11,139 : INFO : _________________________________start___________________________________
2017-05-05 02:05:11,169 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-05 02:05:11,376 : INFO : ==> SST vocabulary size : 21705
2017-05-05 02:05:11,377 : INFO : ==> SST rel vocabulary size : 48
2017-05-05 02:05:11,377 : INFO : ==> SST tag vocabulary size : 47
2017-05-05 02:05:17,758 : INFO : _param count_
2017-05-05 02:05:17,759 : INFO : torch.Size([168, 300])
2017-05-05 02:05:17,759 : INFO : torch.Size([168])
2017-05-05 02:05:17,759 : INFO : torch.Size([168, 168])
2017-05-05 02:05:17,759 : INFO : torch.Size([168])
2017-05-05 02:05:17,759 : INFO : torch.Size([168, 300])
2017-05-05 02:05:17,759 : INFO : torch.Size([168])
2017-05-05 02:05:17,759 : INFO : torch.Size([168, 168])
2017-05-05 02:05:17,760 : INFO : torch.Size([168])
2017-05-05 02:05:17,760 : INFO : torch.Size([168, 300])
2017-05-05 02:05:17,760 : INFO : torch.Size([168])
2017-05-05 02:05:17,760 : INFO : torch.Size([168, 168])
2017-05-05 02:05:17,760 : INFO : torch.Size([168])
2017-05-05 02:05:17,760 : INFO : torch.Size([168, 300])
2017-05-05 02:05:17,760 : INFO : torch.Size([168])
2017-05-05 02:05:17,761 : INFO : torch.Size([168, 168])
2017-05-05 02:05:17,761 : INFO : torch.Size([168])
2017-05-05 02:05:17,761 : INFO : torch.Size([3, 168])
2017-05-05 02:05:17,761 : INFO : torch.Size([3])
2017-05-05 02:05:17,761 : INFO : torch.Size([21705, 300])
2017-05-05 02:05:17,761 : INFO : torch.Size([47, 300])
2017-05-05 02:05:17,761 : INFO : torch.Size([48, 300])
2017-05-05 02:05:17,762 : INFO : sum
2017-05-05 02:05:17,762 : INFO : 6856347
2017-05-05 02:05:17,762 : INFO : ____________
2017-05-05 02:09:26,149 : INFO : LOG_FILE
2017-05-05 02:09:26,149 : INFO : _________________________________start___________________________________
2017-05-05 02:09:26,176 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-05 02:09:26,391 : INFO : ==> SST vocabulary size : 21705
2017-05-05 02:09:26,391 : INFO : ==> SST rel vocabulary size : 48
2017-05-05 02:09:26,391 : INFO : ==> SST tag vocabulary size : 47
2017-05-05 02:09:32,626 : INFO : _param count_
2017-05-05 02:09:32,626 : INFO : torch.Size([168, 300])
2017-05-05 02:09:32,626 : INFO : torch.Size([168])
2017-05-05 02:09:32,626 : INFO : torch.Size([168, 168])
2017-05-05 02:09:32,627 : INFO : torch.Size([168])
2017-05-05 02:09:32,627 : INFO : torch.Size([168, 300])
2017-05-05 02:09:32,627 : INFO : torch.Size([168])
2017-05-05 02:09:32,627 : INFO : torch.Size([168, 168])
2017-05-05 02:09:32,627 : INFO : torch.Size([168])
2017-05-05 02:09:32,627 : INFO : torch.Size([168, 300])
2017-05-05 02:09:32,627 : INFO : torch.Size([168])
2017-05-05 02:09:32,628 : INFO : torch.Size([168, 168])
2017-05-05 02:09:32,628 : INFO : torch.Size([168])
2017-05-05 02:09:32,628 : INFO : torch.Size([168, 300])
2017-05-05 02:09:32,628 : INFO : torch.Size([168])
2017-05-05 02:09:32,628 : INFO : torch.Size([168, 168])
2017-05-05 02:09:32,628 : INFO : torch.Size([168])
2017-05-05 02:09:32,628 : INFO : torch.Size([3, 168])
2017-05-05 02:09:32,629 : INFO : torch.Size([3])
2017-05-05 02:09:32,629 : INFO : torch.Size([21705, 300])
2017-05-05 02:09:32,629 : INFO : torch.Size([47, 300])
2017-05-05 02:09:32,629 : INFO : torch.Size([48, 300])
2017-05-05 02:09:32,629 : INFO : sum
2017-05-05 02:09:32,629 : INFO : 6856347
2017-05-05 02:09:32,630 : INFO : ____________
2017-05-05 02:10:33,784 : INFO : LOG_FILE
2017-05-05 02:10:33,785 : INFO : _________________________________start___________________________________
2017-05-05 02:10:33,824 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-05 02:10:34,039 : INFO : ==> SST vocabulary size : 21705
2017-05-05 02:10:34,039 : INFO : ==> SST rel vocabulary size : 48
2017-05-05 02:10:34,040 : INFO : ==> SST tag vocabulary size : 47
2017-05-05 02:10:40,407 : INFO : _param count_
2017-05-05 02:10:40,408 : INFO : torch.Size([168, 300])
2017-05-05 02:10:40,408 : INFO : torch.Size([168])
2017-05-05 02:10:40,408 : INFO : torch.Size([168, 168])
2017-05-05 02:10:40,408 : INFO : torch.Size([168])
2017-05-05 02:10:40,408 : INFO : torch.Size([168, 300])
2017-05-05 02:10:40,408 : INFO : torch.Size([168])
2017-05-05 02:10:40,409 : INFO : torch.Size([168, 168])
2017-05-05 02:10:40,409 : INFO : torch.Size([168])
2017-05-05 02:10:40,409 : INFO : torch.Size([168, 300])
2017-05-05 02:10:40,409 : INFO : torch.Size([168])
2017-05-05 02:10:40,409 : INFO : torch.Size([168, 168])
2017-05-05 02:10:40,409 : INFO : torch.Size([168])
2017-05-05 02:10:40,410 : INFO : torch.Size([168, 300])
2017-05-05 02:10:40,410 : INFO : torch.Size([168])
2017-05-05 02:10:40,410 : INFO : torch.Size([168, 168])
2017-05-05 02:10:40,410 : INFO : torch.Size([168])
2017-05-05 02:10:40,410 : INFO : torch.Size([3, 168])
2017-05-05 02:10:40,410 : INFO : torch.Size([3])
2017-05-05 02:10:40,410 : INFO : torch.Size([21705, 300])
2017-05-05 02:10:40,411 : INFO : torch.Size([47, 300])
2017-05-05 02:10:40,411 : INFO : torch.Size([48, 300])
2017-05-05 02:10:40,411 : INFO : sum
2017-05-05 02:10:40,411 : INFO : 6856347
2017-05-05 02:10:40,411 : INFO : ____________
2017-05-05 02:10:45,844 : INFO : LOG_FILE
2017-05-05 02:10:45,844 : INFO : _________________________________start___________________________________
2017-05-05 02:10:45,857 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-05 02:10:46,273 : INFO : ==> SST vocabulary size : 21705
2017-05-05 02:10:46,274 : INFO : ==> SST rel vocabulary size : 48
2017-05-05 02:10:46,274 : INFO : ==> SST tag vocabulary size : 47
2017-05-05 02:10:59,228 : INFO : _param count_
2017-05-05 02:10:59,231 : INFO : torch.Size([168, 300])
2017-05-05 02:10:59,232 : INFO : torch.Size([168])
2017-05-05 02:10:59,232 : INFO : torch.Size([168, 168])
2017-05-05 02:10:59,233 : INFO : torch.Size([168])
2017-05-05 02:10:59,233 : INFO : torch.Size([168, 300])
2017-05-05 02:10:59,234 : INFO : torch.Size([168])
2017-05-05 02:10:59,234 : INFO : torch.Size([168, 168])
2017-05-05 02:10:59,235 : INFO : torch.Size([168])
2017-05-05 02:10:59,235 : INFO : torch.Size([168, 300])
2017-05-05 02:10:59,236 : INFO : torch.Size([168])
2017-05-05 02:10:59,237 : INFO : torch.Size([168, 168])
2017-05-05 02:10:59,237 : INFO : torch.Size([168])
2017-05-05 02:10:59,238 : INFO : torch.Size([168, 300])
2017-05-05 02:10:59,238 : INFO : torch.Size([168])
2017-05-05 02:10:59,239 : INFO : torch.Size([168, 168])
2017-05-05 02:10:59,240 : INFO : torch.Size([168])
2017-05-05 02:10:59,240 : INFO : torch.Size([3, 168])
2017-05-05 02:10:59,241 : INFO : torch.Size([3])
2017-05-05 02:10:59,241 : INFO : torch.Size([21705, 300])
2017-05-05 02:10:59,242 : INFO : torch.Size([47, 300])
2017-05-05 02:10:59,242 : INFO : torch.Size([48, 300])
2017-05-05 02:10:59,243 : INFO : sum
2017-05-05 02:10:59,243 : INFO : 6856347
2017-05-05 02:10:59,244 : INFO : ____________
2017-05-05 02:14:11,578 : INFO : LOG_FILE
2017-05-05 02:14:11,579 : INFO : _________________________________start___________________________________
2017-05-05 02:14:11,616 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-05 02:14:12,027 : INFO : ==> SST vocabulary size : 21705
2017-05-05 02:14:12,028 : INFO : ==> SST rel vocabulary size : 48
2017-05-05 02:14:12,028 : INFO : ==> SST tag vocabulary size : 47
2017-05-05 02:14:19,644 : INFO : _param count_
2017-05-05 02:14:19,647 : INFO : torch.Size([168, 300])
2017-05-05 02:14:19,647 : INFO : torch.Size([168])
2017-05-05 02:14:19,648 : INFO : torch.Size([168, 168])
2017-05-05 02:14:19,648 : INFO : torch.Size([168])
2017-05-05 02:14:19,649 : INFO : torch.Size([168, 300])
2017-05-05 02:14:19,649 : INFO : torch.Size([168])
2017-05-05 02:14:19,650 : INFO : torch.Size([168, 168])
2017-05-05 02:14:19,650 : INFO : torch.Size([168])
2017-05-05 02:14:19,651 : INFO : torch.Size([168, 300])
2017-05-05 02:14:19,651 : INFO : torch.Size([168])
2017-05-05 02:14:19,652 : INFO : torch.Size([168, 168])
2017-05-05 02:14:19,653 : INFO : torch.Size([168])
2017-05-05 02:14:19,653 : INFO : torch.Size([168, 300])
2017-05-05 02:14:19,654 : INFO : torch.Size([168])
2017-05-05 02:14:19,654 : INFO : torch.Size([168, 168])
2017-05-05 02:14:19,655 : INFO : torch.Size([168])
2017-05-05 02:14:19,656 : INFO : torch.Size([3, 168])
2017-05-05 02:14:19,656 : INFO : torch.Size([3])
2017-05-05 02:14:19,657 : INFO : torch.Size([21705, 300])
2017-05-05 02:14:19,657 : INFO : torch.Size([47, 300])
2017-05-05 02:14:19,658 : INFO : torch.Size([48, 300])
2017-05-05 02:14:19,658 : INFO : sum
2017-05-05 02:14:19,659 : INFO : 6856347
2017-05-05 02:14:19,659 : INFO : ____________
2017-05-05 02:16:24,164 : INFO : LOG_FILE
2017-05-05 02:16:24,165 : INFO : _________________________________start___________________________________
2017-05-05 02:16:24,200 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-05 02:16:24,613 : INFO : ==> SST vocabulary size : 21705
2017-05-05 02:16:24,614 : INFO : ==> SST rel vocabulary size : 48
2017-05-05 02:16:24,615 : INFO : ==> SST tag vocabulary size : 47
2017-05-05 02:16:32,253 : INFO : _param count_
2017-05-05 02:16:32,256 : INFO : torch.Size([168, 300])
2017-05-05 02:16:32,257 : INFO : torch.Size([168])
2017-05-05 02:16:32,258 : INFO : torch.Size([168, 168])
2017-05-05 02:16:32,258 : INFO : torch.Size([168])
2017-05-05 02:16:32,259 : INFO : torch.Size([168, 300])
2017-05-05 02:16:32,259 : INFO : torch.Size([168])
2017-05-05 02:16:32,260 : INFO : torch.Size([168, 168])
2017-05-05 02:16:32,261 : INFO : torch.Size([168])
2017-05-05 02:16:32,261 : INFO : torch.Size([168, 300])
2017-05-05 02:16:32,262 : INFO : torch.Size([168])
2017-05-05 02:16:32,262 : INFO : torch.Size([168, 168])
2017-05-05 02:16:32,263 : INFO : torch.Size([168])
2017-05-05 02:16:32,264 : INFO : torch.Size([168, 300])
2017-05-05 02:16:32,264 : INFO : torch.Size([168])
2017-05-05 02:16:32,265 : INFO : torch.Size([168, 168])
2017-05-05 02:16:32,265 : INFO : torch.Size([168])
2017-05-05 02:16:32,266 : INFO : torch.Size([3, 168])
2017-05-05 02:16:32,266 : INFO : torch.Size([3])
2017-05-05 02:16:32,267 : INFO : torch.Size([21705, 300])
2017-05-05 02:16:32,268 : INFO : torch.Size([47, 300])
2017-05-05 02:16:32,268 : INFO : torch.Size([48, 300])
2017-05-05 02:16:32,269 : INFO : sum
2017-05-05 02:16:32,269 : INFO : 6856347
2017-05-05 02:16:32,270 : INFO : ____________
2017-05-05 02:16:54,023 : INFO : LOG_FILE
2017-05-05 02:16:54,023 : INFO : _________________________________start___________________________________
2017-05-05 02:16:54,058 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-05 02:16:54,467 : INFO : ==> SST vocabulary size : 21705
2017-05-05 02:16:54,468 : INFO : ==> SST rel vocabulary size : 48
2017-05-05 02:16:54,468 : INFO : ==> SST tag vocabulary size : 47
2017-05-05 02:17:02,057 : INFO : _param count_
2017-05-05 02:17:02,060 : INFO : torch.Size([168, 300])
2017-05-05 02:17:02,061 : INFO : torch.Size([168])
2017-05-05 02:17:02,062 : INFO : torch.Size([168, 168])
2017-05-05 02:17:02,062 : INFO : torch.Size([168])
2017-05-05 02:17:02,063 : INFO : torch.Size([168, 300])
2017-05-05 02:17:02,064 : INFO : torch.Size([168])
2017-05-05 02:17:02,064 : INFO : torch.Size([168, 168])
2017-05-05 02:17:02,065 : INFO : torch.Size([168])
2017-05-05 02:17:02,065 : INFO : torch.Size([168, 300])
2017-05-05 02:17:02,066 : INFO : torch.Size([168])
2017-05-05 02:17:02,066 : INFO : torch.Size([168, 168])
2017-05-05 02:17:02,067 : INFO : torch.Size([168])
2017-05-05 02:17:02,068 : INFO : torch.Size([168, 300])
2017-05-05 02:17:02,068 : INFO : torch.Size([168])
2017-05-05 02:17:02,069 : INFO : torch.Size([168, 168])
2017-05-05 02:17:02,069 : INFO : torch.Size([168])
2017-05-05 02:17:02,070 : INFO : torch.Size([3, 168])
2017-05-05 02:17:02,070 : INFO : torch.Size([3])
2017-05-05 02:17:02,071 : INFO : torch.Size([21705, 300])
2017-05-05 02:17:02,072 : INFO : torch.Size([47, 300])
2017-05-05 02:17:02,072 : INFO : torch.Size([48, 300])
2017-05-05 02:17:02,073 : INFO : sum
2017-05-05 02:17:02,074 : INFO : 6856347
2017-05-05 02:17:02,074 : INFO : ____________
2017-05-05 02:17:39,231 : INFO : LOG_FILE
2017-05-05 02:17:39,232 : INFO : _________________________________start___________________________________
2017-05-05 02:17:39,259 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-05 02:17:39,473 : INFO : ==> SST vocabulary size : 21705
2017-05-05 02:17:39,473 : INFO : ==> SST rel vocabulary size : 48
2017-05-05 02:17:39,473 : INFO : ==> SST tag vocabulary size : 47
2017-05-05 02:17:45,750 : INFO : _param count_
2017-05-05 02:17:45,751 : INFO : torch.Size([168, 300])
2017-05-05 02:17:45,751 : INFO : torch.Size([168])
2017-05-05 02:17:45,751 : INFO : torch.Size([168, 168])
2017-05-05 02:17:45,751 : INFO : torch.Size([168])
2017-05-05 02:17:45,751 : INFO : torch.Size([168, 300])
2017-05-05 02:17:45,751 : INFO : torch.Size([168])
2017-05-05 02:17:45,752 : INFO : torch.Size([168, 168])
2017-05-05 02:17:45,752 : INFO : torch.Size([168])
2017-05-05 02:17:45,752 : INFO : torch.Size([168, 300])
2017-05-05 02:17:45,752 : INFO : torch.Size([168])
2017-05-05 02:17:45,752 : INFO : torch.Size([168, 168])
2017-05-05 02:17:45,752 : INFO : torch.Size([168])
2017-05-05 02:17:45,752 : INFO : torch.Size([168, 300])
2017-05-05 02:17:45,753 : INFO : torch.Size([168])
2017-05-05 02:17:45,753 : INFO : torch.Size([168, 168])
2017-05-05 02:17:45,753 : INFO : torch.Size([168])
2017-05-05 02:17:45,753 : INFO : torch.Size([3, 168])
2017-05-05 02:17:45,753 : INFO : torch.Size([3])
2017-05-05 02:17:45,753 : INFO : torch.Size([21705, 300])
2017-05-05 02:17:45,754 : INFO : torch.Size([47, 300])
2017-05-05 02:17:45,754 : INFO : torch.Size([48, 300])
2017-05-05 02:17:45,754 : INFO : sum
2017-05-05 02:17:45,754 : INFO : 6856347
2017-05-05 02:17:45,754 : INFO : ____________
2017-05-05 02:36:03,092 : INFO : ==> Train loss   : 0.280406
2017-05-05 02:36:03,092 : INFO : Epoch
2017-05-05 02:36:03,093 : INFO : 0
2017-05-05 02:36:03,093 : INFO : train percentage
2017-05-05 02:36:03,093 : INFO : 0.914161849711
2017-05-05 02:36:03,093 : INFO : Epoch
2017-05-05 02:36:03,093 : INFO : 0
2017-05-05 02:36:03,093 : INFO : dev percentage
2017-05-05 02:36:03,093 : INFO : 0.844036697248
2017-05-05 02:36:03,093 : INFO : Epoch
2017-05-05 02:36:03,094 : INFO : 0
2017-05-05 02:36:03,094 : INFO : test percentage
2017-05-05 02:36:03,094 : INFO : 0.838550247117
2017-05-05 02:54:25,495 : INFO : ==> Train loss   : 0.152711
2017-05-05 02:54:25,495 : INFO : Epoch
2017-05-05 02:54:25,495 : INFO : 1
2017-05-05 02:54:25,496 : INFO : train percentage
2017-05-05 02:54:25,496 : INFO : 0.955202312139
2017-05-05 02:54:25,496 : INFO : Epoch
2017-05-05 02:54:25,496 : INFO : 1
2017-05-05 02:54:25,496 : INFO : dev percentage
2017-05-05 02:54:25,496 : INFO : 0.813073394495
2017-05-05 02:54:25,496 : INFO : Epoch
2017-05-05 02:54:25,496 : INFO : 1
2017-05-05 02:54:25,496 : INFO : test percentage
2017-05-05 02:54:25,497 : INFO : 0.826468973092
2017-05-05 03:12:56,228 : INFO : ==> Train loss   : 0.079012
2017-05-05 03:12:56,228 : INFO : Epoch
2017-05-05 03:12:56,229 : INFO : 2
2017-05-05 03:12:56,229 : INFO : train percentage
2017-05-05 03:12:56,229 : INFO : 0.978323699422
2017-05-05 03:12:56,229 : INFO : Epoch
2017-05-05 03:12:56,229 : INFO : 2
2017-05-05 03:12:56,229 : INFO : dev percentage
2017-05-05 03:12:56,229 : INFO : 0.811926605505
2017-05-05 03:12:56,229 : INFO : Epoch
2017-05-05 03:12:56,230 : INFO : 2
2017-05-05 03:12:56,230 : INFO : test percentage
2017-05-05 03:12:56,230 : INFO : 0.838001098298
2017-05-05 03:31:15,044 : INFO : ==> Train loss   : 0.046300
2017-05-05 03:31:15,044 : INFO : Epoch
2017-05-05 03:31:15,046 : INFO : 3
2017-05-05 03:31:15,046 : INFO : train percentage
2017-05-05 03:31:15,046 : INFO : 0.988294797688
2017-05-05 03:31:15,046 : INFO : Epoch
2017-05-05 03:31:15,046 : INFO : 3
2017-05-05 03:31:15,047 : INFO : dev percentage
2017-05-05 03:31:15,047 : INFO : 0.810779816514
2017-05-05 03:31:15,047 : INFO : Epoch
2017-05-05 03:31:15,047 : INFO : 3
2017-05-05 03:31:15,047 : INFO : test percentage
2017-05-05 03:31:15,047 : INFO : 0.81987918726
2017-05-05 03:49:35,702 : INFO : ==> Train loss   : 0.033393
2017-05-05 03:49:35,703 : INFO : Epoch
2017-05-05 03:49:35,703 : INFO : 4
2017-05-05 03:49:35,703 : INFO : train percentage
2017-05-05 03:49:35,703 : INFO : 0.992485549133
2017-05-05 03:49:35,703 : INFO : Epoch
2017-05-05 03:49:35,703 : INFO : 4
2017-05-05 03:49:35,703 : INFO : dev percentage
2017-05-05 03:49:35,703 : INFO : 0.814220183486
2017-05-05 03:49:35,704 : INFO : Epoch
2017-05-05 03:49:35,704 : INFO : 4
2017-05-05 03:49:35,704 : INFO : test percentage
2017-05-05 03:49:35,704 : INFO : 0.817682591982
2017-05-05 04:07:40,561 : INFO : ==> Train loss   : 0.022401
2017-05-05 04:07:40,561 : INFO : Epoch
2017-05-05 04:07:40,561 : INFO : 5
2017-05-05 04:07:40,561 : INFO : train percentage
2017-05-05 04:07:40,561 : INFO : 0.994942196532
2017-05-05 04:07:40,561 : INFO : Epoch
2017-05-05 04:07:40,561 : INFO : 5
2017-05-05 04:07:40,561 : INFO : dev percentage
2017-05-05 04:07:40,562 : INFO : 0.797018348624
2017-05-05 04:07:40,562 : INFO : Epoch
2017-05-05 04:07:40,562 : INFO : 5
2017-05-05 04:07:40,562 : INFO : test percentage
2017-05-05 04:07:40,562 : INFO : 0.81987918726
2017-05-05 04:25:54,949 : INFO : ==> Train loss   : 0.016297
2017-05-05 04:25:54,949 : INFO : Epoch
2017-05-05 04:25:54,949 : INFO : 6
2017-05-05 04:25:54,949 : INFO : train percentage
2017-05-05 04:25:54,950 : INFO : 0.996098265896
2017-05-05 04:25:54,950 : INFO : Epoch
2017-05-05 04:25:54,950 : INFO : 6
2017-05-05 04:25:54,950 : INFO : dev percentage
2017-05-05 04:25:54,950 : INFO : 0.795871559633
2017-05-05 04:25:54,950 : INFO : Epoch
2017-05-05 04:25:54,950 : INFO : 6
2017-05-05 04:25:54,950 : INFO : test percentage
2017-05-05 04:25:54,951 : INFO : 0.814936847886
2017-05-05 04:44:05,741 : INFO : ==> Train loss   : 0.017358
2017-05-05 04:44:05,742 : INFO : Epoch
2017-05-05 04:44:05,742 : INFO : 7
2017-05-05 04:44:05,742 : INFO : train percentage
2017-05-05 04:44:05,742 : INFO : 0.995520231214
2017-05-05 04:44:05,742 : INFO : Epoch
2017-05-05 04:44:05,742 : INFO : 7
2017-05-05 04:44:05,742 : INFO : dev percentage
2017-05-05 04:44:05,743 : INFO : 0.801605504587
2017-05-05 04:44:05,743 : INFO : Epoch
2017-05-05 04:44:05,743 : INFO : 7
2017-05-05 04:44:05,743 : INFO : test percentage
2017-05-05 04:44:05,743 : INFO : 0.812191103789
2017-05-05 05:02:19,034 : INFO : ==> Train loss   : 0.007909
2017-05-05 05:02:19,034 : INFO : Epoch
2017-05-05 05:02:19,035 : INFO : 8
2017-05-05 05:02:19,035 : INFO : train percentage
2017-05-05 05:02:19,035 : INFO : 0.998843930636
2017-05-05 05:02:19,035 : INFO : Epoch
2017-05-05 05:02:19,035 : INFO : 8
2017-05-05 05:02:19,035 : INFO : dev percentage
2017-05-05 05:02:19,035 : INFO : 0.79128440367
2017-05-05 05:02:19,035 : INFO : Epoch
2017-05-05 05:02:19,036 : INFO : 8
2017-05-05 05:02:19,036 : INFO : test percentage
2017-05-05 05:02:19,036 : INFO : 0.809994508512
2017-05-05 05:20:29,582 : INFO : ==> Train loss   : 0.006558
2017-05-05 05:20:29,582 : INFO : Epoch
2017-05-05 05:20:29,584 : INFO : 9
2017-05-05 05:20:29,584 : INFO : train percentage
2017-05-05 05:20:29,584 : INFO : 0.998843930636
2017-05-05 05:20:29,584 : INFO : Epoch
2017-05-05 05:20:29,584 : INFO : 9
2017-05-05 05:20:29,584 : INFO : dev percentage
2017-05-05 05:20:29,584 : INFO : 0.799311926606
2017-05-05 05:20:29,585 : INFO : Epoch
2017-05-05 05:20:29,585 : INFO : 9
2017-05-05 05:20:29,585 : INFO : test percentage
2017-05-05 05:20:29,585 : INFO : 0.802855573861
2017-05-05 05:38:42,407 : INFO : ==> Train loss   : 0.005313
2017-05-05 05:38:42,407 : INFO : Epoch
2017-05-05 05:38:42,407 : INFO : 10
2017-05-05 05:38:42,407 : INFO : train percentage
2017-05-05 05:38:42,407 : INFO : 0.999421965318
2017-05-05 05:38:42,408 : INFO : Epoch
2017-05-05 05:38:42,408 : INFO : 10
2017-05-05 05:38:42,408 : INFO : dev percentage
2017-05-05 05:38:42,408 : INFO : 0.787844036697
2017-05-05 05:38:42,408 : INFO : Epoch
2017-05-05 05:38:42,408 : INFO : 10
2017-05-05 05:38:42,408 : INFO : test percentage
2017-05-05 05:38:42,408 : INFO : 0.80340472268
2017-05-05 05:56:33,566 : INFO : ==> Train loss   : 0.004498
2017-05-05 05:56:33,566 : INFO : Epoch
2017-05-05 05:56:33,566 : INFO : 11
2017-05-05 05:56:33,567 : INFO : train percentage
2017-05-05 05:56:33,567 : INFO : 0.999421965318
2017-05-05 05:56:33,567 : INFO : Epoch
2017-05-05 05:56:33,567 : INFO : 11
2017-05-05 05:56:33,567 : INFO : dev percentage
2017-05-05 05:56:33,567 : INFO : 0.788990825688
2017-05-05 05:56:33,567 : INFO : Epoch
2017-05-05 05:56:33,567 : INFO : 11
2017-05-05 05:56:33,568 : INFO : test percentage
2017-05-05 05:56:33,568 : INFO : 0.799011532125
2017-05-05 06:14:02,858 : INFO : ==> Train loss   : 0.003849
2017-05-05 06:14:02,858 : INFO : Epoch
2017-05-05 06:14:02,858 : INFO : 12
2017-05-05 06:14:02,858 : INFO : train percentage
2017-05-05 06:14:02,858 : INFO : 0.999421965318
2017-05-05 06:14:02,858 : INFO : Epoch
2017-05-05 06:14:02,859 : INFO : 12
2017-05-05 06:14:02,859 : INFO : dev percentage
2017-05-05 06:14:02,859 : INFO : 0.800458715596
2017-05-05 06:14:02,859 : INFO : Epoch
2017-05-05 06:14:02,859 : INFO : 12
2017-05-05 06:14:02,859 : INFO : test percentage
2017-05-05 06:14:02,859 : INFO : 0.797913234487
2017-05-05 06:31:38,203 : INFO : ==> Train loss   : 0.004543
2017-05-05 06:31:38,203 : INFO : Epoch
2017-05-05 06:31:38,203 : INFO : 13
2017-05-05 06:31:38,204 : INFO : train percentage
2017-05-05 06:31:38,204 : INFO : 0.999855491329
2017-05-05 06:31:38,204 : INFO : Epoch
2017-05-05 06:31:38,204 : INFO : 13
2017-05-05 06:31:38,204 : INFO : dev percentage
2017-05-05 06:31:38,204 : INFO : 0.800458715596
2017-05-05 06:31:38,204 : INFO : Epoch
2017-05-05 06:31:38,204 : INFO : 13
2017-05-05 06:31:38,205 : INFO : test percentage
2017-05-05 06:31:38,205 : INFO : 0.795716639209
2017-05-05 06:49:15,269 : INFO : ==> Train loss   : 0.002515
2017-05-05 06:49:15,269 : INFO : Epoch
2017-05-05 06:49:15,269 : INFO : 14
2017-05-05 06:49:15,269 : INFO : train percentage
2017-05-05 06:49:15,269 : INFO : 0.999566473988
2017-05-05 06:49:15,269 : INFO : Epoch
2017-05-05 06:49:15,269 : INFO : 14
2017-05-05 06:49:15,270 : INFO : dev percentage
2017-05-05 06:49:15,270 : INFO : 0.798165137615
2017-05-05 06:49:15,270 : INFO : Epoch
2017-05-05 06:49:15,270 : INFO : 14
2017-05-05 06:49:15,270 : INFO : test percentage
2017-05-05 06:49:15,270 : INFO : 0.800109829764
2017-05-05 07:06:42,897 : INFO : ==> Train loss   : 0.002059
2017-05-05 07:06:42,897 : INFO : Epoch
2017-05-05 07:06:42,897 : INFO : 15
2017-05-05 07:06:42,897 : INFO : train percentage
2017-05-05 07:06:42,898 : INFO : 0.999566473988
2017-05-05 07:06:42,898 : INFO : Epoch
2017-05-05 07:06:42,898 : INFO : 15
2017-05-05 07:06:42,898 : INFO : dev percentage
2017-05-05 07:06:42,898 : INFO : 0.788990825688
2017-05-05 07:06:42,898 : INFO : Epoch
2017-05-05 07:06:42,898 : INFO : 15
2017-05-05 07:06:42,899 : INFO : test percentage
2017-05-05 07:06:42,899 : INFO : 0.802306425041
2017-05-05 07:24:17,063 : INFO : ==> Train loss   : 0.004776
2017-05-05 07:24:17,063 : INFO : Epoch
2017-05-05 07:24:17,063 : INFO : 16
2017-05-05 07:24:17,063 : INFO : train percentage
2017-05-05 07:24:17,063 : INFO : 0.999566473988
2017-05-05 07:24:17,063 : INFO : Epoch
2017-05-05 07:24:17,063 : INFO : 16
2017-05-05 07:24:17,064 : INFO : dev percentage
2017-05-05 07:24:17,064 : INFO : 0.792431192661
2017-05-05 07:24:17,064 : INFO : Epoch
2017-05-05 07:24:17,064 : INFO : 16
2017-05-05 07:24:17,064 : INFO : test percentage
2017-05-05 07:24:17,064 : INFO : 0.794069192751
2017-05-05 07:41:45,637 : INFO : ==> Train loss   : 0.003819
2017-05-05 07:41:45,638 : INFO : Epoch
2017-05-05 07:41:45,638 : INFO : 17
2017-05-05 07:41:45,638 : INFO : train percentage
2017-05-05 07:41:45,638 : INFO : 0.999710982659
2017-05-05 07:41:45,638 : INFO : Epoch
2017-05-05 07:41:45,638 : INFO : 17
2017-05-05 07:41:45,638 : INFO : dev percentage
2017-05-05 07:41:45,638 : INFO : 0.794724770642
2017-05-05 07:41:45,639 : INFO : Epoch
2017-05-05 07:41:45,639 : INFO : 17
2017-05-05 07:41:45,639 : INFO : test percentage
2017-05-05 07:41:45,639 : INFO : 0.792421746293
2017-05-05 07:59:15,570 : INFO : ==> Train loss   : 0.001281
2017-05-05 07:59:15,571 : INFO : Epoch
2017-05-05 07:59:15,571 : INFO : 18
2017-05-05 07:59:15,571 : INFO : train percentage
2017-05-05 07:59:15,571 : INFO : 0.999855491329
2017-05-05 07:59:15,571 : INFO : Epoch
2017-05-05 07:59:15,571 : INFO : 18
2017-05-05 07:59:15,571 : INFO : dev percentage
2017-05-05 07:59:15,571 : INFO : 0.790137614679
2017-05-05 07:59:15,572 : INFO : Epoch
2017-05-05 07:59:15,572 : INFO : 18
2017-05-05 07:59:15,572 : INFO : test percentage
2017-05-05 07:59:15,572 : INFO : 0.79516749039
2017-05-05 08:16:48,218 : INFO : ==> Train loss   : 0.002975
2017-05-05 08:16:48,219 : INFO : Epoch
2017-05-05 08:16:48,219 : INFO : 19
2017-05-05 08:16:48,219 : INFO : train percentage
2017-05-05 08:16:48,219 : INFO : 0.999710982659
2017-05-05 08:16:48,219 : INFO : Epoch
2017-05-05 08:16:48,219 : INFO : 19
2017-05-05 08:16:48,219 : INFO : dev percentage
2017-05-05 08:16:48,219 : INFO : 0.794724770642
2017-05-05 08:16:48,220 : INFO : Epoch
2017-05-05 08:16:48,220 : INFO : 19
2017-05-05 08:16:48,220 : INFO : test percentage
2017-05-05 08:16:48,220 : INFO : 0.797364085667
2017-05-05 08:34:23,234 : INFO : ==> Train loss   : 0.001705
2017-05-05 08:34:23,235 : INFO : Epoch
2017-05-05 08:34:23,235 : INFO : 20
2017-05-05 08:34:23,235 : INFO : train percentage
2017-05-05 08:34:23,235 : INFO : 0.999566473988
2017-05-05 08:34:23,235 : INFO : Epoch
2017-05-05 08:34:23,235 : INFO : 20
2017-05-05 08:34:23,235 : INFO : dev percentage
2017-05-05 08:34:23,236 : INFO : 0.793577981651
2017-05-05 08:34:23,236 : INFO : Epoch
2017-05-05 08:34:23,236 : INFO : 20
2017-05-05 08:34:23,236 : INFO : test percentage
2017-05-05 08:34:23,236 : INFO : 0.791872597474
2017-05-05 08:51:47,609 : INFO : ==> Train loss   : 0.001371
2017-05-05 08:51:47,609 : INFO : Epoch
2017-05-05 08:51:47,609 : INFO : 21
2017-05-05 08:51:47,609 : INFO : train percentage
2017-05-05 08:51:47,610 : INFO : 0.999710982659
2017-05-05 08:51:47,610 : INFO : Epoch
2017-05-05 08:51:47,610 : INFO : 21
2017-05-05 08:51:47,610 : INFO : dev percentage
2017-05-05 08:51:47,610 : INFO : 0.799311926606
2017-05-05 08:51:47,610 : INFO : Epoch
2017-05-05 08:51:47,610 : INFO : 21
2017-05-05 08:51:47,610 : INFO : test percentage
2017-05-05 08:51:47,610 : INFO : 0.792970895113
2017-05-05 09:09:16,713 : INFO : ==> Train loss   : 0.000983
2017-05-05 09:09:16,713 : INFO : Epoch
2017-05-05 09:09:16,713 : INFO : 22
2017-05-05 09:09:16,714 : INFO : train percentage
2017-05-05 09:09:16,714 : INFO : 0.999855491329
2017-05-05 09:09:16,714 : INFO : Epoch
2017-05-05 09:09:16,714 : INFO : 22
2017-05-05 09:09:16,714 : INFO : dev percentage
2017-05-05 09:09:16,714 : INFO : 0.790137614679
2017-05-05 09:09:16,714 : INFO : Epoch
2017-05-05 09:09:16,714 : INFO : 22
2017-05-05 09:09:16,715 : INFO : test percentage
2017-05-05 09:09:16,715 : INFO : 0.796265788029
2017-05-05 15:26:00,136 : INFO : LOG_FILE
2017-05-05 15:26:00,137 : INFO : _________________________________start___________________________________
2017-05-05 15:26:00,199 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-05 15:26:00,418 : INFO : ==> SST vocabulary size : 21705
2017-05-05 15:26:00,418 : INFO : ==> SST rel vocabulary size : 48
2017-05-05 15:26:00,418 : INFO : ==> SST tag vocabulary size : 47
2017-05-05 15:26:07,608 : INFO : _param count_
2017-05-05 15:26:07,609 : INFO : torch.Size([168, 300])
2017-05-05 15:26:07,609 : INFO : torch.Size([168])
2017-05-05 15:26:07,610 : INFO : torch.Size([168, 168])
2017-05-05 15:26:07,610 : INFO : torch.Size([168])
2017-05-05 15:26:07,610 : INFO : torch.Size([168, 300])
2017-05-05 15:26:07,610 : INFO : torch.Size([168])
2017-05-05 15:26:07,611 : INFO : torch.Size([168, 168])
2017-05-05 15:26:07,611 : INFO : torch.Size([168])
2017-05-05 15:26:07,611 : INFO : torch.Size([168, 300])
2017-05-05 15:26:07,611 : INFO : torch.Size([168])
2017-05-05 15:26:07,612 : INFO : torch.Size([168, 168])
2017-05-05 15:26:07,612 : INFO : torch.Size([168])
2017-05-05 15:26:07,612 : INFO : torch.Size([168, 300])
2017-05-05 15:26:07,612 : INFO : torch.Size([168])
2017-05-05 15:26:07,612 : INFO : torch.Size([168, 168])
2017-05-05 15:26:07,613 : INFO : torch.Size([168])
2017-05-05 15:26:07,613 : INFO : torch.Size([3, 168])
2017-05-05 15:26:07,613 : INFO : torch.Size([3])
2017-05-05 15:26:07,613 : INFO : torch.Size([21705, 300])
2017-05-05 15:26:07,613 : INFO : torch.Size([47, 300])
2017-05-05 15:26:07,613 : INFO : torch.Size([48, 300])
2017-05-05 15:26:07,614 : INFO : sum
2017-05-05 15:26:07,614 : INFO : 6856347
2017-05-05 15:26:07,614 : INFO : ____________
2017-05-05 15:31:23,303 : INFO : LOG_FILE
2017-05-05 15:31:23,304 : INFO : _________________________________start___________________________________
2017-05-05 15:31:23,317 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-05 15:31:23,743 : INFO : ==> SST vocabulary size : 21705
2017-05-05 15:31:23,744 : INFO : ==> SST rel vocabulary size : 48
2017-05-05 15:31:23,744 : INFO : ==> SST tag vocabulary size : 47
2017-05-05 15:31:31,373 : INFO : _param count_
2017-05-05 15:31:31,377 : INFO : torch.Size([168, 300])
2017-05-05 15:31:31,378 : INFO : torch.Size([168])
2017-05-05 15:31:31,379 : INFO : torch.Size([168, 168])
2017-05-05 15:31:31,379 : INFO : torch.Size([168])
2017-05-05 15:31:31,380 : INFO : torch.Size([168, 300])
2017-05-05 15:31:31,381 : INFO : torch.Size([168])
2017-05-05 15:31:31,382 : INFO : torch.Size([168, 168])
2017-05-05 15:31:31,383 : INFO : torch.Size([168])
2017-05-05 15:31:31,383 : INFO : torch.Size([168, 300])
2017-05-05 15:31:31,384 : INFO : torch.Size([168])
2017-05-05 15:31:31,385 : INFO : torch.Size([168, 168])
2017-05-05 15:31:31,386 : INFO : torch.Size([168])
2017-05-05 15:31:31,387 : INFO : torch.Size([168, 300])
2017-05-05 15:31:31,387 : INFO : torch.Size([168])
2017-05-05 15:31:31,388 : INFO : torch.Size([168, 168])
2017-05-05 15:31:31,389 : INFO : torch.Size([168])
2017-05-05 15:31:31,390 : INFO : torch.Size([3, 168])
2017-05-05 15:31:31,391 : INFO : torch.Size([3])
2017-05-05 15:31:31,391 : INFO : torch.Size([21705, 300])
2017-05-05 15:31:31,392 : INFO : torch.Size([47, 300])
2017-05-05 15:31:31,393 : INFO : torch.Size([48, 300])
2017-05-05 15:31:31,394 : INFO : sum
2017-05-05 15:31:31,394 : INFO : 6856347
2017-05-05 15:31:31,395 : INFO : ____________
2017-05-05 15:42:37,257 : INFO : LOG_FILE
2017-05-05 15:42:37,258 : INFO : _________________________________start___________________________________
2017-05-05 15:42:37,270 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-05 15:42:37,681 : INFO : ==> SST vocabulary size : 21705
2017-05-05 15:42:37,681 : INFO : ==> SST rel vocabulary size : 48
2017-05-05 15:42:37,682 : INFO : ==> SST tag vocabulary size : 47
2017-05-05 15:42:45,144 : INFO : _param count_
2017-05-05 15:42:45,150 : INFO : torch.Size([168, 300])
2017-05-05 15:42:45,151 : INFO : torch.Size([168])
2017-05-05 15:42:45,152 : INFO : torch.Size([168, 168])
2017-05-05 15:42:45,153 : INFO : torch.Size([168])
2017-05-05 15:42:45,154 : INFO : torch.Size([168, 300])
2017-05-05 15:42:45,155 : INFO : torch.Size([168])
2017-05-05 15:42:45,156 : INFO : torch.Size([168, 168])
2017-05-05 15:42:45,157 : INFO : torch.Size([168])
2017-05-05 15:42:45,158 : INFO : torch.Size([168, 300])
2017-05-05 15:42:45,159 : INFO : torch.Size([168])
2017-05-05 15:42:45,159 : INFO : torch.Size([168, 168])
2017-05-05 15:42:45,160 : INFO : torch.Size([168])
2017-05-05 15:42:45,161 : INFO : torch.Size([168, 300])
2017-05-05 15:42:45,162 : INFO : torch.Size([168])
2017-05-05 15:42:45,163 : INFO : torch.Size([168, 168])
2017-05-05 15:42:45,164 : INFO : torch.Size([168])
2017-05-05 15:42:45,165 : INFO : torch.Size([504, 168])
2017-05-05 15:42:45,166 : INFO : torch.Size([504, 168])
2017-05-05 15:42:45,167 : INFO : torch.Size([504])
2017-05-05 15:42:45,168 : INFO : torch.Size([504])
2017-05-05 15:42:45,169 : INFO : torch.Size([3, 168])
2017-05-05 15:42:45,170 : INFO : torch.Size([3])
2017-05-05 15:42:45,171 : INFO : torch.Size([21705, 300])
2017-05-05 15:42:45,172 : INFO : torch.Size([47, 300])
2017-05-05 15:42:45,173 : INFO : torch.Size([48, 300])
2017-05-05 15:42:45,174 : INFO : sum
2017-05-05 15:42:45,174 : INFO : 7026699
2017-05-05 15:42:45,175 : INFO : ____________
2017-05-05 15:44:42,566 : INFO : ==> Train loss   : 0.280406
2017-05-05 15:44:42,567 : INFO : Epoch
2017-05-05 15:44:42,567 : INFO : 0
2017-05-05 15:44:42,567 : INFO : train percentage
2017-05-05 15:44:42,567 : INFO : 0.914161849711
2017-05-05 15:44:42,567 : INFO : Epoch
2017-05-05 15:44:42,567 : INFO : 0
2017-05-05 15:44:42,567 : INFO : dev percentage
2017-05-05 15:44:42,567 : INFO : 0.844036697248
2017-05-05 15:44:42,567 : INFO : Epoch
2017-05-05 15:44:42,568 : INFO : 0
2017-05-05 15:44:42,568 : INFO : test percentage
2017-05-05 15:44:42,568 : INFO : 0.838550247117
2017-05-05 16:03:24,026 : INFO : ==> Train loss   : 0.152711
2017-05-05 16:03:24,026 : INFO : Epoch
2017-05-05 16:03:24,027 : INFO : 1
2017-05-05 16:03:24,027 : INFO : train percentage
2017-05-05 16:03:24,027 : INFO : 0.955202312139
2017-05-05 16:03:24,027 : INFO : Epoch
2017-05-05 16:03:24,027 : INFO : 1
2017-05-05 16:03:24,027 : INFO : dev percentage
2017-05-05 16:03:24,027 : INFO : 0.813073394495
2017-05-05 16:03:24,027 : INFO : Epoch
2017-05-05 16:03:24,028 : INFO : 1
2017-05-05 16:03:24,028 : INFO : test percentage
2017-05-05 16:03:24,028 : INFO : 0.826468973092
2017-05-05 16:22:04,135 : INFO : ==> Train loss   : 0.079012
2017-05-05 16:22:04,135 : INFO : Epoch
2017-05-05 16:22:04,135 : INFO : 2
2017-05-05 16:22:04,136 : INFO : train percentage
2017-05-05 16:22:04,136 : INFO : 0.978323699422
2017-05-05 16:22:04,136 : INFO : Epoch
2017-05-05 16:22:04,136 : INFO : 2
2017-05-05 16:22:04,136 : INFO : dev percentage
2017-05-05 16:22:04,136 : INFO : 0.811926605505
2017-05-05 16:22:04,136 : INFO : Epoch
2017-05-05 16:22:04,136 : INFO : 2
2017-05-05 16:22:04,137 : INFO : test percentage
2017-05-05 16:22:04,137 : INFO : 0.838001098298
2017-05-05 16:39:51,808 : INFO : ==> Train loss   : 0.046300
2017-05-05 16:39:51,808 : INFO : Epoch
2017-05-05 16:39:51,808 : INFO : 3
2017-05-05 16:39:51,808 : INFO : train percentage
2017-05-05 16:39:51,808 : INFO : 0.988294797688
2017-05-05 16:39:51,808 : INFO : Epoch
2017-05-05 16:39:51,809 : INFO : 3
2017-05-05 16:39:51,809 : INFO : dev percentage
2017-05-05 16:39:51,809 : INFO : 0.810779816514
2017-05-05 16:39:51,809 : INFO : Epoch
2017-05-05 16:39:51,809 : INFO : 3
2017-05-05 16:39:51,809 : INFO : test percentage
2017-05-05 16:39:51,809 : INFO : 0.81987918726
2017-05-05 16:41:25,169 : INFO : LOG_FILE
2017-05-05 16:41:25,169 : INFO : _________________________________start___________________________________
2017-05-05 16:41:25,182 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-05 16:41:25,589 : INFO : ==> SST vocabulary size : 21705
2017-05-05 16:41:25,590 : INFO : ==> SST rel vocabulary size : 48
2017-05-05 16:41:25,590 : INFO : ==> SST tag vocabulary size : 47
2017-05-05 16:41:33,133 : INFO : _param count_
2017-05-05 16:41:33,135 : INFO : torch.Size([168, 300])
2017-05-05 16:41:33,136 : INFO : torch.Size([168])
2017-05-05 16:41:33,136 : INFO : torch.Size([168, 168])
2017-05-05 16:41:33,137 : INFO : torch.Size([168])
2017-05-05 16:41:33,138 : INFO : torch.Size([168, 300])
2017-05-05 16:41:33,138 : INFO : torch.Size([168])
2017-05-05 16:41:33,139 : INFO : torch.Size([168, 168])
2017-05-05 16:41:33,139 : INFO : torch.Size([168])
2017-05-05 16:41:33,140 : INFO : torch.Size([168, 300])
2017-05-05 16:41:33,140 : INFO : torch.Size([168])
2017-05-05 16:41:33,141 : INFO : torch.Size([168, 168])
2017-05-05 16:41:33,141 : INFO : torch.Size([168])
2017-05-05 16:41:33,142 : INFO : torch.Size([168, 300])
2017-05-05 16:41:33,142 : INFO : torch.Size([168])
2017-05-05 16:41:33,143 : INFO : torch.Size([168, 168])
2017-05-05 16:41:33,143 : INFO : torch.Size([168])
2017-05-05 16:41:33,144 : INFO : torch.Size([3, 168])
2017-05-05 16:41:33,145 : INFO : torch.Size([3])
2017-05-05 16:41:33,145 : INFO : torch.Size([21705, 300])
2017-05-05 16:41:33,146 : INFO : torch.Size([47, 300])
2017-05-05 16:41:33,146 : INFO : torch.Size([48, 300])
2017-05-05 16:41:33,147 : INFO : sum
2017-05-05 16:41:33,147 : INFO : 6856347
2017-05-05 16:41:33,148 : INFO : ____________
2017-05-05 16:57:25,227 : INFO : ==> Train loss   : 0.033393
2017-05-05 16:57:25,228 : INFO : Epoch
2017-05-05 16:57:25,228 : INFO : 4
2017-05-05 16:57:25,228 : INFO : train percentage
2017-05-05 16:57:25,228 : INFO : 0.992485549133
2017-05-05 16:57:25,228 : INFO : Epoch
2017-05-05 16:57:25,228 : INFO : 4
2017-05-05 16:57:25,228 : INFO : dev percentage
2017-05-05 16:57:25,229 : INFO : 0.814220183486
2017-05-05 16:57:25,229 : INFO : Epoch
2017-05-05 16:57:25,229 : INFO : 4
2017-05-05 16:57:25,229 : INFO : test percentage
2017-05-05 16:57:25,229 : INFO : 0.817682591982
2017-05-05 17:14:40,169 : INFO : ==> Train loss   : 0.022401
2017-05-05 17:14:40,169 : INFO : Epoch
2017-05-05 17:14:40,169 : INFO : 5
2017-05-05 17:14:40,169 : INFO : train percentage
2017-05-05 17:14:40,169 : INFO : 0.994942196532
2017-05-05 17:14:40,170 : INFO : Epoch
2017-05-05 17:14:40,170 : INFO : 5
2017-05-05 17:14:40,170 : INFO : dev percentage
2017-05-05 17:14:40,170 : INFO : 0.797018348624
2017-05-05 17:14:40,170 : INFO : Epoch
2017-05-05 17:14:40,170 : INFO : 5
2017-05-05 17:14:40,170 : INFO : test percentage
2017-05-05 17:14:40,170 : INFO : 0.81987918726
2017-05-05 17:32:04,821 : INFO : ==> Train loss   : 0.016297
2017-05-05 17:32:04,822 : INFO : Epoch
2017-05-05 17:32:04,822 : INFO : 6
2017-05-05 17:32:04,822 : INFO : train percentage
2017-05-05 17:32:04,822 : INFO : 0.996098265896
2017-05-05 17:32:04,822 : INFO : Epoch
2017-05-05 17:32:04,822 : INFO : 6
2017-05-05 17:32:04,822 : INFO : dev percentage
2017-05-05 17:32:04,822 : INFO : 0.795871559633
2017-05-05 17:32:04,823 : INFO : Epoch
2017-05-05 17:32:04,823 : INFO : 6
2017-05-05 17:32:04,823 : INFO : test percentage
2017-05-05 17:32:04,823 : INFO : 0.814936847886
2017-05-05 17:49:35,201 : INFO : ==> Train loss   : 0.017358
2017-05-05 17:49:35,202 : INFO : Epoch
2017-05-05 17:49:35,202 : INFO : 7
2017-05-05 17:49:35,202 : INFO : train percentage
2017-05-05 17:49:35,202 : INFO : 0.995520231214
2017-05-05 17:49:35,202 : INFO : Epoch
2017-05-05 17:49:35,202 : INFO : 7
2017-05-05 17:49:35,202 : INFO : dev percentage
2017-05-05 17:49:35,202 : INFO : 0.801605504587
2017-05-05 17:49:35,203 : INFO : Epoch
2017-05-05 17:49:35,203 : INFO : 7
2017-05-05 17:49:35,203 : INFO : test percentage
2017-05-05 17:49:35,203 : INFO : 0.812191103789
2017-05-05 18:07:01,747 : INFO : ==> Train loss   : 0.007909
2017-05-05 18:07:01,747 : INFO : Epoch
2017-05-05 18:07:01,747 : INFO : 8
2017-05-05 18:07:01,747 : INFO : train percentage
2017-05-05 18:07:01,748 : INFO : 0.998843930636
2017-05-05 18:07:01,748 : INFO : Epoch
2017-05-05 18:07:01,748 : INFO : 8
2017-05-05 18:07:01,748 : INFO : dev percentage
2017-05-05 18:07:01,748 : INFO : 0.79128440367
2017-05-05 18:07:01,748 : INFO : Epoch
2017-05-05 18:07:01,748 : INFO : 8
2017-05-05 18:07:01,748 : INFO : test percentage
2017-05-05 18:07:01,748 : INFO : 0.809994508512
2017-05-05 18:24:51,559 : INFO : ==> Train loss   : 0.006558
2017-05-05 18:24:51,560 : INFO : Epoch
2017-05-05 18:24:51,560 : INFO : 9
2017-05-05 18:24:51,560 : INFO : train percentage
2017-05-05 18:24:51,560 : INFO : 0.998843930636
2017-05-05 18:24:51,560 : INFO : Epoch
2017-05-05 18:24:51,560 : INFO : 9
2017-05-05 18:24:51,560 : INFO : dev percentage
2017-05-05 18:24:51,561 : INFO : 0.799311926606
2017-05-05 18:24:51,561 : INFO : Epoch
2017-05-05 18:24:51,561 : INFO : 9
2017-05-05 18:24:51,561 : INFO : test percentage
2017-05-05 18:24:51,561 : INFO : 0.802855573861
2017-05-05 18:42:25,760 : INFO : ==> Train loss   : 0.005313
2017-05-05 18:42:25,760 : INFO : Epoch
2017-05-05 18:42:25,760 : INFO : 10
2017-05-05 18:42:25,761 : INFO : train percentage
2017-05-05 18:42:25,761 : INFO : 0.999421965318
2017-05-05 18:42:25,761 : INFO : Epoch
2017-05-05 18:42:25,761 : INFO : 10
2017-05-05 18:42:25,761 : INFO : dev percentage
2017-05-05 18:42:25,761 : INFO : 0.787844036697
2017-05-05 18:42:25,761 : INFO : Epoch
2017-05-05 18:42:25,761 : INFO : 10
2017-05-05 18:42:25,762 : INFO : test percentage
2017-05-05 18:42:25,762 : INFO : 0.80340472268
2017-05-05 19:00:00,435 : INFO : ==> Train loss   : 0.004498
2017-05-05 19:00:00,435 : INFO : Epoch
2017-05-05 19:00:00,435 : INFO : 11
2017-05-05 19:00:00,436 : INFO : train percentage
2017-05-05 19:00:00,436 : INFO : 0.999421965318
2017-05-05 19:00:00,436 : INFO : Epoch
2017-05-05 19:00:00,436 : INFO : 11
2017-05-05 19:00:00,436 : INFO : dev percentage
2017-05-05 19:00:00,436 : INFO : 0.788990825688
2017-05-05 19:00:00,436 : INFO : Epoch
2017-05-05 19:00:00,436 : INFO : 11
2017-05-05 19:00:00,437 : INFO : test percentage
2017-05-05 19:00:00,437 : INFO : 0.799011532125
2017-05-05 19:17:31,533 : INFO : ==> Train loss   : 0.003849
2017-05-05 19:17:31,533 : INFO : Epoch
2017-05-05 19:17:31,533 : INFO : 12
2017-05-05 19:17:31,533 : INFO : train percentage
2017-05-05 19:17:31,533 : INFO : 0.999421965318
2017-05-05 19:17:31,533 : INFO : Epoch
2017-05-05 19:17:31,533 : INFO : 12
2017-05-05 19:17:31,533 : INFO : dev percentage
2017-05-05 19:17:31,534 : INFO : 0.800458715596
2017-05-05 19:17:31,534 : INFO : Epoch
2017-05-05 19:17:31,534 : INFO : 12
2017-05-05 19:17:31,534 : INFO : test percentage
2017-05-05 19:17:31,534 : INFO : 0.797913234487
2017-05-05 19:35:02,582 : INFO : ==> Train loss   : 0.004543
2017-05-05 19:35:02,582 : INFO : Epoch
2017-05-05 19:35:02,582 : INFO : 13
2017-05-05 19:35:02,582 : INFO : train percentage
2017-05-05 19:35:02,582 : INFO : 0.999855491329
2017-05-05 19:35:02,582 : INFO : Epoch
2017-05-05 19:35:02,583 : INFO : 13
2017-05-05 19:35:02,583 : INFO : dev percentage
2017-05-05 19:35:02,583 : INFO : 0.800458715596
2017-05-05 19:35:02,583 : INFO : Epoch
2017-05-05 19:35:02,583 : INFO : 13
2017-05-05 19:35:02,583 : INFO : test percentage
2017-05-05 19:35:02,583 : INFO : 0.795716639209
2017-05-05 19:52:24,813 : INFO : ==> Train loss   : 0.002515
2017-05-05 19:52:24,814 : INFO : Epoch
2017-05-05 19:52:24,814 : INFO : 14
2017-05-05 19:52:24,814 : INFO : train percentage
2017-05-05 19:52:24,814 : INFO : 0.999566473988
2017-05-05 19:52:24,814 : INFO : Epoch
2017-05-05 19:52:24,814 : INFO : 14
2017-05-05 19:52:24,814 : INFO : dev percentage
2017-05-05 19:52:24,815 : INFO : 0.798165137615
2017-05-05 19:52:24,815 : INFO : Epoch
2017-05-05 19:52:24,815 : INFO : 14
2017-05-05 19:52:24,815 : INFO : test percentage
2017-05-05 19:52:24,815 : INFO : 0.800109829764
2017-05-05 20:09:48,559 : INFO : ==> Train loss   : 0.002059
2017-05-05 20:09:48,559 : INFO : Epoch
2017-05-05 20:09:48,559 : INFO : 15
2017-05-05 20:09:48,559 : INFO : train percentage
2017-05-05 20:09:48,559 : INFO : 0.999566473988
2017-05-05 20:09:48,559 : INFO : Epoch
2017-05-05 20:09:48,560 : INFO : 15
2017-05-05 20:09:48,560 : INFO : dev percentage
2017-05-05 20:09:48,560 : INFO : 0.788990825688
2017-05-05 20:09:48,560 : INFO : Epoch
2017-05-05 20:09:48,560 : INFO : 15
2017-05-05 20:09:48,560 : INFO : test percentage
2017-05-05 20:09:48,560 : INFO : 0.802306425041
2017-05-05 20:27:17,477 : INFO : ==> Train loss   : 0.004776
2017-05-05 20:27:17,477 : INFO : Epoch
2017-05-05 20:27:17,477 : INFO : 16
2017-05-05 20:27:17,478 : INFO : train percentage
2017-05-05 20:27:17,478 : INFO : 0.999566473988
2017-05-05 20:27:17,478 : INFO : Epoch
2017-05-05 20:27:17,478 : INFO : 16
2017-05-05 20:27:17,478 : INFO : dev percentage
2017-05-05 20:27:17,478 : INFO : 0.792431192661
2017-05-05 20:27:17,478 : INFO : Epoch
2017-05-05 20:27:17,478 : INFO : 16
2017-05-05 20:27:17,478 : INFO : test percentage
2017-05-05 20:27:17,479 : INFO : 0.794069192751
2017-05-05 20:44:45,827 : INFO : ==> Train loss   : 0.003819
2017-05-05 20:44:45,827 : INFO : Epoch
2017-05-05 20:44:45,827 : INFO : 17
2017-05-05 20:44:45,827 : INFO : train percentage
2017-05-05 20:44:45,827 : INFO : 0.999710982659
2017-05-05 20:44:45,827 : INFO : Epoch
2017-05-05 20:44:45,827 : INFO : 17
2017-05-05 20:44:45,828 : INFO : dev percentage
2017-05-05 20:44:45,828 : INFO : 0.794724770642
2017-05-05 20:44:45,828 : INFO : Epoch
2017-05-05 20:44:45,828 : INFO : 17
2017-05-05 20:44:45,828 : INFO : test percentage
2017-05-05 20:44:45,828 : INFO : 0.792421746293
2017-05-05 21:01:56,970 : INFO : ==> Train loss   : 0.001281
2017-05-05 21:01:56,970 : INFO : Epoch
2017-05-05 21:01:56,970 : INFO : 18
2017-05-05 21:01:56,970 : INFO : train percentage
2017-05-05 21:01:56,970 : INFO : 0.999855491329
2017-05-05 21:01:56,971 : INFO : Epoch
2017-05-05 21:01:56,971 : INFO : 18
2017-05-05 21:01:56,971 : INFO : dev percentage
2017-05-05 21:01:56,971 : INFO : 0.790137614679
2017-05-05 21:01:56,971 : INFO : Epoch
2017-05-05 21:01:56,971 : INFO : 18
2017-05-05 21:01:56,971 : INFO : test percentage
2017-05-05 21:01:56,971 : INFO : 0.79516749039
2017-05-05 21:19:17,454 : INFO : ==> Train loss   : 0.002975
2017-05-05 21:19:17,454 : INFO : Epoch
2017-05-05 21:19:17,454 : INFO : 19
2017-05-05 21:19:17,454 : INFO : train percentage
2017-05-05 21:19:17,454 : INFO : 0.999710982659
2017-05-05 21:19:17,454 : INFO : Epoch
2017-05-05 21:19:17,454 : INFO : 19
2017-05-05 21:19:17,455 : INFO : dev percentage
2017-05-05 21:19:17,455 : INFO : 0.794724770642
2017-05-05 21:19:17,455 : INFO : Epoch
2017-05-05 21:19:17,455 : INFO : 19
2017-05-05 21:19:17,455 : INFO : test percentage
2017-05-05 21:19:17,455 : INFO : 0.797364085667
2017-05-05 21:36:51,751 : INFO : ==> Train loss   : 0.001705
2017-05-05 21:36:51,752 : INFO : Epoch
2017-05-05 21:36:51,752 : INFO : 20
2017-05-05 21:36:51,752 : INFO : train percentage
2017-05-05 21:36:51,752 : INFO : 0.999566473988
2017-05-05 21:36:51,752 : INFO : Epoch
2017-05-05 21:36:51,752 : INFO : 20
2017-05-05 21:36:51,752 : INFO : dev percentage
2017-05-05 21:36:51,752 : INFO : 0.793577981651
2017-05-05 21:36:51,753 : INFO : Epoch
2017-05-05 21:36:51,753 : INFO : 20
2017-05-05 21:36:51,753 : INFO : test percentage
2017-05-05 21:36:51,753 : INFO : 0.791872597474
2017-05-05 21:54:49,354 : INFO : ==> Train loss   : 0.001371
2017-05-05 21:54:49,354 : INFO : Epoch
2017-05-05 21:54:49,354 : INFO : 21
2017-05-05 21:54:49,354 : INFO : train percentage
2017-05-05 21:54:49,354 : INFO : 0.999710982659
2017-05-05 21:54:49,354 : INFO : Epoch
2017-05-05 21:54:49,354 : INFO : 21
2017-05-05 21:54:49,354 : INFO : dev percentage
2017-05-05 21:54:49,355 : INFO : 0.799311926606
2017-05-05 21:54:49,355 : INFO : Epoch
2017-05-05 21:54:49,355 : INFO : 21
2017-05-05 21:54:49,355 : INFO : test percentage
2017-05-05 21:54:49,355 : INFO : 0.792970895113
2017-05-05 22:09:25,191 : INFO : LOG_FILE
2017-05-05 22:09:25,191 : INFO : _________________________________start___________________________________
2017-05-05 22:09:25,198 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-05 22:09:25,406 : INFO : ==> SST vocabulary size : 21705
2017-05-05 22:09:25,406 : INFO : ==> SST rel vocabulary size : 48
2017-05-05 22:09:25,406 : INFO : ==> SST tag vocabulary size : 47
2017-05-05 22:09:55,098 : INFO : LOG_FILE
2017-05-05 22:09:55,098 : INFO : _________________________________start___________________________________
2017-05-05 22:09:55,104 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-05 22:09:55,311 : INFO : ==> SST vocabulary size : 21705
2017-05-05 22:09:55,311 : INFO : ==> SST rel vocabulary size : 48
2017-05-05 22:09:55,311 : INFO : ==> SST tag vocabulary size : 47
2017-05-05 22:10:10,302 : INFO : _param count_
2017-05-05 22:10:10,302 : INFO : torch.Size([168, 300])
2017-05-05 22:10:10,303 : INFO : torch.Size([168])
2017-05-05 22:10:10,303 : INFO : torch.Size([168, 168])
2017-05-05 22:10:10,303 : INFO : torch.Size([168])
2017-05-05 22:10:10,303 : INFO : torch.Size([168, 300])
2017-05-05 22:10:10,304 : INFO : torch.Size([168])
2017-05-05 22:10:10,304 : INFO : torch.Size([168, 168])
2017-05-05 22:10:10,304 : INFO : torch.Size([168])
2017-05-05 22:10:10,304 : INFO : torch.Size([168, 300])
2017-05-05 22:10:10,304 : INFO : torch.Size([168])
2017-05-05 22:10:10,305 : INFO : torch.Size([168, 168])
2017-05-05 22:10:10,305 : INFO : torch.Size([168])
2017-05-05 22:10:10,305 : INFO : torch.Size([168, 300])
2017-05-05 22:10:10,305 : INFO : torch.Size([168])
2017-05-05 22:10:10,305 : INFO : torch.Size([168, 168])
2017-05-05 22:10:10,306 : INFO : torch.Size([168])
2017-05-05 22:10:10,306 : INFO : torch.Size([3, 168])
2017-05-05 22:10:10,306 : INFO : torch.Size([3])
2017-05-05 22:10:10,306 : INFO : torch.Size([21705, 300])
2017-05-05 22:10:10,307 : INFO : torch.Size([47, 300])
2017-05-05 22:10:10,307 : INFO : torch.Size([48, 300])
2017-05-05 22:10:10,307 : INFO : sum
2017-05-05 22:10:10,307 : INFO : 6856347
2017-05-05 22:10:10,307 : INFO : ____________
2017-05-05 22:10:10,308 : INFO : ==> File found, loading to memory
2017-05-05 22:10:28,957 : INFO : ==> GLOVE vocabulary size: 2196016
2017-05-05 22:10:29,601 : INFO : done creating emb, quit
2017-05-05 22:10:29,601 : INFO : quit program due to memory leak during preprocess data, please rerun sentiment.py
2017-05-05 22:12:44,212 : INFO : ==> Train loss   : 0.000983
2017-05-05 22:12:44,212 : INFO : Epoch
2017-05-05 22:12:44,212 : INFO : 22
2017-05-05 22:12:44,212 : INFO : train percentage
2017-05-05 22:12:44,213 : INFO : 0.999855491329
2017-05-05 22:12:44,213 : INFO : Epoch
2017-05-05 22:12:44,213 : INFO : 22
2017-05-05 22:12:44,213 : INFO : dev percentage
2017-05-05 22:12:44,213 : INFO : 0.790137614679
2017-05-05 22:12:44,213 : INFO : Epoch
2017-05-05 22:12:44,213 : INFO : 22
2017-05-05 22:12:44,213 : INFO : test percentage
2017-05-05 22:12:44,214 : INFO : 0.796265788029
2017-05-05 22:30:31,346 : INFO : ==> Train loss   : 0.002059
2017-05-05 22:30:31,346 : INFO : Epoch
2017-05-05 22:30:31,346 : INFO : 23
2017-05-05 22:30:31,346 : INFO : train percentage
2017-05-05 22:30:31,346 : INFO : 0.999566473988
2017-05-05 22:30:31,347 : INFO : Epoch
2017-05-05 22:30:31,347 : INFO : 23
2017-05-05 22:30:31,347 : INFO : dev percentage
2017-05-05 22:30:31,347 : INFO : 0.800458715596
2017-05-05 22:30:31,347 : INFO : Epoch
2017-05-05 22:30:31,347 : INFO : 23
2017-05-05 22:30:31,347 : INFO : test percentage
2017-05-05 22:30:31,348 : INFO : 0.788577704558
2017-05-05 22:48:05,332 : INFO : ==> Train loss   : 0.000705
2017-05-05 22:48:05,332 : INFO : Epoch
2017-05-05 22:48:05,332 : INFO : 24
2017-05-05 22:48:05,332 : INFO : train percentage
2017-05-05 22:48:05,332 : INFO : 1.0
2017-05-05 22:48:05,332 : INFO : Epoch
2017-05-05 22:48:05,332 : INFO : 24
2017-05-05 22:48:05,332 : INFO : dev percentage
2017-05-05 22:48:05,333 : INFO : 0.799311926606
2017-05-05 22:48:05,333 : INFO : Epoch
2017-05-05 22:48:05,333 : INFO : 24
2017-05-05 22:48:05,333 : INFO : test percentage
2017-05-05 22:48:05,333 : INFO : 0.789676002197
2017-05-05 23:05:16,052 : INFO : ==> Train loss   : 0.000653
2017-05-05 23:05:16,052 : INFO : Epoch
2017-05-05 23:05:16,052 : INFO : 25
2017-05-05 23:05:16,052 : INFO : train percentage
2017-05-05 23:05:16,052 : INFO : 1.0
2017-05-05 23:05:16,052 : INFO : Epoch
2017-05-05 23:05:16,053 : INFO : 25
2017-05-05 23:05:16,053 : INFO : dev percentage
2017-05-05 23:05:16,053 : INFO : 0.794724770642
2017-05-05 23:05:16,053 : INFO : Epoch
2017-05-05 23:05:16,053 : INFO : 25
2017-05-05 23:05:16,053 : INFO : test percentage
2017-05-05 23:05:16,053 : INFO : 0.792970895113
2017-05-05 23:22:27,515 : INFO : ==> Train loss   : 0.000499
2017-05-05 23:22:27,515 : INFO : Epoch
2017-05-05 23:22:27,515 : INFO : 26
2017-05-05 23:22:27,515 : INFO : train percentage
2017-05-05 23:22:27,515 : INFO : 1.0
2017-05-05 23:22:27,516 : INFO : Epoch
2017-05-05 23:22:27,516 : INFO : 26
2017-05-05 23:22:27,516 : INFO : dev percentage
2017-05-05 23:22:27,516 : INFO : 0.790137614679
2017-05-05 23:22:27,516 : INFO : Epoch
2017-05-05 23:22:27,516 : INFO : 26
2017-05-05 23:22:27,516 : INFO : test percentage
2017-05-05 23:22:27,517 : INFO : 0.791323448655
2017-05-05 23:39:41,825 : INFO : ==> Train loss   : 0.000662
2017-05-05 23:39:41,825 : INFO : Epoch
2017-05-05 23:39:41,825 : INFO : 27
2017-05-05 23:39:41,825 : INFO : train percentage
2017-05-05 23:39:41,826 : INFO : 1.0
2017-05-05 23:39:41,826 : INFO : Epoch
2017-05-05 23:39:41,826 : INFO : 27
2017-05-05 23:39:41,826 : INFO : dev percentage
2017-05-05 23:39:41,826 : INFO : 0.794724770642
2017-05-05 23:39:41,826 : INFO : Epoch
2017-05-05 23:39:41,826 : INFO : 27
2017-05-05 23:39:41,826 : INFO : test percentage
2017-05-05 23:39:41,826 : INFO : 0.788577704558
2017-05-05 23:56:57,238 : INFO : ==> Train loss   : 0.001647
2017-05-05 23:56:57,238 : INFO : Epoch
2017-05-05 23:56:57,238 : INFO : 28
2017-05-05 23:56:57,238 : INFO : train percentage
2017-05-05 23:56:57,238 : INFO : 0.999710982659
2017-05-05 23:56:57,239 : INFO : Epoch
2017-05-05 23:56:57,239 : INFO : 28
2017-05-05 23:56:57,239 : INFO : dev percentage
2017-05-05 23:56:57,239 : INFO : 0.795871559633
2017-05-05 23:56:57,239 : INFO : Epoch
2017-05-05 23:56:57,239 : INFO : 28
2017-05-05 23:56:57,239 : INFO : test percentage
2017-05-05 23:56:57,239 : INFO : 0.793520043932
2017-05-06 00:14:05,985 : INFO : ==> Train loss   : 0.000497
2017-05-06 00:14:05,985 : INFO : Epoch
2017-05-06 00:14:05,986 : INFO : 29
2017-05-06 00:14:05,986 : INFO : train percentage
2017-05-06 00:14:05,986 : INFO : 1.0
2017-05-06 00:14:05,986 : INFO : Epoch
2017-05-06 00:14:05,986 : INFO : 29
2017-05-06 00:14:05,986 : INFO : dev percentage
2017-05-06 00:14:05,986 : INFO : 0.801605504587
2017-05-06 00:14:05,987 : INFO : Epoch
2017-05-06 00:14:05,987 : INFO : 29
2017-05-06 00:14:05,987 : INFO : test percentage
2017-05-06 00:14:05,987 : INFO : 0.7869302581
2017-05-06 00:31:12,907 : INFO : ==> Train loss   : 0.000525
2017-05-06 00:31:12,907 : INFO : Epoch
2017-05-06 00:31:12,908 : INFO : 30
2017-05-06 00:31:12,908 : INFO : train percentage
2017-05-06 00:31:12,908 : INFO : 0.999855491329
2017-05-06 00:31:12,908 : INFO : Epoch
2017-05-06 00:31:12,908 : INFO : 30
2017-05-06 00:31:12,908 : INFO : dev percentage
2017-05-06 00:31:12,908 : INFO : 0.797018348624
2017-05-06 00:31:12,908 : INFO : Epoch
2017-05-06 00:31:12,909 : INFO : 30
2017-05-06 00:31:12,909 : INFO : test percentage
2017-05-06 00:31:12,909 : INFO : 0.791872597474
2017-05-06 00:48:23,670 : INFO : ==> Train loss   : 0.001740
2017-05-06 00:48:23,670 : INFO : Epoch
2017-05-06 00:48:23,671 : INFO : 31
2017-05-06 00:48:23,671 : INFO : train percentage
2017-05-06 00:48:23,671 : INFO : 1.0
2017-05-06 00:48:23,671 : INFO : Epoch
2017-05-06 00:48:23,671 : INFO : 31
2017-05-06 00:48:23,671 : INFO : dev percentage
2017-05-06 00:48:23,671 : INFO : 0.790137614679
2017-05-06 00:48:23,671 : INFO : Epoch
2017-05-06 00:48:23,672 : INFO : 31
2017-05-06 00:48:23,672 : INFO : test percentage
2017-05-06 00:48:23,672 : INFO : 0.794618341571
2017-05-06 01:05:30,733 : INFO : ==> Train loss   : 0.000443
2017-05-06 01:05:30,733 : INFO : Epoch
2017-05-06 01:05:30,733 : INFO : 32
2017-05-06 01:05:30,733 : INFO : train percentage
2017-05-06 01:05:30,733 : INFO : 1.0
2017-05-06 01:05:30,733 : INFO : Epoch
2017-05-06 01:05:30,734 : INFO : 32
2017-05-06 01:05:30,734 : INFO : dev percentage
2017-05-06 01:05:30,734 : INFO : 0.792431192661
2017-05-06 01:05:30,734 : INFO : Epoch
2017-05-06 01:05:30,734 : INFO : 32
2017-05-06 01:05:30,734 : INFO : test percentage
2017-05-06 01:05:30,734 : INFO : 0.791323448655
2017-05-06 01:22:43,216 : INFO : ==> Train loss   : 0.000303
2017-05-06 01:22:43,216 : INFO : Epoch
2017-05-06 01:22:43,217 : INFO : 33
2017-05-06 01:22:43,217 : INFO : train percentage
2017-05-06 01:22:43,217 : INFO : 0.999855491329
2017-05-06 01:22:43,217 : INFO : Epoch
2017-05-06 01:22:43,217 : INFO : 33
2017-05-06 01:22:43,217 : INFO : dev percentage
2017-05-06 01:22:43,217 : INFO : 0.795871559633
2017-05-06 01:22:43,217 : INFO : Epoch
2017-05-06 01:22:43,218 : INFO : 33
2017-05-06 01:22:43,218 : INFO : test percentage
2017-05-06 01:22:43,218 : INFO : 0.789126853377
2017-05-06 01:39:58,799 : INFO : ==> Train loss   : 0.000458
2017-05-06 01:39:58,800 : INFO : Epoch
2017-05-06 01:39:58,800 : INFO : 34
2017-05-06 01:39:58,800 : INFO : train percentage
2017-05-06 01:39:58,800 : INFO : 0.999855491329
2017-05-06 01:39:58,800 : INFO : Epoch
2017-05-06 01:39:58,800 : INFO : 34
2017-05-06 01:39:58,800 : INFO : dev percentage
2017-05-06 01:39:58,800 : INFO : 0.795871559633
2017-05-06 01:39:58,800 : INFO : Epoch
2017-05-06 01:39:58,801 : INFO : 34
2017-05-06 01:39:58,801 : INFO : test percentage
2017-05-06 01:39:58,801 : INFO : 0.790774299835
2017-05-06 01:57:10,090 : INFO : ==> Train loss   : 0.000187
2017-05-06 01:57:10,090 : INFO : Epoch
2017-05-06 01:57:10,090 : INFO : 35
2017-05-06 01:57:10,090 : INFO : train percentage
2017-05-06 01:57:10,090 : INFO : 1.0
2017-05-06 01:57:10,090 : INFO : Epoch
2017-05-06 01:57:10,091 : INFO : 35
2017-05-06 01:57:10,091 : INFO : dev percentage
2017-05-06 01:57:10,091 : INFO : 0.79128440367
2017-05-06 01:57:10,091 : INFO : Epoch
2017-05-06 01:57:10,091 : INFO : 35
2017-05-06 01:57:10,091 : INFO : test percentage
2017-05-06 01:57:10,091 : INFO : 0.789676002197
2017-05-06 02:14:18,658 : INFO : ==> Train loss   : 0.000215
2017-05-06 02:14:18,658 : INFO : Epoch
2017-05-06 02:14:18,658 : INFO : 36
2017-05-06 02:14:18,658 : INFO : train percentage
2017-05-06 02:14:18,659 : INFO : 1.0
2017-05-06 02:14:18,659 : INFO : Epoch
2017-05-06 02:14:18,659 : INFO : 36
2017-05-06 02:14:18,659 : INFO : dev percentage
2017-05-06 02:14:18,659 : INFO : 0.792431192661
2017-05-06 02:14:18,659 : INFO : Epoch
2017-05-06 02:14:18,659 : INFO : 36
2017-05-06 02:14:18,659 : INFO : test percentage
2017-05-06 02:14:18,660 : INFO : 0.787479406919
2017-05-06 02:31:28,788 : INFO : ==> Train loss   : 0.000223
2017-05-06 02:31:28,788 : INFO : Epoch
2017-05-06 02:31:28,788 : INFO : 37
2017-05-06 02:31:28,788 : INFO : train percentage
2017-05-06 02:31:28,788 : INFO : 1.0
2017-05-06 02:31:28,789 : INFO : Epoch
2017-05-06 02:31:28,789 : INFO : 37
2017-05-06 02:31:28,789 : INFO : dev percentage
2017-05-06 02:31:28,789 : INFO : 0.788990825688
2017-05-06 02:31:28,789 : INFO : Epoch
2017-05-06 02:31:28,789 : INFO : 37
2017-05-06 02:31:28,789 : INFO : test percentage
2017-05-06 02:31:28,789 : INFO : 0.789676002197
2017-05-06 02:48:49,185 : INFO : ==> Train loss   : 0.000175
2017-05-06 02:48:49,185 : INFO : Epoch
2017-05-06 02:48:49,185 : INFO : 38
2017-05-06 02:48:49,185 : INFO : train percentage
2017-05-06 02:48:49,185 : INFO : 1.0
2017-05-06 02:48:49,185 : INFO : Epoch
2017-05-06 02:48:49,185 : INFO : 38
2017-05-06 02:48:49,186 : INFO : dev percentage
2017-05-06 02:48:49,186 : INFO : 0.790137614679
2017-05-06 02:48:49,186 : INFO : Epoch
2017-05-06 02:48:49,186 : INFO : 38
2017-05-06 02:48:49,186 : INFO : test percentage
2017-05-06 02:48:49,186 : INFO : 0.782537067545
2017-05-06 03:06:08,544 : INFO : ==> Train loss   : 0.000162
2017-05-06 03:06:08,545 : INFO : Epoch
2017-05-06 03:06:08,545 : INFO : 39
2017-05-06 03:06:08,545 : INFO : train percentage
2017-05-06 03:06:08,545 : INFO : 1.0
2017-05-06 03:06:08,545 : INFO : Epoch
2017-05-06 03:06:08,545 : INFO : 39
2017-05-06 03:06:08,545 : INFO : dev percentage
2017-05-06 03:06:08,545 : INFO : 0.794724770642
2017-05-06 03:06:08,546 : INFO : Epoch
2017-05-06 03:06:08,546 : INFO : 39
2017-05-06 03:06:08,546 : INFO : test percentage
2017-05-06 03:06:08,546 : INFO : 0.784733662823
2017-05-06 03:23:24,173 : INFO : ==> Train loss   : 0.000184
2017-05-06 03:23:24,174 : INFO : Epoch
2017-05-06 03:23:24,174 : INFO : 40
2017-05-06 03:23:24,174 : INFO : train percentage
2017-05-06 03:23:24,174 : INFO : 1.0
2017-05-06 03:23:24,174 : INFO : Epoch
2017-05-06 03:23:24,174 : INFO : 40
2017-05-06 03:23:24,174 : INFO : dev percentage
2017-05-06 03:23:24,174 : INFO : 0.778669724771
2017-05-06 03:23:24,174 : INFO : Epoch
2017-05-06 03:23:24,175 : INFO : 40
2017-05-06 03:23:24,175 : INFO : test percentage
2017-05-06 03:23:24,175 : INFO : 0.784733662823
2017-05-06 03:40:43,085 : INFO : ==> Train loss   : 0.000214
2017-05-06 03:40:43,085 : INFO : Epoch
2017-05-06 03:40:43,085 : INFO : 41
2017-05-06 03:40:43,086 : INFO : train percentage
2017-05-06 03:40:43,086 : INFO : 1.0
2017-05-06 03:40:43,086 : INFO : Epoch
2017-05-06 03:40:43,086 : INFO : 41
2017-05-06 03:40:43,086 : INFO : dev percentage
2017-05-06 03:40:43,086 : INFO : 0.790137614679
2017-05-06 03:40:43,086 : INFO : Epoch
2017-05-06 03:40:43,086 : INFO : 41
2017-05-06 03:40:43,087 : INFO : test percentage
2017-05-06 03:40:43,087 : INFO : 0.7869302581
2017-05-06 03:57:55,720 : INFO : ==> Train loss   : 0.000282
2017-05-06 03:57:55,720 : INFO : Epoch
2017-05-06 03:57:55,720 : INFO : 42
2017-05-06 03:57:55,720 : INFO : train percentage
2017-05-06 03:57:55,720 : INFO : 1.0
2017-05-06 03:57:55,721 : INFO : Epoch
2017-05-06 03:57:55,721 : INFO : 42
2017-05-06 03:57:55,721 : INFO : dev percentage
2017-05-06 03:57:55,721 : INFO : 0.784403669725
2017-05-06 03:57:55,721 : INFO : Epoch
2017-05-06 03:57:55,721 : INFO : 42
2017-05-06 03:57:55,721 : INFO : test percentage
2017-05-06 03:57:55,721 : INFO : 0.780340472268
2017-05-06 04:15:03,346 : INFO : ==> Train loss   : 0.000137
2017-05-06 04:15:03,346 : INFO : Epoch
2017-05-06 04:15:03,346 : INFO : 43
2017-05-06 04:15:03,346 : INFO : train percentage
2017-05-06 04:15:03,346 : INFO : 1.0
2017-05-06 04:15:03,347 : INFO : Epoch
2017-05-06 04:15:03,347 : INFO : 43
2017-05-06 04:15:03,347 : INFO : dev percentage
2017-05-06 04:15:03,347 : INFO : 0.783256880734
2017-05-06 04:15:03,347 : INFO : Epoch
2017-05-06 04:15:03,347 : INFO : 43
2017-05-06 04:15:03,347 : INFO : test percentage
2017-05-06 04:15:03,347 : INFO : 0.783635365184
2017-05-06 04:32:11,072 : INFO : ==> Train loss   : 0.000127
2017-05-06 04:32:11,073 : INFO : Epoch
2017-05-06 04:32:11,073 : INFO : 44
2017-05-06 04:32:11,073 : INFO : train percentage
2017-05-06 04:32:11,073 : INFO : 1.0
2017-05-06 04:32:11,073 : INFO : Epoch
2017-05-06 04:32:11,073 : INFO : 44
2017-05-06 04:32:11,073 : INFO : dev percentage
2017-05-06 04:32:11,073 : INFO : 0.782110091743
2017-05-06 04:32:11,074 : INFO : Epoch
2017-05-06 04:32:11,074 : INFO : 44
2017-05-06 04:32:11,074 : INFO : test percentage
2017-05-06 04:32:11,074 : INFO : 0.785831960461
2017-05-06 04:49:21,988 : INFO : ==> Train loss   : 0.000181
2017-05-06 04:49:21,988 : INFO : Epoch
2017-05-06 04:49:21,988 : INFO : 45
2017-05-06 04:49:21,988 : INFO : train percentage
2017-05-06 04:49:21,988 : INFO : 1.0
2017-05-06 04:49:21,988 : INFO : Epoch
2017-05-06 04:49:21,988 : INFO : 45
2017-05-06 04:49:21,989 : INFO : dev percentage
2017-05-06 04:49:21,989 : INFO : 0.772935779817
2017-05-06 04:49:21,989 : INFO : Epoch
2017-05-06 04:49:21,989 : INFO : 45
2017-05-06 04:49:21,989 : INFO : test percentage
2017-05-06 04:49:21,989 : INFO : 0.781987918726
2017-05-06 05:06:41,096 : INFO : ==> Train loss   : 0.000103
2017-05-06 05:06:41,097 : INFO : Epoch
2017-05-06 05:06:41,097 : INFO : 46
2017-05-06 05:06:41,097 : INFO : train percentage
2017-05-06 05:06:41,097 : INFO : 1.0
2017-05-06 05:06:41,097 : INFO : Epoch
2017-05-06 05:06:41,097 : INFO : 46
2017-05-06 05:06:41,097 : INFO : dev percentage
2017-05-06 05:06:41,097 : INFO : 0.784403669725
2017-05-06 05:06:41,097 : INFO : Epoch
2017-05-06 05:06:41,098 : INFO : 46
2017-05-06 05:06:41,098 : INFO : test percentage
2017-05-06 05:06:41,098 : INFO : 0.783086216365
2017-05-06 05:23:51,996 : INFO : ==> Train loss   : 0.000080
2017-05-06 05:23:51,996 : INFO : Epoch
2017-05-06 05:23:51,996 : INFO : 47
2017-05-06 05:23:51,997 : INFO : train percentage
2017-05-06 05:23:51,997 : INFO : 1.0
2017-05-06 05:23:51,997 : INFO : Epoch
2017-05-06 05:23:51,997 : INFO : 47
2017-05-06 05:23:51,997 : INFO : dev percentage
2017-05-06 05:23:51,997 : INFO : 0.784403669725
2017-05-06 05:23:51,997 : INFO : Epoch
2017-05-06 05:23:51,997 : INFO : 47
2017-05-06 05:23:51,997 : INFO : test percentage
2017-05-06 05:23:51,998 : INFO : 0.783635365184
2017-05-06 05:41:11,407 : INFO : ==> Train loss   : 0.000074
2017-05-06 05:41:11,407 : INFO : Epoch
2017-05-06 05:41:11,407 : INFO : 48
2017-05-06 05:41:11,407 : INFO : train percentage
2017-05-06 05:41:11,407 : INFO : 1.0
2017-05-06 05:41:11,407 : INFO : Epoch
2017-05-06 05:41:11,408 : INFO : 48
2017-05-06 05:41:11,408 : INFO : dev percentage
2017-05-06 05:41:11,408 : INFO : 0.787844036697
2017-05-06 05:41:11,408 : INFO : Epoch
2017-05-06 05:41:11,408 : INFO : 48
2017-05-06 05:41:11,408 : INFO : test percentage
2017-05-06 05:41:11,408 : INFO : 0.7869302581
2017-05-06 05:58:23,165 : INFO : ==> Train loss   : 0.000133
2017-05-06 05:58:23,165 : INFO : Epoch
2017-05-06 05:58:23,165 : INFO : 49
2017-05-06 05:58:23,165 : INFO : train percentage
2017-05-06 05:58:23,166 : INFO : 1.0
2017-05-06 05:58:23,166 : INFO : Epoch
2017-05-06 05:58:23,166 : INFO : 49
2017-05-06 05:58:23,166 : INFO : dev percentage
2017-05-06 05:58:23,166 : INFO : 0.782110091743
2017-05-06 05:58:23,166 : INFO : Epoch
2017-05-06 05:58:23,166 : INFO : 49
2017-05-06 05:58:23,166 : INFO : test percentage
2017-05-06 05:58:23,166 : INFO : 0.784184514003
2017-05-06 06:15:36,058 : INFO : ==> Train loss   : 0.000081
2017-05-06 06:15:36,058 : INFO : Epoch
2017-05-06 06:15:36,058 : INFO : 50
2017-05-06 06:15:36,058 : INFO : train percentage
2017-05-06 06:15:36,058 : INFO : 1.0
2017-05-06 06:15:36,058 : INFO : Epoch
2017-05-06 06:15:36,058 : INFO : 50
2017-05-06 06:15:36,059 : INFO : dev percentage
2017-05-06 06:15:36,059 : INFO : 0.77752293578
2017-05-06 06:15:36,059 : INFO : Epoch
2017-05-06 06:15:36,059 : INFO : 50
2017-05-06 06:15:36,059 : INFO : test percentage
2017-05-06 06:15:36,059 : INFO : 0.784733662823
2017-05-06 06:32:44,812 : INFO : ==> Train loss   : 0.000144
2017-05-06 06:32:44,812 : INFO : Epoch
2017-05-06 06:32:44,812 : INFO : 51
2017-05-06 06:32:44,812 : INFO : train percentage
2017-05-06 06:32:44,812 : INFO : 1.0
2017-05-06 06:32:44,812 : INFO : Epoch
2017-05-06 06:32:44,812 : INFO : 51
2017-05-06 06:32:44,813 : INFO : dev percentage
2017-05-06 06:32:44,813 : INFO : 0.782110091743
2017-05-06 06:32:44,813 : INFO : Epoch
2017-05-06 06:32:44,813 : INFO : 51
2017-05-06 06:32:44,813 : INFO : test percentage
2017-05-06 06:32:44,813 : INFO : 0.783635365184
2017-05-06 06:50:02,015 : INFO : ==> Train loss   : 0.000512
2017-05-06 06:50:02,016 : INFO : Epoch
2017-05-06 06:50:02,016 : INFO : 52
2017-05-06 06:50:02,016 : INFO : train percentage
2017-05-06 06:50:02,016 : INFO : 0.999855491329
2017-05-06 06:50:02,016 : INFO : Epoch
2017-05-06 06:50:02,016 : INFO : 52
2017-05-06 06:50:02,016 : INFO : dev percentage
2017-05-06 06:50:02,016 : INFO : 0.772935779817
2017-05-06 06:50:02,017 : INFO : Epoch
2017-05-06 06:50:02,017 : INFO : 52
2017-05-06 06:50:02,017 : INFO : test percentage
2017-05-06 06:50:02,017 : INFO : 0.786381109281
2017-05-06 07:07:16,217 : INFO : ==> Train loss   : 0.000121
2017-05-06 07:07:16,217 : INFO : Epoch
2017-05-06 07:07:16,217 : INFO : 53
2017-05-06 07:07:16,217 : INFO : train percentage
2017-05-06 07:07:16,217 : INFO : 1.0
2017-05-06 07:07:16,217 : INFO : Epoch
2017-05-06 07:07:16,218 : INFO : 53
2017-05-06 07:07:16,218 : INFO : dev percentage
2017-05-06 07:07:16,218 : INFO : 0.778669724771
2017-05-06 07:07:16,218 : INFO : Epoch
2017-05-06 07:07:16,218 : INFO : 53
2017-05-06 07:07:16,218 : INFO : test percentage
2017-05-06 07:07:16,218 : INFO : 0.784733662823
2017-05-06 07:24:35,529 : INFO : ==> Train loss   : 0.000092
2017-05-06 07:24:35,530 : INFO : Epoch
2017-05-06 07:24:35,530 : INFO : 54
2017-05-06 07:24:35,530 : INFO : train percentage
2017-05-06 07:24:35,530 : INFO : 1.0
2017-05-06 07:24:35,530 : INFO : Epoch
2017-05-06 07:24:35,530 : INFO : 54
2017-05-06 07:24:35,530 : INFO : dev percentage
2017-05-06 07:24:35,531 : INFO : 0.778669724771
2017-05-06 07:24:35,531 : INFO : Epoch
2017-05-06 07:24:35,531 : INFO : 54
2017-05-06 07:24:35,531 : INFO : test percentage
2017-05-06 07:24:35,531 : INFO : 0.781987918726
2017-05-06 07:41:57,413 : INFO : ==> Train loss   : 0.000081
2017-05-06 07:41:57,413 : INFO : Epoch
2017-05-06 07:41:57,413 : INFO : 55
2017-05-06 07:41:57,413 : INFO : train percentage
2017-05-06 07:41:57,413 : INFO : 1.0
2017-05-06 07:41:57,414 : INFO : Epoch
2017-05-06 07:41:57,414 : INFO : 55
2017-05-06 07:41:57,414 : INFO : dev percentage
2017-05-06 07:41:57,414 : INFO : 0.77752293578
2017-05-06 07:41:57,414 : INFO : Epoch
2017-05-06 07:41:57,414 : INFO : 55
2017-05-06 07:41:57,414 : INFO : test percentage
2017-05-06 07:41:57,414 : INFO : 0.781987918726
2017-05-06 07:59:12,845 : INFO : ==> Train loss   : 0.000074
2017-05-06 07:59:12,845 : INFO : Epoch
2017-05-06 07:59:12,845 : INFO : 56
2017-05-06 07:59:12,845 : INFO : train percentage
2017-05-06 07:59:12,845 : INFO : 1.0
2017-05-06 07:59:12,845 : INFO : Epoch
2017-05-06 07:59:12,845 : INFO : 56
2017-05-06 07:59:12,846 : INFO : dev percentage
2017-05-06 07:59:12,846 : INFO : 0.778669724771
2017-05-06 07:59:12,846 : INFO : Epoch
2017-05-06 07:59:12,846 : INFO : 56
2017-05-06 07:59:12,846 : INFO : test percentage
2017-05-06 07:59:12,846 : INFO : 0.780889621087
2017-05-06 08:16:21,262 : INFO : ==> Train loss   : 0.000061
2017-05-06 08:16:21,262 : INFO : Epoch
2017-05-06 08:16:21,263 : INFO : 57
2017-05-06 08:16:21,263 : INFO : train percentage
2017-05-06 08:16:21,263 : INFO : 1.0
2017-05-06 08:16:21,263 : INFO : Epoch
2017-05-06 08:16:21,263 : INFO : 57
2017-05-06 08:16:21,263 : INFO : dev percentage
2017-05-06 08:16:21,263 : INFO : 0.780963302752
2017-05-06 08:16:21,263 : INFO : Epoch
2017-05-06 08:16:21,263 : INFO : 57
2017-05-06 08:16:21,264 : INFO : test percentage
2017-05-06 08:16:21,264 : INFO : 0.784184514003
2017-05-06 08:33:48,396 : INFO : ==> Train loss   : 0.000244
2017-05-06 08:33:48,396 : INFO : Epoch
2017-05-06 08:33:48,396 : INFO : 58
2017-05-06 08:33:48,396 : INFO : train percentage
2017-05-06 08:33:48,396 : INFO : 0.999855491329
2017-05-06 08:33:48,397 : INFO : Epoch
2017-05-06 08:33:48,397 : INFO : 58
2017-05-06 08:33:48,397 : INFO : dev percentage
2017-05-06 08:33:48,397 : INFO : 0.776376146789
2017-05-06 08:33:48,397 : INFO : Epoch
2017-05-06 08:33:48,397 : INFO : 58
2017-05-06 08:33:48,397 : INFO : test percentage
2017-05-06 08:33:48,397 : INFO : 0.781987918726
2017-05-06 08:51:00,049 : INFO : ==> Train loss   : 0.000057
2017-05-06 08:51:00,049 : INFO : Epoch
2017-05-06 08:51:00,049 : INFO : 59
2017-05-06 08:51:00,049 : INFO : train percentage
2017-05-06 08:51:00,049 : INFO : 1.0
2017-05-06 08:51:00,049 : INFO : Epoch
2017-05-06 08:51:00,049 : INFO : 59
2017-05-06 08:51:00,050 : INFO : dev percentage
2017-05-06 08:51:00,050 : INFO : 0.776376146789
2017-05-06 08:51:00,050 : INFO : Epoch
2017-05-06 08:51:00,050 : INFO : 59
2017-05-06 08:51:00,050 : INFO : test percentage
2017-05-06 08:51:00,050 : INFO : 0.782537067545
2017-05-06 09:08:18,616 : INFO : ==> Train loss   : 0.000048
2017-05-06 09:08:18,616 : INFO : Epoch
2017-05-06 09:08:18,616 : INFO : 60
2017-05-06 09:08:18,616 : INFO : train percentage
2017-05-06 09:08:18,617 : INFO : 1.0
2017-05-06 09:08:18,617 : INFO : Epoch
2017-05-06 09:08:18,617 : INFO : 60
2017-05-06 09:08:18,617 : INFO : dev percentage
2017-05-06 09:08:18,617 : INFO : 0.77752293578
2017-05-06 09:08:18,617 : INFO : Epoch
2017-05-06 09:08:18,617 : INFO : 60
2017-05-06 09:08:18,617 : INFO : test percentage
2017-05-06 09:08:18,618 : INFO : 0.783635365184
2017-05-06 09:25:31,325 : INFO : ==> Train loss   : 0.000060
2017-05-06 09:25:31,325 : INFO : Epoch
2017-05-06 09:25:31,326 : INFO : 61
2017-05-06 09:25:31,326 : INFO : train percentage
2017-05-06 09:25:31,326 : INFO : 1.0
2017-05-06 09:25:31,326 : INFO : Epoch
2017-05-06 09:25:31,326 : INFO : 61
2017-05-06 09:25:31,326 : INFO : dev percentage
2017-05-06 09:25:31,326 : INFO : 0.776376146789
2017-05-06 09:25:31,327 : INFO : Epoch
2017-05-06 09:25:31,327 : INFO : 61
2017-05-06 09:25:31,327 : INFO : test percentage
2017-05-06 09:25:31,327 : INFO : 0.783086216365
2017-05-06 09:43:12,419 : INFO : ==> Train loss   : 0.000065
2017-05-06 09:43:12,419 : INFO : Epoch
2017-05-06 09:43:12,419 : INFO : 62
2017-05-06 09:43:12,419 : INFO : train percentage
2017-05-06 09:43:12,420 : INFO : 1.0
2017-05-06 09:43:12,420 : INFO : Epoch
2017-05-06 09:43:12,420 : INFO : 62
2017-05-06 09:43:12,420 : INFO : dev percentage
2017-05-06 09:43:12,420 : INFO : 0.775229357798
2017-05-06 09:43:12,420 : INFO : Epoch
2017-05-06 09:43:12,420 : INFO : 62
2017-05-06 09:43:12,420 : INFO : test percentage
2017-05-06 09:43:12,421 : INFO : 0.781987918726
2017-05-06 10:00:28,852 : INFO : ==> Train loss   : 0.000061
2017-05-06 10:00:28,852 : INFO : Epoch
2017-05-06 10:00:28,852 : INFO : 63
2017-05-06 10:00:28,852 : INFO : train percentage
2017-05-06 10:00:28,853 : INFO : 1.0
2017-05-06 10:00:28,853 : INFO : Epoch
2017-05-06 10:00:28,853 : INFO : 63
2017-05-06 10:00:28,853 : INFO : dev percentage
2017-05-06 10:00:28,853 : INFO : 0.775229357798
2017-05-06 10:00:28,853 : INFO : Epoch
2017-05-06 10:00:28,853 : INFO : 63
2017-05-06 10:00:28,853 : INFO : test percentage
2017-05-06 10:00:28,853 : INFO : 0.779242174629
2017-05-06 10:18:16,988 : INFO : ==> Train loss   : 0.000069
2017-05-06 10:18:16,988 : INFO : Epoch
2017-05-06 10:18:16,988 : INFO : 64
2017-05-06 10:18:16,988 : INFO : train percentage
2017-05-06 10:18:16,989 : INFO : 1.0
2017-05-06 10:18:16,989 : INFO : Epoch
2017-05-06 10:18:16,989 : INFO : 64
2017-05-06 10:18:16,989 : INFO : dev percentage
2017-05-06 10:18:16,989 : INFO : 0.775229357798
2017-05-06 10:18:16,989 : INFO : Epoch
2017-05-06 10:18:16,989 : INFO : 64
2017-05-06 10:18:16,989 : INFO : test percentage
2017-05-06 10:18:16,990 : INFO : 0.783635365184
2017-05-06 10:36:14,304 : INFO : ==> Train loss   : 0.000060
2017-05-06 10:36:14,304 : INFO : Epoch
2017-05-06 10:36:14,304 : INFO : 65
2017-05-06 10:36:14,304 : INFO : train percentage
2017-05-06 10:36:14,304 : INFO : 1.0
2017-05-06 10:36:14,304 : INFO : Epoch
2017-05-06 10:36:14,305 : INFO : 65
2017-05-06 10:36:14,305 : INFO : dev percentage
2017-05-06 10:36:14,305 : INFO : 0.779816513761
2017-05-06 10:36:14,305 : INFO : Epoch
2017-05-06 10:36:14,305 : INFO : 65
2017-05-06 10:36:14,305 : INFO : test percentage
2017-05-06 10:36:14,305 : INFO : 0.785282811642
2017-05-06 10:49:33,532 : INFO : LOG_FILE
2017-05-06 10:49:33,532 : INFO : _________________________________start___________________________________
2017-05-06 10:49:33,539 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-06 10:49:33,742 : INFO : ==> SST vocabulary size : 21705
2017-05-06 10:49:33,742 : INFO : ==> SST rel vocabulary size : 48
2017-05-06 10:49:33,743 : INFO : ==> SST tag vocabulary size : 47
2017-05-06 10:51:07,720 : INFO : LOG_FILE
2017-05-06 10:51:07,720 : INFO : _________________________________start___________________________________
2017-05-06 10:51:07,726 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-06 10:51:07,925 : INFO : ==> SST vocabulary size : 21705
2017-05-06 10:51:07,925 : INFO : ==> SST rel vocabulary size : 48
2017-05-06 10:51:07,925 : INFO : ==> SST tag vocabulary size : 47
2017-05-06 10:52:45,861 : INFO : LOG_FILE
2017-05-06 10:52:45,861 : INFO : _________________________________start___________________________________
2017-05-06 10:52:45,869 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-06 10:52:46,079 : INFO : ==> SST vocabulary size : 21705
2017-05-06 10:52:46,079 : INFO : ==> SST rel vocabulary size : 48
2017-05-06 10:52:46,079 : INFO : ==> SST tag vocabulary size : 47
2017-05-06 10:53:00,544 : INFO : LOG_FILE
2017-05-06 10:53:00,544 : INFO : _________________________________start___________________________________
2017-05-06 10:53:00,551 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-06 10:53:00,752 : INFO : ==> SST vocabulary size : 21705
2017-05-06 10:53:00,753 : INFO : ==> SST rel vocabulary size : 48
2017-05-06 10:53:00,753 : INFO : ==> SST tag vocabulary size : 47
2017-05-06 10:54:17,890 : INFO : ==> Train loss   : 0.000084
2017-05-06 10:54:17,890 : INFO : Epoch
2017-05-06 10:54:17,891 : INFO : 66
2017-05-06 10:54:17,891 : INFO : train percentage
2017-05-06 10:54:17,891 : INFO : 1.0
2017-05-06 10:54:17,891 : INFO : Epoch
2017-05-06 10:54:17,891 : INFO : 66
2017-05-06 10:54:17,891 : INFO : dev percentage
2017-05-06 10:54:17,891 : INFO : 0.776376146789
2017-05-06 10:54:17,891 : INFO : Epoch
2017-05-06 10:54:17,892 : INFO : 66
2017-05-06 10:54:17,892 : INFO : test percentage
2017-05-06 10:54:17,892 : INFO : 0.788577704558
2017-05-06 10:55:05,162 : INFO : LOG_FILE
2017-05-06 10:55:05,162 : INFO : _________________________________start___________________________________
2017-05-06 10:55:05,168 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-06 10:55:05,389 : INFO : ==> SST vocabulary size : 21705
2017-05-06 10:55:05,389 : INFO : ==> SST rel vocabulary size : 48
2017-05-06 10:55:05,389 : INFO : ==> SST tag vocabulary size : 47
2017-05-06 10:55:11,916 : INFO : _param count_
2017-05-06 10:55:11,916 : INFO : torch.Size([504, 600])
2017-05-06 10:55:11,916 : INFO : torch.Size([504, 168])
2017-05-06 10:55:11,916 : INFO : torch.Size([504])
2017-05-06 10:55:11,917 : INFO : torch.Size([504])
2017-05-06 10:55:11,917 : INFO : torch.Size([168, 168])
2017-05-06 10:55:11,917 : INFO : torch.Size([168])
2017-05-06 10:55:11,917 : INFO : torch.Size([168, 1200])
2017-05-06 10:55:11,917 : INFO : torch.Size([168])
2017-05-06 10:55:11,917 : INFO : torch.Size([504, 1200])
2017-05-06 10:55:11,917 : INFO : torch.Size([504, 168])
2017-05-06 10:55:11,918 : INFO : torch.Size([504])
2017-05-06 10:55:11,918 : INFO : torch.Size([504])
2017-05-06 10:55:11,918 : INFO : torch.Size([3, 168])
2017-05-06 10:55:11,918 : INFO : torch.Size([3])
2017-05-06 10:55:11,918 : INFO : torch.Size([21705, 300])
2017-05-06 10:55:11,918 : INFO : torch.Size([47, 300])
2017-05-06 10:55:11,918 : INFO : torch.Size([48, 300])
2017-05-06 10:55:11,918 : INFO : sum
2017-05-06 10:55:11,919 : INFO : 7849227
2017-05-06 10:55:11,919 : INFO : ____________
2017-05-06 10:55:29,179 : INFO : LOG_FILE
2017-05-06 10:55:29,179 : INFO : _________________________________start___________________________________
2017-05-06 10:55:29,185 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-06 10:55:29,409 : INFO : ==> SST vocabulary size : 21705
2017-05-06 10:55:29,410 : INFO : ==> SST rel vocabulary size : 48
2017-05-06 10:55:29,410 : INFO : ==> SST tag vocabulary size : 47
2017-05-06 10:55:36,012 : INFO : _param count_
2017-05-06 10:55:36,012 : INFO : torch.Size([504, 600])
2017-05-06 10:55:36,013 : INFO : torch.Size([504, 168])
2017-05-06 10:55:36,013 : INFO : torch.Size([504])
2017-05-06 10:55:36,013 : INFO : torch.Size([504])
2017-05-06 10:55:36,013 : INFO : torch.Size([168, 168])
2017-05-06 10:55:36,013 : INFO : torch.Size([168])
2017-05-06 10:55:36,013 : INFO : torch.Size([168, 1200])
2017-05-06 10:55:36,013 : INFO : torch.Size([168])
2017-05-06 10:55:36,014 : INFO : torch.Size([504, 1200])
2017-05-06 10:55:36,014 : INFO : torch.Size([504, 168])
2017-05-06 10:55:36,014 : INFO : torch.Size([504])
2017-05-06 10:55:36,014 : INFO : torch.Size([504])
2017-05-06 10:55:36,014 : INFO : torch.Size([3, 168])
2017-05-06 10:55:36,014 : INFO : torch.Size([3])
2017-05-06 10:55:36,014 : INFO : torch.Size([21705, 300])
2017-05-06 10:55:36,015 : INFO : torch.Size([47, 300])
2017-05-06 10:55:36,015 : INFO : torch.Size([48, 300])
2017-05-06 10:55:36,015 : INFO : sum
2017-05-06 10:55:36,015 : INFO : 7849227
2017-05-06 10:55:36,015 : INFO : ____________
2017-05-06 10:56:09,665 : INFO : LOG_FILE
2017-05-06 10:56:09,666 : INFO : _________________________________start___________________________________
2017-05-06 10:56:09,679 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-06 10:56:10,114 : INFO : ==> SST vocabulary size : 21705
2017-05-06 10:56:10,115 : INFO : ==> SST rel vocabulary size : 48
2017-05-06 10:56:10,115 : INFO : ==> SST tag vocabulary size : 47
2017-05-06 10:56:18,075 : INFO : _param count_
2017-05-06 10:56:18,080 : INFO : torch.Size([504, 600])
2017-05-06 10:56:18,081 : INFO : torch.Size([504, 168])
2017-05-06 10:56:18,082 : INFO : torch.Size([504])
2017-05-06 10:56:18,083 : INFO : torch.Size([504])
2017-05-06 10:56:18,084 : INFO : torch.Size([168, 168])
2017-05-06 10:56:18,084 : INFO : torch.Size([168])
2017-05-06 10:56:18,085 : INFO : torch.Size([168, 1200])
2017-05-06 10:56:18,086 : INFO : torch.Size([168])
2017-05-06 10:56:18,087 : INFO : torch.Size([504, 1200])
2017-05-06 10:56:18,088 : INFO : torch.Size([504, 168])
2017-05-06 10:56:18,089 : INFO : torch.Size([504])
2017-05-06 10:56:18,090 : INFO : torch.Size([504])
2017-05-06 10:56:18,091 : INFO : torch.Size([3, 168])
2017-05-06 10:56:18,091 : INFO : torch.Size([3])
2017-05-06 10:56:18,092 : INFO : torch.Size([21705, 300])
2017-05-06 10:56:18,092 : INFO : torch.Size([47, 300])
2017-05-06 10:56:18,093 : INFO : torch.Size([48, 300])
2017-05-06 10:56:18,093 : INFO : sum
2017-05-06 10:56:18,094 : INFO : 7849227
2017-05-06 10:56:18,094 : INFO : ____________
2017-05-06 10:57:45,344 : INFO : LOG_FILE
2017-05-06 10:57:45,344 : INFO : _________________________________start___________________________________
2017-05-06 10:57:45,351 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-06 10:57:45,563 : INFO : ==> SST vocabulary size : 21705
2017-05-06 10:57:45,563 : INFO : ==> SST rel vocabulary size : 48
2017-05-06 10:57:45,563 : INFO : ==> SST tag vocabulary size : 47
2017-05-06 10:57:52,189 : INFO : _param count_
2017-05-06 10:57:52,189 : INFO : torch.Size([504, 600])
2017-05-06 10:57:52,189 : INFO : torch.Size([504, 168])
2017-05-06 10:57:52,189 : INFO : torch.Size([504])
2017-05-06 10:57:52,189 : INFO : torch.Size([504])
2017-05-06 10:57:52,190 : INFO : torch.Size([168, 168])
2017-05-06 10:57:52,190 : INFO : torch.Size([168])
2017-05-06 10:57:52,190 : INFO : torch.Size([168, 1200])
2017-05-06 10:57:52,190 : INFO : torch.Size([168])
2017-05-06 10:57:52,190 : INFO : torch.Size([504, 1200])
2017-05-06 10:57:52,190 : INFO : torch.Size([504, 168])
2017-05-06 10:57:52,190 : INFO : torch.Size([504])
2017-05-06 10:57:52,190 : INFO : torch.Size([504])
2017-05-06 10:57:52,191 : INFO : torch.Size([3, 168])
2017-05-06 10:57:52,191 : INFO : torch.Size([3])
2017-05-06 10:57:52,191 : INFO : torch.Size([21705, 300])
2017-05-06 10:57:52,191 : INFO : torch.Size([47, 300])
2017-05-06 10:57:52,191 : INFO : torch.Size([48, 300])
2017-05-06 10:57:52,191 : INFO : sum
2017-05-06 10:57:52,191 : INFO : 7849227
2017-05-06 10:57:52,192 : INFO : ____________
2017-05-06 10:59:26,614 : INFO : LOG_FILE
2017-05-06 10:59:26,614 : INFO : _________________________________start___________________________________
2017-05-06 10:59:26,621 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-06 10:59:26,830 : INFO : ==> SST vocabulary size : 21705
2017-05-06 10:59:26,830 : INFO : ==> SST rel vocabulary size : 48
2017-05-06 10:59:26,831 : INFO : ==> SST tag vocabulary size : 47
2017-05-06 10:59:33,449 : INFO : _param count_
2017-05-06 10:59:33,449 : INFO : torch.Size([504, 600])
2017-05-06 10:59:33,449 : INFO : torch.Size([504, 168])
2017-05-06 10:59:33,449 : INFO : torch.Size([504])
2017-05-06 10:59:33,449 : INFO : torch.Size([504])
2017-05-06 10:59:33,450 : INFO : torch.Size([168, 168])
2017-05-06 10:59:33,450 : INFO : torch.Size([168])
2017-05-06 10:59:33,450 : INFO : torch.Size([168, 1200])
2017-05-06 10:59:33,450 : INFO : torch.Size([168])
2017-05-06 10:59:33,450 : INFO : torch.Size([504, 1200])
2017-05-06 10:59:33,450 : INFO : torch.Size([504, 168])
2017-05-06 10:59:33,450 : INFO : torch.Size([504])
2017-05-06 10:59:33,451 : INFO : torch.Size([504])
2017-05-06 10:59:33,451 : INFO : torch.Size([3, 168])
2017-05-06 10:59:33,451 : INFO : torch.Size([3])
2017-05-06 10:59:33,451 : INFO : torch.Size([21705, 300])
2017-05-06 10:59:33,451 : INFO : torch.Size([47, 300])
2017-05-06 10:59:33,451 : INFO : torch.Size([48, 300])
2017-05-06 10:59:33,451 : INFO : sum
2017-05-06 10:59:33,452 : INFO : 7849227
2017-05-06 10:59:33,452 : INFO : ____________
2017-05-06 11:00:11,856 : INFO : LOG_FILE
2017-05-06 11:00:11,856 : INFO : _________________________________start___________________________________
2017-05-06 11:00:11,863 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-06 11:00:12,072 : INFO : ==> SST vocabulary size : 21705
2017-05-06 11:00:12,072 : INFO : ==> SST rel vocabulary size : 48
2017-05-06 11:00:12,072 : INFO : ==> SST tag vocabulary size : 47
2017-05-06 11:00:18,642 : INFO : _param count_
2017-05-06 11:00:18,642 : INFO : torch.Size([504, 600])
2017-05-06 11:00:18,642 : INFO : torch.Size([504, 168])
2017-05-06 11:00:18,642 : INFO : torch.Size([504])
2017-05-06 11:00:18,642 : INFO : torch.Size([504])
2017-05-06 11:00:18,642 : INFO : torch.Size([168, 168])
2017-05-06 11:00:18,643 : INFO : torch.Size([168])
2017-05-06 11:00:18,643 : INFO : torch.Size([168, 1200])
2017-05-06 11:00:18,643 : INFO : torch.Size([168])
2017-05-06 11:00:18,643 : INFO : torch.Size([504, 1200])
2017-05-06 11:00:18,643 : INFO : torch.Size([504, 168])
2017-05-06 11:00:18,643 : INFO : torch.Size([504])
2017-05-06 11:00:18,643 : INFO : torch.Size([504])
2017-05-06 11:00:18,644 : INFO : torch.Size([3, 168])
2017-05-06 11:00:18,644 : INFO : torch.Size([3])
2017-05-06 11:00:18,644 : INFO : torch.Size([21705, 300])
2017-05-06 11:00:18,644 : INFO : torch.Size([47, 300])
2017-05-06 11:00:18,644 : INFO : torch.Size([48, 300])
2017-05-06 11:00:18,644 : INFO : sum
2017-05-06 11:00:18,644 : INFO : 7849227
2017-05-06 11:00:18,644 : INFO : ____________
2017-05-06 11:02:07,476 : INFO : LOG_FILE
2017-05-06 11:02:07,476 : INFO : _________________________________start___________________________________
2017-05-06 11:02:07,483 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-06 11:02:07,694 : INFO : ==> SST vocabulary size : 21705
2017-05-06 11:02:07,694 : INFO : ==> SST rel vocabulary size : 48
2017-05-06 11:02:07,694 : INFO : ==> SST tag vocabulary size : 47
2017-05-06 11:02:14,191 : INFO : _param count_
2017-05-06 11:02:14,192 : INFO : torch.Size([504, 600])
2017-05-06 11:02:14,192 : INFO : torch.Size([504, 168])
2017-05-06 11:02:14,192 : INFO : torch.Size([504])
2017-05-06 11:02:14,192 : INFO : torch.Size([504])
2017-05-06 11:02:14,192 : INFO : torch.Size([168, 168])
2017-05-06 11:02:14,193 : INFO : torch.Size([168])
2017-05-06 11:02:14,193 : INFO : torch.Size([168, 1200])
2017-05-06 11:02:14,193 : INFO : torch.Size([168])
2017-05-06 11:02:14,193 : INFO : torch.Size([504, 1200])
2017-05-06 11:02:14,193 : INFO : torch.Size([504, 168])
2017-05-06 11:02:14,193 : INFO : torch.Size([504])
2017-05-06 11:02:14,193 : INFO : torch.Size([504])
2017-05-06 11:02:14,193 : INFO : torch.Size([3, 168])
2017-05-06 11:02:14,194 : INFO : torch.Size([3])
2017-05-06 11:02:14,194 : INFO : torch.Size([21705, 300])
2017-05-06 11:02:14,194 : INFO : torch.Size([47, 300])
2017-05-06 11:02:14,194 : INFO : torch.Size([48, 300])
2017-05-06 11:02:14,194 : INFO : sum
2017-05-06 11:02:14,194 : INFO : 7849227
2017-05-06 11:02:14,194 : INFO : ____________
2017-05-06 11:02:31,615 : INFO : LOG_FILE
2017-05-06 11:02:31,616 : INFO : _________________________________start___________________________________
2017-05-06 11:02:31,629 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-06 11:02:32,043 : INFO : ==> SST vocabulary size : 21705
2017-05-06 11:02:32,044 : INFO : ==> SST rel vocabulary size : 48
2017-05-06 11:02:32,044 : INFO : ==> SST tag vocabulary size : 47
2017-05-06 11:02:40,136 : INFO : _param count_
2017-05-06 11:02:40,140 : INFO : torch.Size([504, 600])
2017-05-06 11:02:40,140 : INFO : torch.Size([504, 168])
2017-05-06 11:02:40,141 : INFO : torch.Size([504])
2017-05-06 11:02:40,142 : INFO : torch.Size([504])
2017-05-06 11:02:40,142 : INFO : torch.Size([168, 168])
2017-05-06 11:02:40,143 : INFO : torch.Size([168])
2017-05-06 11:02:40,143 : INFO : torch.Size([168, 1200])
2017-05-06 11:02:40,144 : INFO : torch.Size([168])
2017-05-06 11:02:40,144 : INFO : torch.Size([504, 1200])
2017-05-06 11:02:40,145 : INFO : torch.Size([504, 168])
2017-05-06 11:02:40,146 : INFO : torch.Size([504])
2017-05-06 11:02:40,146 : INFO : torch.Size([504])
2017-05-06 11:02:40,147 : INFO : torch.Size([3, 168])
2017-05-06 11:02:40,147 : INFO : torch.Size([3])
2017-05-06 11:02:40,148 : INFO : torch.Size([21705, 300])
2017-05-06 11:02:40,148 : INFO : torch.Size([47, 300])
2017-05-06 11:02:40,149 : INFO : torch.Size([48, 300])
2017-05-06 11:02:40,150 : INFO : sum
2017-05-06 11:02:40,150 : INFO : 7849227
2017-05-06 11:02:40,151 : INFO : ____________
2017-05-06 11:03:50,597 : INFO : LOG_FILE
2017-05-06 11:03:50,598 : INFO : _________________________________start___________________________________
2017-05-06 11:03:50,604 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-06 11:03:50,821 : INFO : ==> SST vocabulary size : 21705
2017-05-06 11:03:50,822 : INFO : ==> SST rel vocabulary size : 48
2017-05-06 11:03:50,822 : INFO : ==> SST tag vocabulary size : 47
2017-05-06 11:03:57,371 : INFO : _param count_
2017-05-06 11:03:57,371 : INFO : torch.Size([504, 600])
2017-05-06 11:03:57,372 : INFO : torch.Size([504, 168])
2017-05-06 11:03:57,372 : INFO : torch.Size([504])
2017-05-06 11:03:57,372 : INFO : torch.Size([504])
2017-05-06 11:03:57,372 : INFO : torch.Size([168, 168])
2017-05-06 11:03:57,372 : INFO : torch.Size([168])
2017-05-06 11:03:57,372 : INFO : torch.Size([168, 1068])
2017-05-06 11:03:57,372 : INFO : torch.Size([168])
2017-05-06 11:03:57,372 : INFO : torch.Size([504, 1068])
2017-05-06 11:03:57,373 : INFO : torch.Size([504, 168])
2017-05-06 11:03:57,373 : INFO : torch.Size([504])
2017-05-06 11:03:57,373 : INFO : torch.Size([504])
2017-05-06 11:03:57,373 : INFO : torch.Size([3, 168])
2017-05-06 11:03:57,373 : INFO : torch.Size([3])
2017-05-06 11:03:57,373 : INFO : torch.Size([21705, 300])
2017-05-06 11:03:57,373 : INFO : torch.Size([47, 300])
2017-05-06 11:03:57,374 : INFO : torch.Size([48, 300])
2017-05-06 11:03:57,374 : INFO : sum
2017-05-06 11:03:57,374 : INFO : 7760523
2017-05-06 11:03:57,374 : INFO : ____________
2017-05-06 11:04:08,323 : INFO : LOG_FILE
2017-05-06 11:04:08,323 : INFO : _________________________________start___________________________________
2017-05-06 11:04:08,329 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-06 11:04:08,531 : INFO : ==> SST vocabulary size : 21705
2017-05-06 11:04:08,531 : INFO : ==> SST rel vocabulary size : 48
2017-05-06 11:04:08,531 : INFO : ==> SST tag vocabulary size : 47
2017-05-06 11:04:14,963 : INFO : _param count_
2017-05-06 11:04:14,963 : INFO : torch.Size([504, 600])
2017-05-06 11:04:14,963 : INFO : torch.Size([504, 168])
2017-05-06 11:04:14,964 : INFO : torch.Size([504])
2017-05-06 11:04:14,964 : INFO : torch.Size([504])
2017-05-06 11:04:14,964 : INFO : torch.Size([168, 168])
2017-05-06 11:04:14,964 : INFO : torch.Size([168])
2017-05-06 11:04:14,965 : INFO : torch.Size([168, 1068])
2017-05-06 11:04:14,965 : INFO : torch.Size([168])
2017-05-06 11:04:14,965 : INFO : torch.Size([504, 1068])
2017-05-06 11:04:14,965 : INFO : torch.Size([504, 168])
2017-05-06 11:04:14,965 : INFO : torch.Size([504])
2017-05-06 11:04:14,966 : INFO : torch.Size([504])
2017-05-06 11:04:14,966 : INFO : torch.Size([3, 168])
2017-05-06 11:04:14,966 : INFO : torch.Size([3])
2017-05-06 11:04:14,966 : INFO : torch.Size([21705, 300])
2017-05-06 11:04:14,966 : INFO : torch.Size([47, 300])
2017-05-06 11:04:14,967 : INFO : torch.Size([48, 300])
2017-05-06 11:04:14,967 : INFO : sum
2017-05-06 11:04:14,967 : INFO : 7760523
2017-05-06 11:04:14,967 : INFO : ____________
2017-05-06 11:12:06,821 : INFO : ==> Train loss   : 0.000064
2017-05-06 11:12:06,822 : INFO : Epoch
2017-05-06 11:12:06,822 : INFO : 67
2017-05-06 11:12:06,822 : INFO : train percentage
2017-05-06 11:12:06,822 : INFO : 1.0
2017-05-06 11:12:06,822 : INFO : Epoch
2017-05-06 11:12:06,822 : INFO : 67
2017-05-06 11:12:06,822 : INFO : dev percentage
2017-05-06 11:12:06,822 : INFO : 0.779816513761
2017-05-06 11:12:06,823 : INFO : Epoch
2017-05-06 11:12:06,823 : INFO : 67
2017-05-06 11:12:06,823 : INFO : test percentage
2017-05-06 11:12:06,823 : INFO : 0.780340472268
2017-05-06 11:29:27,866 : INFO : ==> Train loss   : 0.000065
2017-05-06 11:29:27,866 : INFO : Epoch
2017-05-06 11:29:27,866 : INFO : 68
2017-05-06 11:29:27,866 : INFO : train percentage
2017-05-06 11:29:27,866 : INFO : 1.0
2017-05-06 11:29:27,866 : INFO : Epoch
2017-05-06 11:29:27,866 : INFO : 68
2017-05-06 11:29:27,867 : INFO : dev percentage
2017-05-06 11:29:27,867 : INFO : 0.782110091743
2017-05-06 11:29:27,867 : INFO : Epoch
2017-05-06 11:29:27,867 : INFO : 68
2017-05-06 11:29:27,867 : INFO : test percentage
2017-05-06 11:29:27,867 : INFO : 0.784184514003
2017-05-06 11:46:51,100 : INFO : ==> Train loss   : 0.000095
2017-05-06 11:46:51,101 : INFO : Epoch
2017-05-06 11:46:51,101 : INFO : 69
2017-05-06 11:46:51,101 : INFO : train percentage
2017-05-06 11:46:51,101 : INFO : 1.0
2017-05-06 11:46:51,101 : INFO : Epoch
2017-05-06 11:46:51,101 : INFO : 69
2017-05-06 11:46:51,101 : INFO : dev percentage
2017-05-06 11:46:51,101 : INFO : 0.77752293578
2017-05-06 11:46:51,102 : INFO : Epoch
2017-05-06 11:46:51,102 : INFO : 69
2017-05-06 11:46:51,102 : INFO : test percentage
2017-05-06 11:46:51,102 : INFO : 0.780340472268
2017-05-06 12:04:10,807 : INFO : ==> Train loss   : 0.000045
2017-05-06 12:04:10,807 : INFO : Epoch
2017-05-06 12:04:10,807 : INFO : 70
2017-05-06 12:04:10,807 : INFO : train percentage
2017-05-06 12:04:10,807 : INFO : 1.0
2017-05-06 12:04:10,807 : INFO : Epoch
2017-05-06 12:04:10,807 : INFO : 70
2017-05-06 12:04:10,808 : INFO : dev percentage
2017-05-06 12:04:10,808 : INFO : 0.77752293578
2017-05-06 12:04:10,808 : INFO : Epoch
2017-05-06 12:04:10,808 : INFO : 70
2017-05-06 12:04:10,808 : INFO : test percentage
2017-05-06 12:04:10,808 : INFO : 0.7869302581
2017-05-06 12:21:25,301 : INFO : ==> Train loss   : 0.001595
2017-05-06 12:21:25,301 : INFO : Epoch
2017-05-06 12:21:25,301 : INFO : 71
2017-05-06 12:21:25,301 : INFO : train percentage
2017-05-06 12:21:25,301 : INFO : 0.999855491329
2017-05-06 12:21:25,301 : INFO : Epoch
2017-05-06 12:21:25,302 : INFO : 71
2017-05-06 12:21:25,302 : INFO : dev percentage
2017-05-06 12:21:25,302 : INFO : 0.771788990826
2017-05-06 12:21:25,302 : INFO : Epoch
2017-05-06 12:21:25,302 : INFO : 71
2017-05-06 12:21:25,302 : INFO : test percentage
2017-05-06 12:21:25,302 : INFO : 0.780340472268
2017-05-06 12:38:42,393 : INFO : ==> Train loss   : 0.011244
2017-05-06 12:38:42,393 : INFO : Epoch
2017-05-06 12:38:42,394 : INFO : 72
2017-05-06 12:38:42,394 : INFO : train percentage
2017-05-06 12:38:42,394 : INFO : 0.99725433526
2017-05-06 12:38:42,394 : INFO : Epoch
2017-05-06 12:38:42,394 : INFO : 72
2017-05-06 12:38:42,394 : INFO : dev percentage
2017-05-06 12:38:42,394 : INFO : 0.761467889908
2017-05-06 12:38:42,395 : INFO : Epoch
2017-05-06 12:38:42,395 : INFO : 72
2017-05-06 12:38:42,395 : INFO : test percentage
2017-05-06 12:38:42,395 : INFO : 0.780889621087
2017-05-06 12:55:59,763 : INFO : ==> Train loss   : 0.000827
2017-05-06 12:55:59,764 : INFO : Epoch
2017-05-06 12:55:59,764 : INFO : 73
2017-05-06 12:55:59,764 : INFO : train percentage
2017-05-06 12:55:59,764 : INFO : 0.999855491329
2017-05-06 12:55:59,764 : INFO : Epoch
2017-05-06 12:55:59,764 : INFO : 73
2017-05-06 12:55:59,764 : INFO : dev percentage
2017-05-06 12:55:59,764 : INFO : 0.77752293578
2017-05-06 12:55:59,765 : INFO : Epoch
2017-05-06 12:55:59,765 : INFO : 73
2017-05-06 12:55:59,765 : INFO : test percentage
2017-05-06 12:55:59,765 : INFO : 0.785282811642
2017-05-06 13:13:18,858 : INFO : ==> Train loss   : 0.000027
2017-05-06 13:13:18,858 : INFO : Epoch
2017-05-06 13:13:18,858 : INFO : 74
2017-05-06 13:13:18,858 : INFO : train percentage
2017-05-06 13:13:18,859 : INFO : 1.0
2017-05-06 13:13:18,859 : INFO : Epoch
2017-05-06 13:13:18,859 : INFO : 74
2017-05-06 13:13:18,859 : INFO : dev percentage
2017-05-06 13:13:18,859 : INFO : 0.782110091743
2017-05-06 13:13:18,859 : INFO : Epoch
2017-05-06 13:13:18,859 : INFO : 74
2017-05-06 13:13:18,859 : INFO : test percentage
2017-05-06 13:13:18,860 : INFO : 0.782537067545
2017-05-06 13:30:38,726 : INFO : ==> Train loss   : 0.000032
2017-05-06 13:30:38,726 : INFO : Epoch
2017-05-06 13:30:38,726 : INFO : 75
2017-05-06 13:30:38,727 : INFO : train percentage
2017-05-06 13:30:38,727 : INFO : 1.0
2017-05-06 13:30:38,727 : INFO : Epoch
2017-05-06 13:30:38,727 : INFO : 75
2017-05-06 13:30:38,727 : INFO : dev percentage
2017-05-06 13:30:38,727 : INFO : 0.782110091743
2017-05-06 13:30:38,727 : INFO : Epoch
2017-05-06 13:30:38,727 : INFO : 75
2017-05-06 13:30:38,727 : INFO : test percentage
2017-05-06 13:30:38,728 : INFO : 0.781438769907
2017-05-06 13:44:08,493 : INFO : LOG_FILE
2017-05-06 13:44:08,493 : INFO : _________________________________start___________________________________
2017-05-06 13:44:08,499 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-06 13:44:08,700 : INFO : ==> SST vocabulary size : 21705
2017-05-06 13:44:08,700 : INFO : ==> SST rel vocabulary size : 48
2017-05-06 13:44:08,700 : INFO : ==> SST tag vocabulary size : 47
2017-05-06 13:44:15,222 : INFO : _param count_
2017-05-06 13:44:15,222 : INFO : torch.Size([504, 600])
2017-05-06 13:44:15,223 : INFO : torch.Size([504, 168])
2017-05-06 13:44:15,223 : INFO : torch.Size([504])
2017-05-06 13:44:15,223 : INFO : torch.Size([504])
2017-05-06 13:44:15,223 : INFO : torch.Size([168, 168])
2017-05-06 13:44:15,223 : INFO : torch.Size([168])
2017-05-06 13:44:15,223 : INFO : torch.Size([168, 1068])
2017-05-06 13:44:15,224 : INFO : torch.Size([168])
2017-05-06 13:44:15,224 : INFO : torch.Size([504, 1068])
2017-05-06 13:44:15,224 : INFO : torch.Size([504, 168])
2017-05-06 13:44:15,224 : INFO : torch.Size([504])
2017-05-06 13:44:15,224 : INFO : torch.Size([504])
2017-05-06 13:44:15,224 : INFO : torch.Size([3, 168])
2017-05-06 13:44:15,224 : INFO : torch.Size([3])
2017-05-06 13:44:15,225 : INFO : torch.Size([21705, 300])
2017-05-06 13:44:15,225 : INFO : torch.Size([47, 300])
2017-05-06 13:44:15,225 : INFO : torch.Size([48, 300])
2017-05-06 13:44:15,225 : INFO : sum
2017-05-06 13:44:15,225 : INFO : 7760523
2017-05-06 13:44:15,225 : INFO : ____________
2017-05-06 13:46:44,682 : INFO : LOG_FILE
2017-05-06 13:46:44,683 : INFO : _________________________________start___________________________________
2017-05-06 13:46:44,689 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-06 13:46:44,895 : INFO : ==> SST vocabulary size : 21705
2017-05-06 13:46:44,895 : INFO : ==> SST rel vocabulary size : 48
2017-05-06 13:46:44,895 : INFO : ==> SST tag vocabulary size : 47
2017-05-06 13:47:18,141 : INFO : LOG_FILE
2017-05-06 13:47:18,141 : INFO : _________________________________start___________________________________
2017-05-06 13:47:18,148 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-06 13:47:18,358 : INFO : ==> SST vocabulary size : 21705
2017-05-06 13:47:18,358 : INFO : ==> SST rel vocabulary size : 48
2017-05-06 13:47:18,359 : INFO : ==> SST tag vocabulary size : 47
2017-05-06 13:47:24,796 : INFO : _param count_
2017-05-06 13:47:24,796 : INFO : torch.Size([504, 600])
2017-05-06 13:47:24,797 : INFO : torch.Size([504, 168])
2017-05-06 13:47:24,797 : INFO : torch.Size([504])
2017-05-06 13:47:24,797 : INFO : torch.Size([504])
2017-05-06 13:47:24,797 : INFO : torch.Size([168, 168])
2017-05-06 13:47:24,797 : INFO : torch.Size([168])
2017-05-06 13:47:24,797 : INFO : torch.Size([168, 1068])
2017-05-06 13:47:24,797 : INFO : torch.Size([168])
2017-05-06 13:47:24,797 : INFO : torch.Size([504, 1068])
2017-05-06 13:47:24,798 : INFO : torch.Size([504, 168])
2017-05-06 13:47:24,798 : INFO : torch.Size([504])
2017-05-06 13:47:24,798 : INFO : torch.Size([504])
2017-05-06 13:47:24,798 : INFO : torch.Size([3, 168])
2017-05-06 13:47:24,798 : INFO : torch.Size([3])
2017-05-06 13:47:24,798 : INFO : torch.Size([21705, 300])
2017-05-06 13:47:24,798 : INFO : torch.Size([47, 300])
2017-05-06 13:47:24,799 : INFO : torch.Size([48, 300])
2017-05-06 13:47:24,799 : INFO : sum
2017-05-06 13:47:24,799 : INFO : 7760523
2017-05-06 13:47:24,799 : INFO : ____________
2017-05-06 13:48:29,616 : INFO : ==> Train loss   : 0.000025
2017-05-06 13:48:29,616 : INFO : Epoch
2017-05-06 13:48:29,616 : INFO : 76
2017-05-06 13:48:29,616 : INFO : train percentage
2017-05-06 13:48:29,616 : INFO : 1.0
2017-05-06 13:48:29,616 : INFO : Epoch
2017-05-06 13:48:29,617 : INFO : 76
2017-05-06 13:48:29,617 : INFO : dev percentage
2017-05-06 13:48:29,617 : INFO : 0.779816513761
2017-05-06 13:48:29,617 : INFO : Epoch
2017-05-06 13:48:29,617 : INFO : 76
2017-05-06 13:48:29,617 : INFO : test percentage
2017-05-06 13:48:29,617 : INFO : 0.783635365184
2017-05-06 13:49:06,666 : INFO : LOG_FILE
2017-05-06 13:49:06,666 : INFO : _________________________________start___________________________________
2017-05-06 13:49:06,673 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-06 13:49:06,883 : INFO : ==> SST vocabulary size : 21705
2017-05-06 13:49:06,883 : INFO : ==> SST rel vocabulary size : 48
2017-05-06 13:49:06,883 : INFO : ==> SST tag vocabulary size : 47
2017-05-06 13:49:13,599 : INFO : _param count_
2017-05-06 13:49:13,599 : INFO : torch.Size([504, 600])
2017-05-06 13:49:13,599 : INFO : torch.Size([504, 168])
2017-05-06 13:49:13,600 : INFO : torch.Size([504])
2017-05-06 13:49:13,600 : INFO : torch.Size([504])
2017-05-06 13:49:13,600 : INFO : torch.Size([168, 168])
2017-05-06 13:49:13,600 : INFO : torch.Size([168])
2017-05-06 13:49:13,600 : INFO : torch.Size([168, 1068])
2017-05-06 13:49:13,601 : INFO : torch.Size([168])
2017-05-06 13:49:13,601 : INFO : torch.Size([504, 1068])
2017-05-06 13:49:13,601 : INFO : torch.Size([504, 168])
2017-05-06 13:49:13,601 : INFO : torch.Size([504])
2017-05-06 13:49:13,601 : INFO : torch.Size([504])
2017-05-06 13:49:13,601 : INFO : torch.Size([3, 168])
2017-05-06 13:49:13,602 : INFO : torch.Size([3])
2017-05-06 13:49:13,602 : INFO : torch.Size([21705, 300])
2017-05-06 13:49:13,602 : INFO : torch.Size([47, 300])
2017-05-06 13:49:13,602 : INFO : torch.Size([48, 300])
2017-05-06 13:49:13,602 : INFO : sum
2017-05-06 13:49:13,602 : INFO : 7760523
2017-05-06 13:49:13,603 : INFO : ____________
2017-05-06 13:53:04,897 : INFO : ==> Train loss   : 13.575249
2017-05-06 13:53:04,897 : INFO : Epoch
2017-05-06 13:53:04,897 : INFO : 0
2017-05-06 13:53:04,897 : INFO : dev percentage
2017-05-06 13:53:04,897 : INFO : 0.509174311927
2017-05-06 13:53:04,898 : INFO : Epoch
2017-05-06 13:53:04,898 : INFO : 0
2017-05-06 13:53:04,898 : INFO : test percentage
2017-05-06 13:53:04,898 : INFO : 0.499176276771
2017-05-06 13:57:02,089 : INFO : ==> Train loss   : 11.738976
2017-05-06 13:57:02,090 : INFO : Epoch
2017-05-06 13:57:02,090 : INFO : 1
2017-05-06 13:57:02,090 : INFO : dev percentage
2017-05-06 13:57:02,090 : INFO : 0.509174311927
2017-05-06 13:57:02,090 : INFO : Epoch
2017-05-06 13:57:02,090 : INFO : 1
2017-05-06 13:57:02,090 : INFO : test percentage
2017-05-06 13:57:02,090 : INFO : 0.499176276771
2017-05-06 14:00:44,346 : INFO : ==> Train loss   : 11.457429
2017-05-06 14:00:44,346 : INFO : Epoch
2017-05-06 14:00:44,346 : INFO : 2
2017-05-06 14:00:44,346 : INFO : dev percentage
2017-05-06 14:00:44,346 : INFO : 0.509174311927
2017-05-06 14:00:44,346 : INFO : Epoch
2017-05-06 14:00:44,346 : INFO : 2
2017-05-06 14:00:44,347 : INFO : test percentage
2017-05-06 14:00:44,347 : INFO : 0.499176276771
2017-05-06 14:02:33,328 : INFO : LOG_FILE
2017-05-06 14:02:33,328 : INFO : _________________________________start___________________________________
2017-05-06 14:02:33,335 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-06 14:02:33,545 : INFO : ==> SST vocabulary size : 21705
2017-05-06 14:02:33,545 : INFO : ==> SST rel vocabulary size : 48
2017-05-06 14:02:33,545 : INFO : ==> SST tag vocabulary size : 47
2017-05-06 14:02:48,581 : INFO : _param count_
2017-05-06 14:02:48,581 : INFO : torch.Size([504, 600])
2017-05-06 14:02:48,581 : INFO : torch.Size([504, 168])
2017-05-06 14:02:48,581 : INFO : torch.Size([504])
2017-05-06 14:02:48,581 : INFO : torch.Size([504])
2017-05-06 14:02:48,582 : INFO : torch.Size([168, 168])
2017-05-06 14:02:48,582 : INFO : torch.Size([168])
2017-05-06 14:02:48,582 : INFO : torch.Size([168, 1068])
2017-05-06 14:02:48,582 : INFO : torch.Size([168])
2017-05-06 14:02:48,582 : INFO : torch.Size([504, 1068])
2017-05-06 14:02:48,582 : INFO : torch.Size([504, 168])
2017-05-06 14:02:48,582 : INFO : torch.Size([504])
2017-05-06 14:02:48,582 : INFO : torch.Size([504])
2017-05-06 14:02:48,583 : INFO : torch.Size([3, 168])
2017-05-06 14:02:48,583 : INFO : torch.Size([3])
2017-05-06 14:02:48,583 : INFO : torch.Size([21705, 300])
2017-05-06 14:02:48,583 : INFO : torch.Size([47, 300])
2017-05-06 14:02:48,583 : INFO : torch.Size([48, 300])
2017-05-06 14:02:48,583 : INFO : sum
2017-05-06 14:02:48,583 : INFO : 7760523
2017-05-06 14:02:48,583 : INFO : ____________
2017-05-06 14:02:48,584 : INFO : ==> File found, loading to memory
2017-05-06 14:02:52,857 : INFO : ==> GLOVE vocabulary size: 2196016
2017-05-06 14:02:53,509 : INFO : done creating emb, quit
2017-05-06 14:02:53,509 : INFO : quit program due to memory leak during preprocess data, please rerun sentiment.py
2017-05-06 14:04:28,840 : INFO : LOG_FILE
2017-05-06 14:04:28,840 : INFO : _________________________________start___________________________________
2017-05-06 14:04:28,846 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-06 14:04:29,042 : INFO : ==> SST vocabulary size : 21705
2017-05-06 14:04:29,043 : INFO : ==> SST rel vocabulary size : 48
2017-05-06 14:04:29,043 : INFO : ==> SST tag vocabulary size : 47
2017-05-06 14:04:35,611 : INFO : _param count_
2017-05-06 14:04:35,611 : INFO : torch.Size([168, 300])
2017-05-06 14:04:35,611 : INFO : torch.Size([168])
2017-05-06 14:04:35,611 : INFO : torch.Size([168, 168])
2017-05-06 14:04:35,612 : INFO : torch.Size([168])
2017-05-06 14:04:35,612 : INFO : torch.Size([168, 300])
2017-05-06 14:04:35,612 : INFO : torch.Size([168])
2017-05-06 14:04:35,612 : INFO : torch.Size([168, 168])
2017-05-06 14:04:35,612 : INFO : torch.Size([168])
2017-05-06 14:04:35,613 : INFO : torch.Size([168, 300])
2017-05-06 14:04:35,613 : INFO : torch.Size([168])
2017-05-06 14:04:35,613 : INFO : torch.Size([168, 168])
2017-05-06 14:04:35,613 : INFO : torch.Size([168])
2017-05-06 14:04:35,613 : INFO : torch.Size([168, 300])
2017-05-06 14:04:35,614 : INFO : torch.Size([168])
2017-05-06 14:04:35,614 : INFO : torch.Size([168, 168])
2017-05-06 14:04:35,614 : INFO : torch.Size([168])
2017-05-06 14:04:35,614 : INFO : torch.Size([3, 168])
2017-05-06 14:04:35,614 : INFO : torch.Size([3])
2017-05-06 14:04:35,614 : INFO : torch.Size([21705, 300])
2017-05-06 14:04:35,614 : INFO : torch.Size([47, 300])
2017-05-06 14:04:35,615 : INFO : torch.Size([48, 300])
2017-05-06 14:04:35,615 : INFO : sum
2017-05-06 14:04:35,615 : INFO : 6856347
2017-05-06 14:04:35,615 : INFO : ____________
2017-05-06 14:04:59,479 : INFO : LOG_FILE
2017-05-06 14:04:59,480 : INFO : _________________________________start___________________________________
2017-05-06 14:04:59,486 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-06 14:04:59,695 : INFO : ==> SST vocabulary size : 21705
2017-05-06 14:04:59,695 : INFO : ==> SST rel vocabulary size : 48
2017-05-06 14:04:59,695 : INFO : ==> SST tag vocabulary size : 47
2017-05-06 14:05:06,272 : INFO : _param count_
2017-05-06 14:05:06,272 : INFO : torch.Size([168, 300])
2017-05-06 14:05:06,272 : INFO : torch.Size([168])
2017-05-06 14:05:06,272 : INFO : torch.Size([168, 168])
2017-05-06 14:05:06,273 : INFO : torch.Size([168])
2017-05-06 14:05:06,273 : INFO : torch.Size([168, 300])
2017-05-06 14:05:06,273 : INFO : torch.Size([168])
2017-05-06 14:05:06,273 : INFO : torch.Size([168, 168])
2017-05-06 14:05:06,273 : INFO : torch.Size([168])
2017-05-06 14:05:06,273 : INFO : torch.Size([168, 300])
2017-05-06 14:05:06,273 : INFO : torch.Size([168])
2017-05-06 14:05:06,273 : INFO : torch.Size([168, 168])
2017-05-06 14:05:06,274 : INFO : torch.Size([168])
2017-05-06 14:05:06,274 : INFO : torch.Size([168, 300])
2017-05-06 14:05:06,274 : INFO : torch.Size([168])
2017-05-06 14:05:06,274 : INFO : torch.Size([168, 168])
2017-05-06 14:05:06,274 : INFO : torch.Size([168])
2017-05-06 14:05:06,274 : INFO : torch.Size([3, 168])
2017-05-06 14:05:06,274 : INFO : torch.Size([3])
2017-05-06 14:05:06,275 : INFO : torch.Size([21705, 300])
2017-05-06 14:05:06,275 : INFO : torch.Size([47, 300])
2017-05-06 14:05:06,275 : INFO : torch.Size([48, 300])
2017-05-06 14:05:06,275 : INFO : sum
2017-05-06 14:05:06,275 : INFO : 6856347
2017-05-06 14:05:06,275 : INFO : ____________
2017-05-06 14:07:27,905 : INFO : ==> Train loss   : 0.000029
2017-05-06 14:07:27,905 : INFO : Epoch
2017-05-06 14:07:27,905 : INFO : 77
2017-05-06 14:07:27,906 : INFO : train percentage
2017-05-06 14:07:27,906 : INFO : 1.0
2017-05-06 14:07:27,906 : INFO : Epoch
2017-05-06 14:07:27,906 : INFO : 77
2017-05-06 14:07:27,906 : INFO : dev percentage
2017-05-06 14:07:27,906 : INFO : 0.782110091743
2017-05-06 14:07:27,906 : INFO : Epoch
2017-05-06 14:07:27,907 : INFO : 77
2017-05-06 14:07:27,907 : INFO : test percentage
2017-05-06 14:07:27,907 : INFO : 0.7869302581
2017-05-06 14:08:27,033 : INFO : ==> Train loss   : 14.684663
2017-05-06 14:08:27,033 : INFO : Epoch
2017-05-06 14:08:27,034 : INFO : 0
2017-05-06 14:08:27,034 : INFO : dev percentage
2017-05-06 14:08:27,034 : INFO : 0.911697247706
2017-05-06 14:08:27,034 : INFO : Epoch
2017-05-06 14:08:27,034 : INFO : 0
2017-05-06 14:08:27,034 : INFO : test percentage
2017-05-06 14:08:27,034 : INFO : 0.766611751785
2017-05-06 14:11:48,673 : INFO : ==> Train loss   : 8.204493
2017-05-06 14:11:48,673 : INFO : Epoch
2017-05-06 14:11:48,673 : INFO : 1
2017-05-06 14:11:48,673 : INFO : dev percentage
2017-05-06 14:11:48,673 : INFO : 0.971330275229
2017-05-06 14:11:48,673 : INFO : Epoch
2017-05-06 14:11:48,674 : INFO : 1
2017-05-06 14:11:48,674 : INFO : test percentage
2017-05-06 14:11:48,674 : INFO : 0.799011532125
2017-05-06 14:16:01,231 : INFO : LOG_FILE
2017-05-06 14:16:01,231 : INFO : _________________________________start___________________________________
2017-05-06 14:16:01,258 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-06 14:16:01,481 : INFO : ==> SST vocabulary size : 21705
2017-05-06 14:16:01,482 : INFO : ==> SST rel vocabulary size : 48
2017-05-06 14:16:01,482 : INFO : ==> SST tag vocabulary size : 47
2017-05-06 14:16:07,948 : INFO : _param count_
2017-05-06 14:16:07,948 : INFO : torch.Size([504, 600])
2017-05-06 14:16:07,948 : INFO : torch.Size([504, 168])
2017-05-06 14:16:07,948 : INFO : torch.Size([504])
2017-05-06 14:16:07,948 : INFO : torch.Size([504])
2017-05-06 14:16:07,948 : INFO : torch.Size([168, 168])
2017-05-06 14:16:07,949 : INFO : torch.Size([168])
2017-05-06 14:16:07,949 : INFO : torch.Size([168, 1068])
2017-05-06 14:16:07,949 : INFO : torch.Size([168])
2017-05-06 14:16:07,949 : INFO : torch.Size([504, 1068])
2017-05-06 14:16:07,949 : INFO : torch.Size([504, 168])
2017-05-06 14:16:07,949 : INFO : torch.Size([504])
2017-05-06 14:16:07,950 : INFO : torch.Size([504])
2017-05-06 14:16:07,950 : INFO : torch.Size([3, 168])
2017-05-06 14:16:07,950 : INFO : torch.Size([3])
2017-05-06 14:16:07,950 : INFO : torch.Size([21705, 300])
2017-05-06 14:16:07,950 : INFO : torch.Size([47, 300])
2017-05-06 14:16:07,950 : INFO : torch.Size([48, 300])
2017-05-06 14:16:07,950 : INFO : sum
2017-05-06 14:16:07,951 : INFO : 7760523
2017-05-06 14:16:07,951 : INFO : ____________
2017-05-06 14:16:51,926 : INFO : LOG_FILE
2017-05-06 14:16:51,927 : INFO : _________________________________start___________________________________
2017-05-06 14:16:51,941 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-06 14:16:52,358 : INFO : ==> SST vocabulary size : 21705
2017-05-06 14:16:52,359 : INFO : ==> SST rel vocabulary size : 48
2017-05-06 14:16:52,360 : INFO : ==> SST tag vocabulary size : 47
2017-05-06 14:17:00,254 : INFO : _param count_
2017-05-06 14:17:00,257 : INFO : torch.Size([504, 600])
2017-05-06 14:17:00,257 : INFO : torch.Size([504, 168])
2017-05-06 14:17:00,258 : INFO : torch.Size([504])
2017-05-06 14:17:00,259 : INFO : torch.Size([504])
2017-05-06 14:17:00,259 : INFO : torch.Size([168, 168])
2017-05-06 14:17:00,260 : INFO : torch.Size([168])
2017-05-06 14:17:00,260 : INFO : torch.Size([168, 1068])
2017-05-06 14:17:00,261 : INFO : torch.Size([168])
2017-05-06 14:17:00,261 : INFO : torch.Size([504, 1068])
2017-05-06 14:17:00,262 : INFO : torch.Size([504, 168])
2017-05-06 14:17:00,262 : INFO : torch.Size([504])
2017-05-06 14:17:00,263 : INFO : torch.Size([504])
2017-05-06 14:17:00,264 : INFO : torch.Size([3, 168])
2017-05-06 14:17:00,264 : INFO : torch.Size([3])
2017-05-06 14:17:00,265 : INFO : torch.Size([21705, 300])
2017-05-06 14:17:00,265 : INFO : torch.Size([47, 300])
2017-05-06 14:17:00,266 : INFO : torch.Size([48, 300])
2017-05-06 14:17:00,266 : INFO : sum
2017-05-06 14:17:00,267 : INFO : 7760523
2017-05-06 14:17:00,267 : INFO : ____________
2017-05-06 14:19:31,797 : INFO : ==> Train loss   : 13.338270
2017-05-06 14:19:31,797 : INFO : Epoch
2017-05-06 14:19:31,798 : INFO : 0
2017-05-06 14:19:31,798 : INFO : dev percentage
2017-05-06 14:19:31,798 : INFO : 0.509174311927
2017-05-06 14:19:31,798 : INFO : Epoch
2017-05-06 14:19:31,798 : INFO : 0
2017-05-06 14:19:31,798 : INFO : test percentage
2017-05-06 14:19:31,798 : INFO : 0.499176276771
2017-05-06 14:22:56,020 : INFO : ==> Train loss   : 11.484866
2017-05-06 14:22:56,021 : INFO : Epoch
2017-05-06 14:22:56,021 : INFO : 1
2017-05-06 14:22:56,021 : INFO : dev percentage
2017-05-06 14:22:56,021 : INFO : 0.509174311927
2017-05-06 14:22:56,021 : INFO : Epoch
2017-05-06 14:22:56,021 : INFO : 1
2017-05-06 14:22:56,022 : INFO : test percentage
2017-05-06 14:22:56,022 : INFO : 0.499176276771
2017-05-06 14:26:21,192 : INFO : ==> Train loss   : 11.171860
2017-05-06 14:26:21,192 : INFO : Epoch
2017-05-06 14:26:21,192 : INFO : 2
2017-05-06 14:26:21,192 : INFO : dev percentage
2017-05-06 14:26:21,193 : INFO : 0.509174311927
2017-05-06 14:26:21,193 : INFO : Epoch
2017-05-06 14:26:21,193 : INFO : 2
2017-05-06 14:26:21,193 : INFO : test percentage
2017-05-06 14:26:21,193 : INFO : 0.499176276771
2017-05-06 14:29:38,809 : INFO : LOG_FILE
2017-05-06 14:29:38,809 : INFO : _________________________________start___________________________________
2017-05-06 14:29:38,816 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-06 14:29:39,029 : INFO : ==> SST vocabulary size : 21705
2017-05-06 14:29:39,029 : INFO : ==> SST rel vocabulary size : 48
2017-05-06 14:29:39,029 : INFO : ==> SST tag vocabulary size : 47
2017-05-06 14:29:45,444 : INFO : _param count_
2017-05-06 14:29:45,444 : INFO : torch.Size([504, 600])
2017-05-06 14:29:45,445 : INFO : torch.Size([504, 168])
2017-05-06 14:29:45,445 : INFO : torch.Size([504])
2017-05-06 14:29:45,445 : INFO : torch.Size([504])
2017-05-06 14:29:45,445 : INFO : torch.Size([168, 168])
2017-05-06 14:29:45,445 : INFO : torch.Size([168])
2017-05-06 14:29:45,445 : INFO : torch.Size([168, 1068])
2017-05-06 14:29:45,445 : INFO : torch.Size([168])
2017-05-06 14:29:45,446 : INFO : torch.Size([504, 1068])
2017-05-06 14:29:45,446 : INFO : torch.Size([504, 168])
2017-05-06 14:29:45,446 : INFO : torch.Size([504])
2017-05-06 14:29:45,446 : INFO : torch.Size([504])
2017-05-06 14:29:45,446 : INFO : torch.Size([3, 168])
2017-05-06 14:29:45,446 : INFO : torch.Size([3])
2017-05-06 14:29:45,446 : INFO : torch.Size([21705, 300])
2017-05-06 14:29:45,447 : INFO : torch.Size([47, 300])
2017-05-06 14:29:45,447 : INFO : torch.Size([48, 300])
2017-05-06 14:29:45,447 : INFO : sum
2017-05-06 14:29:45,447 : INFO : 7760523
2017-05-06 14:29:45,447 : INFO : ____________
2017-05-06 14:29:46,337 : INFO : ==> Train loss   : 10.720213
2017-05-06 14:29:46,337 : INFO : Epoch
2017-05-06 14:29:46,337 : INFO : 3
2017-05-06 14:29:46,337 : INFO : dev percentage
2017-05-06 14:29:46,338 : INFO : 0.509174311927
2017-05-06 14:29:46,338 : INFO : Epoch
2017-05-06 14:29:46,338 : INFO : 3
2017-05-06 14:29:46,338 : INFO : test percentage
2017-05-06 14:29:46,338 : INFO : 0.499176276771
2017-05-06 14:29:58,465 : INFO : LOG_FILE
2017-05-06 14:29:58,465 : INFO : _________________________________start___________________________________
2017-05-06 14:29:58,492 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-06 14:29:58,705 : INFO : ==> SST vocabulary size : 21705
2017-05-06 14:29:58,706 : INFO : ==> SST rel vocabulary size : 48
2017-05-06 14:29:58,706 : INFO : ==> SST tag vocabulary size : 47
2017-05-06 14:30:05,123 : INFO : _param count_
2017-05-06 14:30:05,123 : INFO : torch.Size([504, 600])
2017-05-06 14:30:05,123 : INFO : torch.Size([504, 168])
2017-05-06 14:30:05,124 : INFO : torch.Size([504])
2017-05-06 14:30:05,124 : INFO : torch.Size([504])
2017-05-06 14:30:05,124 : INFO : torch.Size([168, 168])
2017-05-06 14:30:05,124 : INFO : torch.Size([168])
2017-05-06 14:30:05,124 : INFO : torch.Size([168, 1068])
2017-05-06 14:30:05,124 : INFO : torch.Size([168])
2017-05-06 14:30:05,124 : INFO : torch.Size([504, 1068])
2017-05-06 14:30:05,125 : INFO : torch.Size([504, 168])
2017-05-06 14:30:05,125 : INFO : torch.Size([504])
2017-05-06 14:30:05,125 : INFO : torch.Size([504])
2017-05-06 14:30:05,125 : INFO : torch.Size([3, 168])
2017-05-06 14:30:05,125 : INFO : torch.Size([3])
2017-05-06 14:30:05,125 : INFO : torch.Size([21705, 300])
2017-05-06 14:30:05,126 : INFO : torch.Size([47, 300])
2017-05-06 14:30:05,126 : INFO : torch.Size([48, 300])
2017-05-06 14:30:05,126 : INFO : sum
2017-05-06 14:30:05,126 : INFO : 7760523
2017-05-06 14:30:05,126 : INFO : ____________
2017-05-06 14:31:08,855 : INFO : LOG_FILE
2017-05-06 14:31:08,856 : INFO : _________________________________start___________________________________
2017-05-06 14:31:08,869 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-06 14:31:09,305 : INFO : ==> SST vocabulary size : 21705
2017-05-06 14:31:09,305 : INFO : ==> SST rel vocabulary size : 48
2017-05-06 14:31:09,306 : INFO : ==> SST tag vocabulary size : 47
2017-05-06 14:31:17,166 : INFO : _param count_
2017-05-06 14:31:17,169 : INFO : torch.Size([504, 600])
2017-05-06 14:31:17,169 : INFO : torch.Size([504, 168])
2017-05-06 14:31:17,170 : INFO : torch.Size([504])
2017-05-06 14:31:17,170 : INFO : torch.Size([504])
2017-05-06 14:31:17,171 : INFO : torch.Size([168, 168])
2017-05-06 14:31:17,172 : INFO : torch.Size([168])
2017-05-06 14:31:17,172 : INFO : torch.Size([168, 1068])
2017-05-06 14:31:17,173 : INFO : torch.Size([168])
2017-05-06 14:31:17,173 : INFO : torch.Size([504, 1068])
2017-05-06 14:31:17,174 : INFO : torch.Size([504, 168])
2017-05-06 14:31:17,174 : INFO : torch.Size([504])
2017-05-06 14:31:17,175 : INFO : torch.Size([504])
2017-05-06 14:31:17,175 : INFO : torch.Size([3, 168])
2017-05-06 14:31:17,176 : INFO : torch.Size([3])
2017-05-06 14:31:17,177 : INFO : torch.Size([21705, 300])
2017-05-06 14:31:17,177 : INFO : torch.Size([47, 300])
2017-05-06 14:31:17,178 : INFO : torch.Size([48, 300])
2017-05-06 14:31:17,178 : INFO : sum
2017-05-06 14:31:17,179 : INFO : 7760523
2017-05-06 14:31:17,179 : INFO : ____________
2017-05-06 14:31:59,986 : INFO : LOG_FILE
2017-05-06 14:31:59,987 : INFO : _________________________________start___________________________________
2017-05-06 14:31:59,999 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-06 14:32:00,388 : INFO : ==> SST vocabulary size : 21705
2017-05-06 14:32:00,389 : INFO : ==> SST rel vocabulary size : 48
2017-05-06 14:32:00,389 : INFO : ==> SST tag vocabulary size : 47
2017-05-06 14:32:08,238 : INFO : _param count_
2017-05-06 14:32:08,241 : INFO : torch.Size([504, 600])
2017-05-06 14:32:08,242 : INFO : torch.Size([504, 168])
2017-05-06 14:32:08,242 : INFO : torch.Size([504])
2017-05-06 14:32:08,243 : INFO : torch.Size([504])
2017-05-06 14:32:08,244 : INFO : torch.Size([168, 168])
2017-05-06 14:32:08,245 : INFO : torch.Size([168])
2017-05-06 14:32:08,246 : INFO : torch.Size([168, 1068])
2017-05-06 14:32:08,247 : INFO : torch.Size([168])
2017-05-06 14:32:08,247 : INFO : torch.Size([504, 1068])
2017-05-06 14:32:08,248 : INFO : torch.Size([504, 168])
2017-05-06 14:32:08,248 : INFO : torch.Size([504])
2017-05-06 14:32:08,249 : INFO : torch.Size([504])
2017-05-06 14:32:08,249 : INFO : torch.Size([3, 168])
2017-05-06 14:32:08,250 : INFO : torch.Size([3])
2017-05-06 14:32:08,251 : INFO : torch.Size([21705, 300])
2017-05-06 14:32:08,251 : INFO : torch.Size([47, 300])
2017-05-06 14:32:08,252 : INFO : torch.Size([48, 300])
2017-05-06 14:32:08,252 : INFO : sum
2017-05-06 14:32:08,253 : INFO : 7760523
2017-05-06 14:32:08,253 : INFO : ____________
2017-05-06 14:33:36,370 : INFO : ==> Train loss   : 12.137781
2017-05-06 14:33:36,370 : INFO : Epoch
2017-05-06 14:33:36,371 : INFO : 0
2017-05-06 14:33:36,371 : INFO : dev percentage
2017-05-06 14:33:36,371 : INFO : 0.628440366972
2017-05-06 14:33:36,371 : INFO : Epoch
2017-05-06 14:33:36,371 : INFO : 0
2017-05-06 14:33:36,371 : INFO : test percentage
2017-05-06 14:33:36,371 : INFO : 0.575507962658
2017-05-06 14:35:03,676 : INFO : LOG_FILE
2017-05-06 14:35:03,677 : INFO : _________________________________start___________________________________
2017-05-06 14:35:03,690 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-06 14:35:04,107 : INFO : ==> SST vocabulary size : 21705
2017-05-06 14:35:04,108 : INFO : ==> SST rel vocabulary size : 48
2017-05-06 14:35:04,108 : INFO : ==> SST tag vocabulary size : 47
2017-05-06 14:35:12,017 : INFO : _param count_
2017-05-06 14:35:12,021 : INFO : torch.Size([504, 600])
2017-05-06 14:35:12,022 : INFO : torch.Size([504, 168])
2017-05-06 14:35:12,023 : INFO : torch.Size([504])
2017-05-06 14:35:12,024 : INFO : torch.Size([504])
2017-05-06 14:35:12,024 : INFO : torch.Size([168, 168])
2017-05-06 14:35:12,025 : INFO : torch.Size([168])
2017-05-06 14:35:12,026 : INFO : torch.Size([168, 1068])
2017-05-06 14:35:12,027 : INFO : torch.Size([168])
2017-05-06 14:35:12,028 : INFO : torch.Size([504, 1068])
2017-05-06 14:35:12,028 : INFO : torch.Size([504, 168])
2017-05-06 14:35:12,029 : INFO : torch.Size([504])
2017-05-06 14:35:12,030 : INFO : torch.Size([504])
2017-05-06 14:35:12,031 : INFO : torch.Size([3, 168])
2017-05-06 14:35:12,031 : INFO : torch.Size([3])
2017-05-06 14:35:12,032 : INFO : torch.Size([21705, 300])
2017-05-06 14:35:12,033 : INFO : torch.Size([47, 300])
2017-05-06 14:35:12,034 : INFO : torch.Size([48, 300])
2017-05-06 14:35:12,034 : INFO : sum
2017-05-06 14:35:12,035 : INFO : 7760523
2017-05-06 14:35:12,036 : INFO : ____________
2017-05-06 14:37:04,899 : INFO : ==> Train loss   : 10.472522
2017-05-06 14:37:04,899 : INFO : Epoch
2017-05-06 14:37:04,900 : INFO : 1
2017-05-06 14:37:04,900 : INFO : dev percentage
2017-05-06 14:37:04,900 : INFO : 0.672018348624
2017-05-06 14:37:04,900 : INFO : Epoch
2017-05-06 14:37:04,900 : INFO : 1
2017-05-06 14:37:04,900 : INFO : test percentage
2017-05-06 14:37:04,900 : INFO : 0.578802855574
2017-05-06 14:42:36,555 : INFO : LOG_FILE
2017-05-06 14:42:36,555 : INFO : _________________________________start___________________________________
2017-05-06 14:42:36,562 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-06 14:42:36,777 : INFO : ==> SST vocabulary size : 21705
2017-05-06 14:42:36,777 : INFO : ==> SST rel vocabulary size : 48
2017-05-06 14:42:36,777 : INFO : ==> SST tag vocabulary size : 47
2017-05-06 14:43:31,297 : INFO : LOG_FILE
2017-05-06 14:43:31,297 : INFO : _________________________________start___________________________________
2017-05-06 14:43:31,304 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-06 14:43:31,525 : INFO : ==> SST vocabulary size : 21705
2017-05-06 14:43:31,525 : INFO : ==> SST rel vocabulary size : 48
2017-05-06 14:43:31,525 : INFO : ==> SST tag vocabulary size : 47
2017-05-06 14:43:37,968 : INFO : _param count_
2017-05-06 14:43:37,968 : INFO : torch.Size([504, 600])
2017-05-06 14:43:37,968 : INFO : torch.Size([504, 168])
2017-05-06 14:43:37,968 : INFO : torch.Size([504])
2017-05-06 14:43:37,968 : INFO : torch.Size([504])
2017-05-06 14:43:37,969 : INFO : torch.Size([168, 168])
2017-05-06 14:43:37,969 : INFO : torch.Size([168])
2017-05-06 14:43:37,969 : INFO : torch.Size([168, 1068])
2017-05-06 14:43:37,969 : INFO : torch.Size([168])
2017-05-06 14:43:37,969 : INFO : torch.Size([504, 1068])
2017-05-06 14:43:37,969 : INFO : torch.Size([504, 168])
2017-05-06 14:43:37,969 : INFO : torch.Size([504])
2017-05-06 14:43:37,970 : INFO : torch.Size([504])
2017-05-06 14:43:37,970 : INFO : torch.Size([3, 168])
2017-05-06 14:43:37,970 : INFO : torch.Size([3])
2017-05-06 14:43:37,970 : INFO : torch.Size([21705, 300])
2017-05-06 14:43:37,970 : INFO : torch.Size([47, 300])
2017-05-06 14:43:37,970 : INFO : torch.Size([48, 300])
2017-05-06 14:43:37,970 : INFO : sum
2017-05-06 14:43:37,971 : INFO : 7760523
2017-05-06 14:43:37,971 : INFO : ____________
2017-05-06 14:47:12,506 : INFO : ==> Train loss   : 12.389662
2017-05-06 14:47:12,507 : INFO : Epoch
2017-05-06 14:47:12,507 : INFO : 0
2017-05-06 14:47:12,507 : INFO : dev percentage
2017-05-06 14:47:12,507 : INFO : 0.626146788991
2017-05-06 14:47:12,507 : INFO : Epoch
2017-05-06 14:47:12,507 : INFO : 0
2017-05-06 14:47:12,507 : INFO : test percentage
2017-05-06 14:47:12,507 : INFO : 0.566172432729
2017-05-06 14:51:18,452 : INFO : ==> Train loss   : 10.442425
2017-05-06 14:51:18,452 : INFO : Epoch
2017-05-06 14:51:18,452 : INFO : 1
2017-05-06 14:51:18,452 : INFO : dev percentage
2017-05-06 14:51:18,452 : INFO : 0.616972477064
2017-05-06 14:51:18,452 : INFO : Epoch
2017-05-06 14:51:18,453 : INFO : 1
2017-05-06 14:51:18,453 : INFO : test percentage
2017-05-06 14:51:18,453 : INFO : 0.547501372872
2017-05-06 14:55:44,550 : INFO : ==> Train loss   : 9.911450
2017-05-06 14:55:44,550 : INFO : Epoch
2017-05-06 14:55:44,550 : INFO : 2
2017-05-06 14:55:44,550 : INFO : dev percentage
2017-05-06 14:55:44,550 : INFO : 0.73623853211
2017-05-06 14:55:44,550 : INFO : Epoch
2017-05-06 14:55:44,550 : INFO : 2
2017-05-06 14:55:44,551 : INFO : test percentage
2017-05-06 14:55:44,551 : INFO : 0.584294343767
2017-05-06 15:00:07,805 : INFO : ==> Train loss   : 9.206440
2017-05-06 15:00:07,805 : INFO : Epoch
2017-05-06 15:00:07,805 : INFO : 3
2017-05-06 15:00:07,805 : INFO : dev percentage
2017-05-06 15:00:07,805 : INFO : 0.798165137615
2017-05-06 15:00:07,805 : INFO : Epoch
2017-05-06 15:00:07,806 : INFO : 3
2017-05-06 15:00:07,806 : INFO : test percentage
2017-05-06 15:00:07,806 : INFO : 0.607358594179
2017-05-06 15:04:50,680 : INFO : ==> Train loss   : 8.461920
2017-05-06 15:04:50,681 : INFO : Epoch
2017-05-06 15:04:50,681 : INFO : 4
2017-05-06 15:04:50,681 : INFO : dev percentage
2017-05-06 15:04:50,681 : INFO : 0.825688073394
2017-05-06 15:04:50,681 : INFO : Epoch
2017-05-06 15:04:50,681 : INFO : 4
2017-05-06 15:04:50,681 : INFO : test percentage
2017-05-06 15:04:50,682 : INFO : 0.609555189456
2017-05-06 15:09:52,829 : INFO : ==> Train loss   : 7.828219
2017-05-06 15:09:52,829 : INFO : Epoch
2017-05-06 15:09:52,831 : INFO : 5
2017-05-06 15:09:52,831 : INFO : dev percentage
2017-05-06 15:09:52,831 : INFO : 0.834862385321
2017-05-06 15:09:52,831 : INFO : Epoch
2017-05-06 15:09:52,832 : INFO : 5
2017-05-06 15:09:52,832 : INFO : test percentage
2017-05-06 15:09:52,832 : INFO : 0.605711147721
2017-05-06 15:15:02,693 : INFO : ==> Train loss   : 7.391756
2017-05-06 15:15:02,693 : INFO : Epoch
2017-05-06 15:15:02,693 : INFO : 6
2017-05-06 15:15:02,693 : INFO : dev percentage
2017-05-06 15:15:02,693 : INFO : 0.883027522936
2017-05-06 15:15:02,693 : INFO : Epoch
2017-05-06 15:15:02,693 : INFO : 6
2017-05-06 15:15:02,694 : INFO : test percentage
2017-05-06 15:15:02,694 : INFO : 0.630422844591
2017-05-06 15:20:39,635 : INFO : ==> Train loss   : 6.943163
2017-05-06 15:20:39,636 : INFO : Epoch
2017-05-06 15:20:39,636 : INFO : 7
2017-05-06 15:20:39,636 : INFO : dev percentage
2017-05-06 15:20:39,636 : INFO : 0.899082568807
2017-05-06 15:20:39,636 : INFO : Epoch
2017-05-06 15:20:39,636 : INFO : 7
2017-05-06 15:20:39,636 : INFO : test percentage
2017-05-06 15:20:39,637 : INFO : 0.654585392641
2017-05-06 15:26:36,438 : INFO : ==> Train loss   : 6.655963
2017-05-06 15:26:36,438 : INFO : Epoch
2017-05-06 15:26:36,439 : INFO : 8
2017-05-06 15:26:36,439 : INFO : dev percentage
2017-05-06 15:26:36,439 : INFO : 0.923165137615
2017-05-06 15:26:36,439 : INFO : Epoch
2017-05-06 15:26:36,439 : INFO : 8
2017-05-06 15:26:36,439 : INFO : test percentage
2017-05-06 15:26:36,439 : INFO : 0.647995606809
2017-05-06 15:32:40,984 : INFO : ==> Train loss   : 6.298363
2017-05-06 15:32:40,984 : INFO : Epoch
2017-05-06 15:32:40,984 : INFO : 9
2017-05-06 15:32:40,984 : INFO : dev percentage
2017-05-06 15:32:40,985 : INFO : 0.923165137615
2017-05-06 15:32:40,985 : INFO : Epoch
2017-05-06 15:32:40,985 : INFO : 9
2017-05-06 15:32:40,985 : INFO : test percentage
2017-05-06 15:32:40,985 : INFO : 0.650741350906
2017-05-06 15:39:05,641 : INFO : ==> Train loss   : 6.088136
2017-05-06 15:39:05,641 : INFO : Epoch
2017-05-06 15:39:05,642 : INFO : 10
2017-05-06 15:39:05,642 : INFO : dev percentage
2017-05-06 15:39:05,642 : INFO : 0.94380733945
2017-05-06 15:39:05,642 : INFO : Epoch
2017-05-06 15:39:05,642 : INFO : 10
2017-05-06 15:39:05,642 : INFO : test percentage
2017-05-06 15:39:05,642 : INFO : 0.655134541461
2017-05-06 15:45:48,482 : INFO : ==> Train loss   : 5.903757
2017-05-06 15:45:48,482 : INFO : Epoch
2017-05-06 15:45:48,482 : INFO : 11
2017-05-06 15:45:48,482 : INFO : dev percentage
2017-05-06 15:45:48,482 : INFO : 0.949541284404
2017-05-06 15:45:48,483 : INFO : Epoch
2017-05-06 15:45:48,483 : INFO : 11
2017-05-06 15:45:48,483 : INFO : test percentage
2017-05-06 15:45:48,483 : INFO : 0.661175178473
2017-05-06 15:52:59,853 : INFO : ==> Train loss   : 5.740841
2017-05-06 15:52:59,853 : INFO : Epoch
2017-05-06 15:52:59,853 : INFO : 12
2017-05-06 15:52:59,853 : INFO : dev percentage
2017-05-06 15:52:59,853 : INFO : 0.967889908257
2017-05-06 15:52:59,854 : INFO : Epoch
2017-05-06 15:52:59,854 : INFO : 12
2017-05-06 15:52:59,854 : INFO : test percentage
2017-05-06 15:52:59,854 : INFO : 0.668863261944
2017-05-06 16:01:10,568 : INFO : ==> Train loss   : 5.577068
2017-05-06 16:01:10,568 : INFO : Epoch
2017-05-06 16:01:10,569 : INFO : 13
2017-05-06 16:01:10,569 : INFO : dev percentage
2017-05-06 16:01:10,569 : INFO : 0.971330275229
2017-05-06 16:01:10,569 : INFO : Epoch
2017-05-06 16:01:10,569 : INFO : 13
2017-05-06 16:01:10,569 : INFO : test percentage
2017-05-06 16:01:10,569 : INFO : 0.664470071389
2017-05-06 16:09:24,392 : INFO : ==> Train loss   : 5.317616
2017-05-06 16:09:24,392 : INFO : Epoch
2017-05-06 16:09:24,392 : INFO : 14
2017-05-06 16:09:24,392 : INFO : dev percentage
2017-05-06 16:09:24,392 : INFO : 0.982798165138
2017-05-06 16:09:24,392 : INFO : Epoch
2017-05-06 16:09:24,393 : INFO : 14
2017-05-06 16:09:24,393 : INFO : test percentage
2017-05-06 16:09:24,393 : INFO : 0.668314113125
2017-05-06 16:17:36,130 : INFO : ==> Train loss   : 5.230310
2017-05-06 16:17:36,130 : INFO : Epoch
2017-05-06 16:17:36,130 : INFO : 15
2017-05-06 16:17:36,130 : INFO : dev percentage
2017-05-06 16:17:36,131 : INFO : 0.988532110092
2017-05-06 16:17:36,131 : INFO : Epoch
2017-05-06 16:17:36,131 : INFO : 15
2017-05-06 16:17:36,131 : INFO : test percentage
2017-05-06 16:17:36,131 : INFO : 0.67215815486
2017-05-06 16:25:33,480 : INFO : LOG_FILE
2017-05-06 16:25:33,480 : INFO : _________________________________start___________________________________
2017-05-06 16:25:33,517 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-06 16:25:33,733 : INFO : ==> SST vocabulary size : 21705
2017-05-06 16:25:33,734 : INFO : ==> SST rel vocabulary size : 48
2017-05-06 16:25:33,734 : INFO : ==> SST tag vocabulary size : 47
2017-05-06 16:25:40,260 : INFO : _param count_
2017-05-06 16:25:40,260 : INFO : torch.Size([504, 600])
2017-05-06 16:25:40,260 : INFO : torch.Size([504, 168])
2017-05-06 16:25:40,260 : INFO : torch.Size([504])
2017-05-06 16:25:40,260 : INFO : torch.Size([504])
2017-05-06 16:25:40,261 : INFO : torch.Size([168, 168])
2017-05-06 16:25:40,261 : INFO : torch.Size([168])
2017-05-06 16:25:40,261 : INFO : torch.Size([168, 1068])
2017-05-06 16:25:40,261 : INFO : torch.Size([168])
2017-05-06 16:25:40,261 : INFO : torch.Size([504, 1068])
2017-05-06 16:25:40,261 : INFO : torch.Size([504, 168])
2017-05-06 16:25:40,262 : INFO : torch.Size([504])
2017-05-06 16:25:40,262 : INFO : torch.Size([504])
2017-05-06 16:25:40,262 : INFO : torch.Size([3, 168])
2017-05-06 16:25:40,262 : INFO : torch.Size([3])
2017-05-06 16:25:40,262 : INFO : torch.Size([21705, 300])
2017-05-06 16:25:40,262 : INFO : torch.Size([47, 300])
2017-05-06 16:25:40,263 : INFO : torch.Size([48, 300])
2017-05-06 16:25:40,263 : INFO : sum
2017-05-06 16:25:40,263 : INFO : 7760523
2017-05-06 16:25:40,263 : INFO : ____________
2017-05-06 16:46:25,013 : INFO : ==> Train loss   : 0.701790
2017-05-06 16:46:25,013 : INFO : Epoch
2017-05-06 16:46:25,015 : INFO : 0
2017-05-06 16:46:25,015 : INFO : train percentage
2017-05-06 16:46:25,015 : INFO : 0.609682080925
2017-05-06 16:46:25,015 : INFO : Epoch
2017-05-06 16:46:25,015 : INFO : 0
2017-05-06 16:46:25,016 : INFO : dev percentage
2017-05-06 16:46:25,016 : INFO : 0.627293577982
2017-05-06 16:46:25,016 : INFO : Epoch
2017-05-06 16:46:25,016 : INFO : 0
2017-05-06 16:46:25,016 : INFO : test percentage
2017-05-06 16:46:25,016 : INFO : 0.596924766612
2017-05-06 17:16:20,030 : INFO : ==> Train loss   : 0.630467
2017-05-06 17:16:20,030 : INFO : Epoch
2017-05-06 17:16:20,030 : INFO : 1
2017-05-06 17:16:20,031 : INFO : train percentage
2017-05-06 17:16:20,031 : INFO : 0.687283236994
2017-05-06 17:16:20,031 : INFO : Epoch
2017-05-06 17:16:20,031 : INFO : 1
2017-05-06 17:16:20,031 : INFO : dev percentage
2017-05-06 17:16:20,031 : INFO : 0.63876146789
2017-05-06 17:16:20,031 : INFO : Epoch
2017-05-06 17:16:20,031 : INFO : 1
2017-05-06 17:16:20,032 : INFO : test percentage
2017-05-06 17:16:20,032 : INFO : 0.618890719385
2017-05-06 17:58:22,396 : INFO : ==> Train loss   : 0.520320
2017-05-06 17:58:22,396 : INFO : Epoch
2017-05-06 17:58:22,396 : INFO : 2
2017-05-06 17:58:22,396 : INFO : train percentage
2017-05-06 17:58:22,396 : INFO : 0.747976878613
2017-05-06 17:58:22,396 : INFO : Epoch
2017-05-06 17:58:22,397 : INFO : 2
2017-05-06 17:58:22,397 : INFO : dev percentage
2017-05-06 17:58:22,397 : INFO : 0.668577981651
2017-05-06 17:58:22,397 : INFO : Epoch
2017-05-06 17:58:22,397 : INFO : 2
2017-05-06 17:58:22,397 : INFO : test percentage
2017-05-06 17:58:22,397 : INFO : 0.655134541461
2017-05-06 18:59:47,271 : INFO : ==> Train loss   : 0.387091
2017-05-06 18:59:47,271 : INFO : Epoch
2017-05-06 18:59:47,272 : INFO : 3
2017-05-06 18:59:47,272 : INFO : train percentage
2017-05-06 18:59:47,272 : INFO : 0.854913294798
2017-05-06 18:59:47,272 : INFO : Epoch
2017-05-06 18:59:47,272 : INFO : 3
2017-05-06 18:59:47,272 : INFO : dev percentage
2017-05-06 18:59:47,272 : INFO : 0.751146788991
2017-05-06 18:59:47,273 : INFO : Epoch
2017-05-06 18:59:47,273 : INFO : 3
2017-05-06 18:59:47,273 : INFO : test percentage
2017-05-06 18:59:47,273 : INFO : 0.74574409665
2017-05-06 20:13:06,857 : INFO : ==> Train loss   : 0.285950
2017-05-06 20:13:06,857 : INFO : Epoch
2017-05-06 20:13:06,857 : INFO : 4
2017-05-06 20:13:06,857 : INFO : train percentage
2017-05-06 20:13:06,857 : INFO : 0.898554913295
2017-05-06 20:13:06,858 : INFO : Epoch
2017-05-06 20:13:06,858 : INFO : 4
2017-05-06 20:13:06,858 : INFO : dev percentage
2017-05-06 20:13:06,858 : INFO : 0.76376146789
2017-05-06 20:13:06,858 : INFO : Epoch
2017-05-06 20:13:06,858 : INFO : 4
2017-05-06 20:13:06,858 : INFO : test percentage
2017-05-06 20:13:06,858 : INFO : 0.767160900604
2017-05-06 21:39:17,382 : INFO : ==> Train loss   : 0.221512
2017-05-06 21:39:17,382 : INFO : Epoch
2017-05-06 21:39:17,382 : INFO : 5
2017-05-06 21:39:17,383 : INFO : train percentage
2017-05-06 21:39:17,383 : INFO : 0.926445086705
2017-05-06 21:39:17,383 : INFO : Epoch
2017-05-06 21:39:17,383 : INFO : 5
2017-05-06 21:39:17,383 : INFO : dev percentage
2017-05-06 21:39:17,383 : INFO : 0.778669724771
2017-05-06 21:39:17,383 : INFO : Epoch
2017-05-06 21:39:17,383 : INFO : 5
2017-05-06 21:39:17,384 : INFO : test percentage
2017-05-06 21:39:17,384 : INFO : 0.769906644701
2017-05-06 23:29:38,690 : INFO : ==> Train loss   : 0.170489
2017-05-06 23:29:38,691 : INFO : Epoch
2017-05-06 23:29:38,691 : INFO : 6
2017-05-06 23:29:38,691 : INFO : train percentage
2017-05-06 23:29:38,691 : INFO : 0.946387283237
2017-05-06 23:29:38,691 : INFO : Epoch
2017-05-06 23:29:38,691 : INFO : 6
2017-05-06 23:29:38,691 : INFO : dev percentage
2017-05-06 23:29:38,692 : INFO : 0.778669724771
2017-05-06 23:29:38,692 : INFO : Epoch
2017-05-06 23:29:38,692 : INFO : 6
2017-05-06 23:29:38,692 : INFO : test percentage
2017-05-06 23:29:38,692 : INFO : 0.778143876991
2017-05-07 01:28:07,248 : INFO : ==> Train loss   : 0.129346
2017-05-07 01:28:07,248 : INFO : Epoch
2017-05-07 01:28:07,248 : INFO : 7
2017-05-07 01:28:07,248 : INFO : train percentage
2017-05-07 01:28:07,248 : INFO : 0.96387283237
2017-05-07 01:28:07,248 : INFO : Epoch
2017-05-07 01:28:07,248 : INFO : 7
2017-05-07 01:28:07,249 : INFO : dev percentage
2017-05-07 01:28:07,249 : INFO : 0.771788990826
2017-05-07 01:28:07,249 : INFO : Epoch
2017-05-07 01:28:07,249 : INFO : 7
2017-05-07 01:28:07,249 : INFO : test percentage
2017-05-07 01:28:07,249 : INFO : 0.781987918726
2017-05-07 03:35:21,498 : INFO : ==> Train loss   : 0.104151
2017-05-07 03:35:21,498 : INFO : Epoch
2017-05-07 03:35:21,498 : INFO : 8
2017-05-07 03:35:21,498 : INFO : train percentage
2017-05-07 03:35:21,498 : INFO : 0.970375722543
2017-05-07 03:35:21,498 : INFO : Epoch
2017-05-07 03:35:21,499 : INFO : 8
2017-05-07 03:35:21,499 : INFO : dev percentage
2017-05-07 03:35:21,499 : INFO : 0.776376146789
2017-05-07 03:35:21,499 : INFO : Epoch
2017-05-07 03:35:21,499 : INFO : 8
2017-05-07 03:35:21,499 : INFO : test percentage
2017-05-07 03:35:21,499 : INFO : 0.772652388797
2017-05-07 05:54:33,905 : INFO : ==> Train loss   : 0.084698
2017-05-07 05:54:33,905 : INFO : Epoch
2017-05-07 05:54:33,905 : INFO : 9
2017-05-07 05:54:33,905 : INFO : train percentage
2017-05-07 05:54:33,906 : INFO : 0.975722543353
2017-05-07 05:54:33,906 : INFO : Epoch
2017-05-07 05:54:33,906 : INFO : 9
2017-05-07 05:54:33,906 : INFO : dev percentage
2017-05-07 05:54:33,906 : INFO : 0.778669724771
2017-05-07 05:54:33,906 : INFO : Epoch
2017-05-07 05:54:33,906 : INFO : 9
2017-05-07 05:54:33,906 : INFO : test percentage
2017-05-07 05:54:33,907 : INFO : 0.781987918726
2017-05-07 08:29:03,294 : INFO : ==> Train loss   : 0.067962
2017-05-07 08:29:03,294 : INFO : Epoch
2017-05-07 08:29:03,294 : INFO : 10
2017-05-07 08:29:03,295 : INFO : train percentage
2017-05-07 08:29:03,295 : INFO : 0.98338150289
2017-05-07 08:29:03,295 : INFO : Epoch
2017-05-07 08:29:03,295 : INFO : 10
2017-05-07 08:29:03,295 : INFO : dev percentage
2017-05-07 08:29:03,295 : INFO : 0.775229357798
2017-05-07 08:29:03,295 : INFO : Epoch
2017-05-07 08:29:03,295 : INFO : 10
2017-05-07 08:29:03,295 : INFO : test percentage
2017-05-07 08:29:03,296 : INFO : 0.787479406919
2017-05-07 11:26:42,939 : INFO : ==> Train loss   : 0.058841
2017-05-07 11:26:42,939 : INFO : Epoch
2017-05-07 11:26:42,939 : INFO : 11
2017-05-07 11:26:42,940 : INFO : train percentage
2017-05-07 11:26:42,940 : INFO : 0.985404624277
2017-05-07 11:26:42,940 : INFO : Epoch
2017-05-07 11:26:42,940 : INFO : 11
2017-05-07 11:26:42,940 : INFO : dev percentage
2017-05-07 11:26:42,940 : INFO : 0.771788990826
2017-05-07 11:26:42,940 : INFO : Epoch
2017-05-07 11:26:42,940 : INFO : 11
2017-05-07 11:26:42,941 : INFO : test percentage
2017-05-07 11:26:42,941 : INFO : 0.783086216365
2017-05-07 14:52:50,004 : INFO : ==> Train loss   : 0.051845
2017-05-07 14:52:50,004 : INFO : Epoch
2017-05-07 14:52:50,004 : INFO : 12
2017-05-07 14:52:50,004 : INFO : train percentage
2017-05-07 14:52:50,004 : INFO : 0.988150289017
2017-05-07 14:52:50,004 : INFO : Epoch
2017-05-07 14:52:50,004 : INFO : 12
2017-05-07 14:52:50,005 : INFO : dev percentage
2017-05-07 14:52:50,005 : INFO : 0.76376146789
2017-05-07 14:52:50,005 : INFO : Epoch
2017-05-07 14:52:50,005 : INFO : 12
2017-05-07 14:52:50,005 : INFO : test percentage
2017-05-07 14:52:50,005 : INFO : 0.774299835255
2017-05-07 18:25:59,451 : INFO : ==> Train loss   : 0.045213
2017-05-07 18:25:59,451 : INFO : Epoch
2017-05-07 18:25:59,452 : INFO : 13
2017-05-07 18:25:59,452 : INFO : train percentage
2017-05-07 18:25:59,452 : INFO : 0.990606936416
2017-05-07 18:25:59,452 : INFO : Epoch
2017-05-07 18:25:59,452 : INFO : 13
2017-05-07 18:25:59,452 : INFO : dev percentage
2017-05-07 18:25:59,452 : INFO : 0.770642201835
2017-05-07 18:25:59,452 : INFO : Epoch
2017-05-07 18:25:59,452 : INFO : 13
2017-05-07 18:25:59,453 : INFO : test percentage
2017-05-07 18:25:59,453 : INFO : 0.783086216365
2017-05-07 22:00:32,137 : INFO : ==> Train loss   : 0.038694
2017-05-07 22:00:32,137 : INFO : Epoch
2017-05-07 22:00:32,137 : INFO : 14
2017-05-07 22:00:32,137 : INFO : train percentage
2017-05-07 22:00:32,137 : INFO : 0.991329479769
2017-05-07 22:00:32,138 : INFO : Epoch
2017-05-07 22:00:32,138 : INFO : 14
2017-05-07 22:00:32,138 : INFO : dev percentage
2017-05-07 22:00:32,138 : INFO : 0.76376146789
2017-05-07 22:00:32,138 : INFO : Epoch
2017-05-07 22:00:32,138 : INFO : 14
2017-05-07 22:00:32,138 : INFO : test percentage
2017-05-07 22:00:32,138 : INFO : 0.777045579352
2017-05-08 01:53:04,728 : INFO : ==> Train loss   : 0.033949
2017-05-08 01:53:04,728 : INFO : Epoch
2017-05-08 01:53:04,728 : INFO : 15
2017-05-08 01:53:04,728 : INFO : train percentage
2017-05-08 01:53:04,728 : INFO : 0.992630057803
2017-05-08 01:53:04,728 : INFO : Epoch
2017-05-08 01:53:04,728 : INFO : 15
2017-05-08 01:53:04,728 : INFO : dev percentage
2017-05-08 01:53:04,729 : INFO : 0.766055045872
2017-05-08 01:53:04,729 : INFO : Epoch
2017-05-08 01:53:04,729 : INFO : 15
2017-05-08 01:53:04,729 : INFO : test percentage
2017-05-08 01:53:04,729 : INFO : 0.781987918726
2017-05-08 07:43:00,687 : INFO : ==> Train loss   : 0.028807
2017-05-08 07:43:00,720 : INFO : Epoch
2017-05-08 07:43:00,721 : INFO : 16
2017-05-08 07:43:00,721 : INFO : train percentage
2017-05-08 07:43:00,721 : INFO : 0.993497109827
2017-05-08 07:43:00,721 : INFO : Epoch
2017-05-08 07:43:00,721 : INFO : 16
2017-05-08 07:43:00,721 : INFO : dev percentage
2017-05-08 07:43:00,721 : INFO : 0.761467889908
2017-05-08 07:43:00,721 : INFO : Epoch
2017-05-08 07:43:00,722 : INFO : 16
2017-05-08 07:43:00,722 : INFO : test percentage
2017-05-08 07:43:00,722 : INFO : 0.768259198243
2017-05-08 11:46:18,824 : INFO : ==> Train loss   : 0.027269
2017-05-08 11:46:18,824 : INFO : Epoch
2017-05-08 11:46:18,824 : INFO : 17
2017-05-08 11:46:18,824 : INFO : train percentage
2017-05-08 11:46:18,824 : INFO : 0.994219653179
2017-05-08 11:46:18,824 : INFO : Epoch
2017-05-08 11:46:18,825 : INFO : 17
2017-05-08 11:46:18,825 : INFO : dev percentage
2017-05-08 11:46:18,825 : INFO : 0.748853211009
2017-05-08 11:46:18,825 : INFO : Epoch
2017-05-08 11:46:18,825 : INFO : 17
2017-05-08 11:46:18,825 : INFO : test percentage
2017-05-08 11:46:18,825 : INFO : 0.771554091159
2017-05-08 13:53:31,536 : INFO : LOG_FILE
2017-05-08 13:53:31,536 : INFO : _________________________________start___________________________________
2017-05-08 13:53:31,543 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-08 13:53:31,767 : INFO : ==> SST vocabulary size : 21705
2017-05-08 13:53:31,767 : INFO : ==> SST rel vocabulary size : 48
2017-05-08 13:53:31,767 : INFO : ==> SST tag vocabulary size : 47
2017-05-08 13:53:38,609 : INFO : _param count_
2017-05-08 13:53:38,609 : INFO : torch.Size([504, 600])
2017-05-08 13:53:38,609 : INFO : torch.Size([504, 168])
2017-05-08 13:53:38,609 : INFO : torch.Size([504])
2017-05-08 13:53:38,609 : INFO : torch.Size([504])
2017-05-08 13:53:38,609 : INFO : torch.Size([168, 168])
2017-05-08 13:53:38,610 : INFO : torch.Size([168])
2017-05-08 13:53:38,610 : INFO : torch.Size([168, 1068])
2017-05-08 13:53:38,610 : INFO : torch.Size([168])
2017-05-08 13:53:38,610 : INFO : torch.Size([504, 1068])
2017-05-08 13:53:38,610 : INFO : torch.Size([504, 168])
2017-05-08 13:53:38,610 : INFO : torch.Size([504])
2017-05-08 13:53:38,610 : INFO : torch.Size([504])
2017-05-08 13:53:38,610 : INFO : torch.Size([3, 168])
2017-05-08 13:53:38,611 : INFO : torch.Size([3])
2017-05-08 13:53:38,611 : INFO : torch.Size([21705, 300])
2017-05-08 13:53:38,611 : INFO : torch.Size([47, 300])
2017-05-08 13:53:38,611 : INFO : torch.Size([48, 300])
2017-05-08 13:53:38,611 : INFO : sum
2017-05-08 13:53:38,611 : INFO : 7760523
2017-05-08 13:53:38,611 : INFO : ____________
2017-05-08 13:56:36,258 : INFO : LOG_FILE
2017-05-08 13:56:36,258 : INFO : _________________________________start___________________________________
2017-05-08 13:56:36,264 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-08 13:56:36,472 : INFO : ==> SST vocabulary size : 21705
2017-05-08 13:56:36,472 : INFO : ==> SST rel vocabulary size : 48
2017-05-08 13:56:36,472 : INFO : ==> SST tag vocabulary size : 47
2017-05-08 13:56:43,022 : INFO : _param count_
2017-05-08 13:56:43,022 : INFO : torch.Size([504, 600])
2017-05-08 13:56:43,022 : INFO : torch.Size([504, 168])
2017-05-08 13:56:43,022 : INFO : torch.Size([504])
2017-05-08 13:56:43,023 : INFO : torch.Size([504])
2017-05-08 13:56:43,023 : INFO : torch.Size([168, 168])
2017-05-08 13:56:43,023 : INFO : torch.Size([168])
2017-05-08 13:56:43,023 : INFO : torch.Size([168, 1068])
2017-05-08 13:56:43,023 : INFO : torch.Size([168])
2017-05-08 13:56:43,023 : INFO : torch.Size([504, 1068])
2017-05-08 13:56:43,024 : INFO : torch.Size([504, 168])
2017-05-08 13:56:43,024 : INFO : torch.Size([504])
2017-05-08 13:56:43,024 : INFO : torch.Size([504])
2017-05-08 13:56:43,024 : INFO : torch.Size([3, 168])
2017-05-08 13:56:43,024 : INFO : torch.Size([3])
2017-05-08 13:56:43,025 : INFO : torch.Size([21705, 300])
2017-05-08 13:56:43,025 : INFO : torch.Size([47, 300])
2017-05-08 13:56:43,025 : INFO : torch.Size([48, 300])
2017-05-08 13:56:43,025 : INFO : sum
2017-05-08 13:56:43,025 : INFO : 7760523
2017-05-08 13:56:43,026 : INFO : ____________
2017-05-08 13:56:51,829 : INFO : LOG_FILE
2017-05-08 13:56:51,830 : INFO : _________________________________start___________________________________
2017-05-08 13:56:51,843 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-08 13:56:52,256 : INFO : ==> SST vocabulary size : 21705
2017-05-08 13:56:52,257 : INFO : ==> SST rel vocabulary size : 48
2017-05-08 13:56:52,257 : INFO : ==> SST tag vocabulary size : 47
2017-05-08 13:57:00,049 : INFO : _param count_
2017-05-08 13:57:00,051 : INFO : torch.Size([504, 600])
2017-05-08 13:57:00,052 : INFO : torch.Size([504, 168])
2017-05-08 13:57:00,053 : INFO : torch.Size([504])
2017-05-08 13:57:00,053 : INFO : torch.Size([504])
2017-05-08 13:57:00,054 : INFO : torch.Size([168, 168])
2017-05-08 13:57:00,054 : INFO : torch.Size([168])
2017-05-08 13:57:00,055 : INFO : torch.Size([168, 1068])
2017-05-08 13:57:00,055 : INFO : torch.Size([168])
2017-05-08 13:57:00,056 : INFO : torch.Size([504, 1068])
2017-05-08 13:57:00,057 : INFO : torch.Size([504, 168])
2017-05-08 13:57:00,057 : INFO : torch.Size([504])
2017-05-08 13:57:00,058 : INFO : torch.Size([504])
2017-05-08 13:57:00,058 : INFO : torch.Size([3, 168])
2017-05-08 13:57:00,059 : INFO : torch.Size([3])
2017-05-08 13:57:00,059 : INFO : torch.Size([21705, 300])
2017-05-08 13:57:00,060 : INFO : torch.Size([47, 300])
2017-05-08 13:57:00,061 : INFO : torch.Size([48, 300])
2017-05-08 13:57:00,061 : INFO : sum
2017-05-08 13:57:00,062 : INFO : 7760523
2017-05-08 13:57:00,062 : INFO : ____________
2017-05-08 13:57:44,368 : INFO : LOG_FILE
2017-05-08 13:57:44,368 : INFO : _________________________________start___________________________________
2017-05-08 13:57:44,375 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-08 13:57:44,588 : INFO : ==> SST vocabulary size : 21705
2017-05-08 13:57:44,588 : INFO : ==> SST rel vocabulary size : 48
2017-05-08 13:57:44,588 : INFO : ==> SST tag vocabulary size : 47
2017-05-08 13:57:51,349 : INFO : _param count_
2017-05-08 13:57:51,350 : INFO : torch.Size([504, 600])
2017-05-08 13:57:51,350 : INFO : torch.Size([504, 168])
2017-05-08 13:57:51,350 : INFO : torch.Size([504])
2017-05-08 13:57:51,350 : INFO : torch.Size([504])
2017-05-08 13:57:51,350 : INFO : torch.Size([168, 168])
2017-05-08 13:57:51,350 : INFO : torch.Size([168])
2017-05-08 13:57:51,351 : INFO : torch.Size([168, 1068])
2017-05-08 13:57:51,351 : INFO : torch.Size([168])
2017-05-08 13:57:51,351 : INFO : torch.Size([504, 1068])
2017-05-08 13:57:51,351 : INFO : torch.Size([504, 168])
2017-05-08 13:57:51,351 : INFO : torch.Size([504])
2017-05-08 13:57:51,351 : INFO : torch.Size([504])
2017-05-08 13:57:51,351 : INFO : torch.Size([3, 168])
2017-05-08 13:57:51,352 : INFO : torch.Size([3])
2017-05-08 13:57:51,352 : INFO : torch.Size([21705, 300])
2017-05-08 13:57:51,352 : INFO : torch.Size([47, 300])
2017-05-08 13:57:51,352 : INFO : torch.Size([48, 300])
2017-05-08 13:57:51,352 : INFO : sum
2017-05-08 13:57:51,352 : INFO : 7760523
2017-05-08 13:57:51,352 : INFO : ____________
2017-05-08 14:13:43,031 : INFO : LOG_FILE
2017-05-08 14:13:43,031 : INFO : _________________________________start___________________________________
2017-05-08 14:13:43,037 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-08 14:13:43,256 : INFO : ==> SST vocabulary size : 21705
2017-05-08 14:13:43,256 : INFO : ==> SST rel vocabulary size : 48
2017-05-08 14:13:43,256 : INFO : ==> SST tag vocabulary size : 47
2017-05-08 14:13:49,589 : INFO : _param count_
2017-05-08 14:13:49,589 : INFO : torch.Size([504, 600])
2017-05-08 14:13:49,589 : INFO : torch.Size([504, 168])
2017-05-08 14:13:49,589 : INFO : torch.Size([504])
2017-05-08 14:13:49,590 : INFO : torch.Size([504])
2017-05-08 14:13:49,590 : INFO : torch.Size([168, 168])
2017-05-08 14:13:49,590 : INFO : torch.Size([168])
2017-05-08 14:13:49,590 : INFO : torch.Size([168, 1068])
2017-05-08 14:13:49,590 : INFO : torch.Size([168])
2017-05-08 14:13:49,590 : INFO : torch.Size([504, 1068])
2017-05-08 14:13:49,591 : INFO : torch.Size([504, 168])
2017-05-08 14:13:49,591 : INFO : torch.Size([504])
2017-05-08 14:13:49,591 : INFO : torch.Size([504])
2017-05-08 14:13:49,591 : INFO : torch.Size([3, 168])
2017-05-08 14:13:49,591 : INFO : torch.Size([3])
2017-05-08 14:13:49,591 : INFO : torch.Size([21705, 300])
2017-05-08 14:13:49,592 : INFO : torch.Size([47, 300])
2017-05-08 14:13:49,592 : INFO : torch.Size([48, 300])
2017-05-08 14:13:49,592 : INFO : sum
2017-05-08 14:13:49,592 : INFO : 7760523
2017-05-08 14:13:49,592 : INFO : ____________
2017-05-08 14:18:35,991 : INFO : LOG_FILE
2017-05-08 14:18:35,991 : INFO : _________________________________start___________________________________
2017-05-08 14:18:35,997 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-08 14:18:36,202 : INFO : ==> SST vocabulary size : 21705
2017-05-08 14:18:36,203 : INFO : ==> SST rel vocabulary size : 48
2017-05-08 14:18:36,203 : INFO : ==> SST tag vocabulary size : 47
2017-05-08 14:18:43,064 : INFO : _param count_
2017-05-08 14:18:43,064 : INFO : torch.Size([504, 600])
2017-05-08 14:18:43,064 : INFO : torch.Size([504, 168])
2017-05-08 14:18:43,064 : INFO : torch.Size([504])
2017-05-08 14:18:43,065 : INFO : torch.Size([504])
2017-05-08 14:18:43,065 : INFO : torch.Size([168, 168])
2017-05-08 14:18:43,065 : INFO : torch.Size([168])
2017-05-08 14:18:43,065 : INFO : torch.Size([168, 1068])
2017-05-08 14:18:43,065 : INFO : torch.Size([168])
2017-05-08 14:18:43,065 : INFO : torch.Size([504, 1068])
2017-05-08 14:18:43,066 : INFO : torch.Size([504, 168])
2017-05-08 14:18:43,066 : INFO : torch.Size([504])
2017-05-08 14:18:43,066 : INFO : torch.Size([504])
2017-05-08 14:18:43,066 : INFO : torch.Size([3, 168])
2017-05-08 14:18:43,066 : INFO : torch.Size([3])
2017-05-08 14:18:43,066 : INFO : torch.Size([21705, 300])
2017-05-08 14:18:43,067 : INFO : torch.Size([47, 300])
2017-05-08 14:18:43,067 : INFO : torch.Size([48, 300])
2017-05-08 14:18:43,067 : INFO : sum
2017-05-08 14:18:43,067 : INFO : 7760523
2017-05-08 14:18:43,067 : INFO : ____________
2017-05-08 14:18:59,809 : INFO : LOG_FILE
2017-05-08 14:18:59,809 : INFO : _________________________________start___________________________________
2017-05-08 14:18:59,816 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-08 14:19:00,043 : INFO : ==> SST vocabulary size : 21705
2017-05-08 14:19:00,043 : INFO : ==> SST rel vocabulary size : 48
2017-05-08 14:19:00,043 : INFO : ==> SST tag vocabulary size : 47
2017-05-08 14:19:06,885 : INFO : _param count_
2017-05-08 14:19:06,886 : INFO : torch.Size([504, 600])
2017-05-08 14:19:06,886 : INFO : torch.Size([504, 168])
2017-05-08 14:19:06,886 : INFO : torch.Size([504])
2017-05-08 14:19:06,886 : INFO : torch.Size([504])
2017-05-08 14:19:06,886 : INFO : torch.Size([168, 168])
2017-05-08 14:19:06,886 : INFO : torch.Size([168])
2017-05-08 14:19:06,887 : INFO : torch.Size([168, 1068])
2017-05-08 14:19:06,887 : INFO : torch.Size([168])
2017-05-08 14:19:06,887 : INFO : torch.Size([504, 1068])
2017-05-08 14:19:06,887 : INFO : torch.Size([504, 168])
2017-05-08 14:19:06,887 : INFO : torch.Size([504])
2017-05-08 14:19:06,887 : INFO : torch.Size([504])
2017-05-08 14:19:06,887 : INFO : torch.Size([3, 168])
2017-05-08 14:19:06,888 : INFO : torch.Size([3])
2017-05-08 14:19:06,888 : INFO : torch.Size([21705, 300])
2017-05-08 14:19:06,888 : INFO : torch.Size([47, 300])
2017-05-08 14:19:06,888 : INFO : torch.Size([48, 300])
2017-05-08 14:19:06,888 : INFO : sum
2017-05-08 14:19:06,888 : INFO : 7760523
2017-05-08 14:19:06,888 : INFO : ____________
2017-05-08 14:19:15,180 : INFO : LOG_FILE
2017-05-08 14:19:15,180 : INFO : _________________________________start___________________________________
2017-05-08 14:19:15,186 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-08 14:19:15,398 : INFO : ==> SST vocabulary size : 21705
2017-05-08 14:19:15,398 : INFO : ==> SST rel vocabulary size : 48
2017-05-08 14:19:15,398 : INFO : ==> SST tag vocabulary size : 47
2017-05-08 14:19:22,284 : INFO : _param count_
2017-05-08 14:19:22,285 : INFO : torch.Size([504, 600])
2017-05-08 14:19:22,285 : INFO : torch.Size([504, 168])
2017-05-08 14:19:22,285 : INFO : torch.Size([504])
2017-05-08 14:19:22,285 : INFO : torch.Size([504])
2017-05-08 14:19:22,286 : INFO : torch.Size([168, 168])
2017-05-08 14:19:22,286 : INFO : torch.Size([168])
2017-05-08 14:19:22,286 : INFO : torch.Size([168, 1068])
2017-05-08 14:19:22,286 : INFO : torch.Size([168])
2017-05-08 14:19:22,286 : INFO : torch.Size([504, 1068])
2017-05-08 14:19:22,286 : INFO : torch.Size([504, 168])
2017-05-08 14:19:22,286 : INFO : torch.Size([504])
2017-05-08 14:19:22,287 : INFO : torch.Size([504])
2017-05-08 14:19:22,287 : INFO : torch.Size([3, 168])
2017-05-08 14:19:22,287 : INFO : torch.Size([3])
2017-05-08 14:19:22,287 : INFO : torch.Size([21705, 300])
2017-05-08 14:19:22,287 : INFO : torch.Size([47, 300])
2017-05-08 14:19:22,287 : INFO : torch.Size([48, 300])
2017-05-08 14:19:22,287 : INFO : sum
2017-05-08 14:19:22,287 : INFO : 7760523
2017-05-08 14:19:22,288 : INFO : ____________
2017-05-08 14:19:32,618 : INFO : LOG_FILE
2017-05-08 14:19:32,619 : INFO : _________________________________start___________________________________
2017-05-08 14:19:32,632 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-08 14:19:33,035 : INFO : ==> SST vocabulary size : 21705
2017-05-08 14:19:33,036 : INFO : ==> SST rel vocabulary size : 48
2017-05-08 14:19:33,036 : INFO : ==> SST tag vocabulary size : 47
2017-05-08 14:19:41,272 : INFO : _param count_
2017-05-08 14:19:41,275 : INFO : torch.Size([504, 600])
2017-05-08 14:19:41,275 : INFO : torch.Size([504, 168])
2017-05-08 14:19:41,276 : INFO : torch.Size([504])
2017-05-08 14:19:41,276 : INFO : torch.Size([504])
2017-05-08 14:19:41,277 : INFO : torch.Size([168, 168])
2017-05-08 14:19:41,277 : INFO : torch.Size([168])
2017-05-08 14:19:41,278 : INFO : torch.Size([168, 1068])
2017-05-08 14:19:41,279 : INFO : torch.Size([168])
2017-05-08 14:19:41,279 : INFO : torch.Size([504, 1068])
2017-05-08 14:19:41,280 : INFO : torch.Size([504, 168])
2017-05-08 14:19:41,280 : INFO : torch.Size([504])
2017-05-08 14:19:41,281 : INFO : torch.Size([504])
2017-05-08 14:19:41,281 : INFO : torch.Size([3, 168])
2017-05-08 14:19:41,282 : INFO : torch.Size([3])
2017-05-08 14:19:41,283 : INFO : torch.Size([21705, 300])
2017-05-08 14:19:41,283 : INFO : torch.Size([47, 300])
2017-05-08 14:19:41,284 : INFO : torch.Size([48, 300])
2017-05-08 14:19:41,284 : INFO : sum
2017-05-08 14:19:41,285 : INFO : 7760523
2017-05-08 14:19:41,285 : INFO : ____________
2017-05-08 14:21:07,988 : INFO : LOG_FILE
2017-05-08 14:21:07,988 : INFO : _________________________________start___________________________________
2017-05-08 14:21:07,994 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-08 14:21:08,188 : INFO : ==> SST vocabulary size : 21705
2017-05-08 14:21:08,188 : INFO : ==> SST rel vocabulary size : 48
2017-05-08 14:21:08,188 : INFO : ==> SST tag vocabulary size : 47
2017-05-08 14:21:49,911 : INFO : LOG_FILE
2017-05-08 14:21:49,911 : INFO : _________________________________start___________________________________
2017-05-08 14:21:49,917 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-08 14:21:50,125 : INFO : ==> SST vocabulary size : 21705
2017-05-08 14:21:50,125 : INFO : ==> SST rel vocabulary size : 48
2017-05-08 14:21:50,125 : INFO : ==> SST tag vocabulary size : 47
2017-05-08 14:21:56,472 : INFO : _param count_
2017-05-08 14:21:56,472 : INFO : torch.Size([504, 600])
2017-05-08 14:21:56,472 : INFO : torch.Size([504, 168])
2017-05-08 14:21:56,472 : INFO : torch.Size([504])
2017-05-08 14:21:56,472 : INFO : torch.Size([504])
2017-05-08 14:21:56,473 : INFO : torch.Size([168, 168])
2017-05-08 14:21:56,473 : INFO : torch.Size([168])
2017-05-08 14:21:56,473 : INFO : torch.Size([168, 1068])
2017-05-08 14:21:56,473 : INFO : torch.Size([168])
2017-05-08 14:21:56,473 : INFO : torch.Size([504, 1068])
2017-05-08 14:21:56,473 : INFO : torch.Size([504, 168])
2017-05-08 14:21:56,473 : INFO : torch.Size([504])
2017-05-08 14:21:56,474 : INFO : torch.Size([504])
2017-05-08 14:21:56,474 : INFO : torch.Size([3, 168])
2017-05-08 14:21:56,474 : INFO : torch.Size([3])
2017-05-08 14:21:56,474 : INFO : sum
2017-05-08 14:21:56,474 : INFO : 1220523
2017-05-08 14:21:56,474 : INFO : ____________
2017-05-08 14:25:31,330 : INFO : LOG_FILE
2017-05-08 14:25:31,331 : INFO : _________________________________start___________________________________
2017-05-08 14:25:31,337 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-08 14:25:31,543 : INFO : ==> SST vocabulary size : 21705
2017-05-08 14:25:31,544 : INFO : ==> SST rel vocabulary size : 48
2017-05-08 14:25:31,544 : INFO : ==> SST tag vocabulary size : 47
2017-05-08 14:25:37,958 : INFO : _param count_
2017-05-08 14:25:37,959 : INFO : torch.Size([504, 600])
2017-05-08 14:25:37,959 : INFO : torch.Size([504, 168])
2017-05-08 14:25:37,959 : INFO : torch.Size([504])
2017-05-08 14:25:37,959 : INFO : torch.Size([504])
2017-05-08 14:25:37,959 : INFO : torch.Size([168, 168])
2017-05-08 14:25:37,959 : INFO : torch.Size([168])
2017-05-08 14:25:37,960 : INFO : torch.Size([168, 1068])
2017-05-08 14:25:37,960 : INFO : torch.Size([168])
2017-05-08 14:25:37,960 : INFO : torch.Size([504, 1068])
2017-05-08 14:25:37,960 : INFO : torch.Size([504, 168])
2017-05-08 14:25:37,960 : INFO : torch.Size([504])
2017-05-08 14:25:37,960 : INFO : torch.Size([504])
2017-05-08 14:25:37,960 : INFO : torch.Size([3, 168])
2017-05-08 14:25:37,961 : INFO : torch.Size([3])
2017-05-08 14:25:37,961 : INFO : sum
2017-05-08 14:25:37,961 : INFO : 1220523
2017-05-08 14:25:37,961 : INFO : ____________
2017-05-08 14:29:05,339 : INFO : ==> Dev loss   : 0.807664
2017-05-08 14:29:05,339 : INFO : Epoch
2017-05-08 14:29:05,339 : INFO : 0
2017-05-08 14:29:05,339 : INFO : dev percentage
2017-05-08 14:29:05,339 : INFO : 0.628440366972
2017-05-08 14:30:44,312 : INFO : LOG_FILE
2017-05-08 14:30:44,313 : INFO : _________________________________start___________________________________
2017-05-08 14:30:44,326 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-08 14:30:44,742 : INFO : ==> SST vocabulary size : 21705
2017-05-08 14:30:44,742 : INFO : ==> SST rel vocabulary size : 48
2017-05-08 14:30:44,743 : INFO : ==> SST tag vocabulary size : 47
2017-05-08 14:30:52,773 : INFO : _param count_
2017-05-08 14:30:52,776 : INFO : torch.Size([504, 600])
2017-05-08 14:30:52,777 : INFO : torch.Size([504, 168])
2017-05-08 14:30:52,777 : INFO : torch.Size([504])
2017-05-08 14:30:52,778 : INFO : torch.Size([504])
2017-05-08 14:30:52,778 : INFO : torch.Size([168, 168])
2017-05-08 14:30:52,779 : INFO : torch.Size([168])
2017-05-08 14:30:52,779 : INFO : torch.Size([168, 1068])
2017-05-08 14:30:52,780 : INFO : torch.Size([168])
2017-05-08 14:30:52,780 : INFO : torch.Size([504, 1068])
2017-05-08 14:30:52,781 : INFO : torch.Size([504, 168])
2017-05-08 14:30:52,781 : INFO : torch.Size([504])
2017-05-08 14:30:52,782 : INFO : torch.Size([504])
2017-05-08 14:30:52,783 : INFO : torch.Size([3, 168])
2017-05-08 14:30:52,783 : INFO : torch.Size([3])
2017-05-08 14:30:52,784 : INFO : sum
2017-05-08 14:30:52,784 : INFO : 1220523
2017-05-08 14:30:52,785 : INFO : ____________
2017-05-08 14:34:52,493 : INFO : LOG_FILE
2017-05-08 14:34:52,493 : INFO : _________________________________start___________________________________
2017-05-08 14:34:52,500 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=168, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-08 14:34:52,704 : INFO : ==> SST vocabulary size : 21705
2017-05-08 14:34:52,704 : INFO : ==> SST rel vocabulary size : 48
2017-05-08 14:34:52,704 : INFO : ==> SST tag vocabulary size : 47
2017-05-08 14:34:59,147 : INFO : _param count_
2017-05-08 14:34:59,148 : INFO : torch.Size([504, 600])
2017-05-08 14:34:59,148 : INFO : torch.Size([504, 168])
2017-05-08 14:34:59,148 : INFO : torch.Size([504])
2017-05-08 14:34:59,148 : INFO : torch.Size([504])
2017-05-08 14:34:59,148 : INFO : torch.Size([168, 168])
2017-05-08 14:34:59,148 : INFO : torch.Size([168])
2017-05-08 14:34:59,148 : INFO : torch.Size([168, 1068])
2017-05-08 14:34:59,149 : INFO : torch.Size([168])
2017-05-08 14:34:59,149 : INFO : torch.Size([504, 1068])
2017-05-08 14:34:59,149 : INFO : torch.Size([504, 168])
2017-05-08 14:34:59,149 : INFO : torch.Size([504])
2017-05-08 14:34:59,149 : INFO : torch.Size([504])
2017-05-08 14:34:59,149 : INFO : torch.Size([3, 168])
2017-05-08 14:34:59,149 : INFO : torch.Size([3])
2017-05-08 14:34:59,150 : INFO : sum
2017-05-08 14:34:59,150 : INFO : 1220523
2017-05-08 14:34:59,150 : INFO : ____________
2017-05-08 14:45:56,053 : INFO : LOG_FILE
2017-05-08 14:45:56,053 : INFO : _________________________________start___________________________________
2017-05-08 14:45:56,060 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=150, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-08 14:45:56,265 : INFO : ==> SST vocabulary size : 21705
2017-05-08 14:45:56,265 : INFO : ==> SST rel vocabulary size : 48
2017-05-08 14:45:56,265 : INFO : ==> SST tag vocabulary size : 47
2017-05-08 14:46:02,596 : INFO : _param count_
2017-05-08 14:46:02,596 : INFO : torch.Size([450, 600])
2017-05-08 14:46:02,596 : INFO : torch.Size([450, 150])
2017-05-08 14:46:02,596 : INFO : torch.Size([450])
2017-05-08 14:46:02,596 : INFO : torch.Size([450])
2017-05-08 14:46:02,597 : INFO : torch.Size([150, 150])
2017-05-08 14:46:02,597 : INFO : torch.Size([150])
2017-05-08 14:46:02,597 : INFO : torch.Size([150, 1050])
2017-05-08 14:46:02,597 : INFO : torch.Size([150])
2017-05-08 14:46:02,597 : INFO : torch.Size([450, 1050])
2017-05-08 14:46:02,597 : INFO : torch.Size([450, 150])
2017-05-08 14:46:02,597 : INFO : torch.Size([450])
2017-05-08 14:46:02,598 : INFO : torch.Size([450])
2017-05-08 14:46:02,598 : INFO : torch.Size([3, 150])
2017-05-08 14:46:02,598 : INFO : torch.Size([3])
2017-05-08 14:46:02,598 : INFO : sum
2017-05-08 14:46:02,598 : INFO : 1060053
2017-05-08 14:46:02,598 : INFO : ____________
2017-05-08 14:46:13,721 : INFO : LOG_FILE
2017-05-08 14:46:13,722 : INFO : _________________________________start___________________________________
2017-05-08 14:46:13,728 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=150, num_classes=3, optim='adagrad', reg=0.0001, seed=123, wd=0)
2017-05-08 14:46:13,936 : INFO : ==> SST vocabulary size : 21705
2017-05-08 14:46:13,936 : INFO : ==> SST rel vocabulary size : 48
2017-05-08 14:46:13,937 : INFO : ==> SST tag vocabulary size : 47
2017-05-08 14:46:20,441 : INFO : _param count_
2017-05-08 14:46:20,441 : INFO : torch.Size([450, 600])
2017-05-08 14:46:20,441 : INFO : torch.Size([450, 150])
2017-05-08 14:46:20,442 : INFO : torch.Size([450])
2017-05-08 14:46:20,442 : INFO : torch.Size([450])
2017-05-08 14:46:20,442 : INFO : torch.Size([150, 150])
2017-05-08 14:46:20,442 : INFO : torch.Size([150])
2017-05-08 14:46:20,442 : INFO : torch.Size([150, 1050])
2017-05-08 14:46:20,442 : INFO : torch.Size([150])
2017-05-08 14:46:20,442 : INFO : torch.Size([450, 1050])
2017-05-08 14:46:20,443 : INFO : torch.Size([450, 150])
2017-05-08 14:46:20,443 : INFO : torch.Size([450])
2017-05-08 14:46:20,443 : INFO : torch.Size([450])
2017-05-08 14:46:20,443 : INFO : torch.Size([3, 150])
2017-05-08 14:46:20,443 : INFO : torch.Size([3])
2017-05-08 14:46:20,443 : INFO : sum
2017-05-08 14:46:20,443 : INFO : 1060053
2017-05-08 14:46:20,444 : INFO : ____________
2017-05-08 15:07:56,620 : INFO : ==> Train loss   : 0.751649
2017-05-08 15:07:56,620 : INFO : Epoch
2017-05-08 15:07:56,620 : INFO : 0
2017-05-08 15:07:56,620 : INFO : train percentage
2017-05-08 15:07:56,620 : INFO : 0.561560693642
2017-05-08 15:07:56,620 : INFO : Epoch
2017-05-08 15:07:56,620 : INFO : 0
2017-05-08 15:07:56,620 : INFO : dev percentage
2017-05-08 15:07:56,621 : INFO : 0.584862385321
2017-05-08 15:07:56,621 : INFO : Epoch
2017-05-08 15:07:56,621 : INFO : 0
2017-05-08 15:07:56,621 : INFO : test percentage
2017-05-08 15:07:56,621 : INFO : 0.562328390994
2017-05-08 15:19:10,154 : INFO : LOG_FILE
2017-05-08 15:19:10,154 : INFO : _________________________________start___________________________________
2017-05-08 15:19:10,160 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=150, num_classes=3, optim='adagrad', reg=0.0001, rel_dim=20, seed=123, tag_dim=20, wd=0, word_dim=300)
2017-05-08 15:19:10,366 : INFO : ==> SST vocabulary size : 21705
2017-05-08 15:19:10,366 : INFO : ==> SST rel vocabulary size : 48
2017-05-08 15:19:10,366 : INFO : ==> SST tag vocabulary size : 47
2017-05-08 15:19:17,050 : INFO : _param count_
2017-05-08 15:19:17,051 : INFO : torch.Size([450, 320])
2017-05-08 15:19:17,051 : INFO : torch.Size([450, 150])
2017-05-08 15:19:17,051 : INFO : torch.Size([450])
2017-05-08 15:19:17,051 : INFO : torch.Size([450])
2017-05-08 15:19:17,051 : INFO : torch.Size([150, 150])
2017-05-08 15:19:17,051 : INFO : torch.Size([150])
2017-05-08 15:19:17,051 : INFO : torch.Size([150, 490])
2017-05-08 15:19:17,052 : INFO : torch.Size([150])
2017-05-08 15:19:17,052 : INFO : torch.Size([450, 490])
2017-05-08 15:19:17,052 : INFO : torch.Size([450, 150])
2017-05-08 15:19:17,052 : INFO : torch.Size([450])
2017-05-08 15:19:17,052 : INFO : torch.Size([450])
2017-05-08 15:19:17,052 : INFO : torch.Size([3, 150])
2017-05-08 15:19:17,052 : INFO : torch.Size([3])
2017-05-08 15:19:17,052 : INFO : sum
2017-05-08 15:19:17,053 : INFO : 598053
2017-05-08 15:19:17,053 : INFO : ____________
2017-05-08 15:19:22,275 : INFO : LOG_FILE
2017-05-08 15:19:22,275 : INFO : _________________________________start___________________________________
2017-05-08 15:19:22,281 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=150, num_classes=3, optim='adagrad', reg=0.0001, rel_dim=20, seed=123, tag_dim=20, wd=0, word_dim=300)
2017-05-08 15:19:22,480 : INFO : ==> SST vocabulary size : 21705
2017-05-08 15:19:22,480 : INFO : ==> SST rel vocabulary size : 48
2017-05-08 15:19:22,480 : INFO : ==> SST tag vocabulary size : 47
2017-05-08 15:19:29,006 : INFO : _param count_
2017-05-08 15:19:29,006 : INFO : torch.Size([450, 320])
2017-05-08 15:19:29,006 : INFO : torch.Size([450, 150])
2017-05-08 15:19:29,006 : INFO : torch.Size([450])
2017-05-08 15:19:29,007 : INFO : torch.Size([450])
2017-05-08 15:19:29,007 : INFO : torch.Size([150, 150])
2017-05-08 15:19:29,007 : INFO : torch.Size([150])
2017-05-08 15:19:29,007 : INFO : torch.Size([150, 490])
2017-05-08 15:19:29,007 : INFO : torch.Size([150])
2017-05-08 15:19:29,007 : INFO : torch.Size([450, 490])
2017-05-08 15:19:29,007 : INFO : torch.Size([450, 150])
2017-05-08 15:19:29,008 : INFO : torch.Size([450])
2017-05-08 15:19:29,008 : INFO : torch.Size([450])
2017-05-08 15:19:29,008 : INFO : torch.Size([3, 150])
2017-05-08 15:19:29,008 : INFO : torch.Size([3])
2017-05-08 15:19:29,008 : INFO : sum
2017-05-08 15:19:29,008 : INFO : 598053
2017-05-08 15:19:29,008 : INFO : ____________
2017-05-08 15:19:51,846 : INFO : LOG_FILE
2017-05-08 15:19:51,847 : INFO : _________________________________start___________________________________
2017-05-08 15:19:51,860 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=150, num_classes=3, optim='adagrad', reg=0.0001, rel_dim=20, seed=123, tag_dim=20, wd=0, word_dim=300)
2017-05-08 15:19:52,264 : INFO : ==> SST vocabulary size : 21705
2017-05-08 15:19:52,265 : INFO : ==> SST rel vocabulary size : 48
2017-05-08 15:19:52,265 : INFO : ==> SST tag vocabulary size : 47
2017-05-08 15:20:00,587 : INFO : _param count_
2017-05-08 15:20:00,590 : INFO : torch.Size([450, 320])
2017-05-08 15:20:00,590 : INFO : torch.Size([450, 150])
2017-05-08 15:20:00,591 : INFO : torch.Size([450])
2017-05-08 15:20:00,591 : INFO : torch.Size([450])
2017-05-08 15:20:00,592 : INFO : torch.Size([150, 150])
2017-05-08 15:20:00,592 : INFO : torch.Size([150])
2017-05-08 15:20:00,593 : INFO : torch.Size([150, 490])
2017-05-08 15:20:00,594 : INFO : torch.Size([150])
2017-05-08 15:20:00,594 : INFO : torch.Size([450, 490])
2017-05-08 15:20:00,595 : INFO : torch.Size([450, 150])
2017-05-08 15:20:00,595 : INFO : torch.Size([450])
2017-05-08 15:20:00,596 : INFO : torch.Size([450])
2017-05-08 15:20:00,596 : INFO : torch.Size([3, 150])
2017-05-08 15:20:00,597 : INFO : torch.Size([3])
2017-05-08 15:20:00,597 : INFO : sum
2017-05-08 15:20:00,598 : INFO : 598053
2017-05-08 15:20:00,599 : INFO : ____________
2017-05-08 15:20:18,322 : INFO : LOG_FILE
2017-05-08 15:20:18,323 : INFO : _________________________________start___________________________________
2017-05-08 15:20:18,335 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=150, num_classes=3, optim='adagrad', reg=0.0001, rel_dim=20, seed=123, tag_dim=20, wd=0, word_dim=300)
2017-05-08 15:20:18,750 : INFO : ==> SST vocabulary size : 21705
2017-05-08 15:20:18,751 : INFO : ==> SST rel vocabulary size : 48
2017-05-08 15:20:18,752 : INFO : ==> SST tag vocabulary size : 47
2017-05-08 15:20:26,904 : INFO : _param count_
2017-05-08 15:20:26,906 : INFO : torch.Size([450, 320])
2017-05-08 15:20:26,907 : INFO : torch.Size([450, 150])
2017-05-08 15:20:26,908 : INFO : torch.Size([450])
2017-05-08 15:20:26,909 : INFO : torch.Size([450])
2017-05-08 15:20:26,909 : INFO : torch.Size([150, 150])
2017-05-08 15:20:26,910 : INFO : torch.Size([150])
2017-05-08 15:20:26,911 : INFO : torch.Size([150, 490])
2017-05-08 15:20:26,911 : INFO : torch.Size([150])
2017-05-08 15:20:26,912 : INFO : torch.Size([450, 490])
2017-05-08 15:20:26,912 : INFO : torch.Size([450, 150])
2017-05-08 15:20:26,913 : INFO : torch.Size([450])
2017-05-08 15:20:26,913 : INFO : torch.Size([450])
2017-05-08 15:20:26,914 : INFO : torch.Size([3, 150])
2017-05-08 15:20:26,915 : INFO : torch.Size([3])
2017-05-08 15:20:26,915 : INFO : sum
2017-05-08 15:20:26,916 : INFO : 598053
2017-05-08 15:20:26,916 : INFO : ____________
2017-05-08 15:21:50,135 : INFO : LOG_FILE
2017-05-08 15:21:50,135 : INFO : _________________________________start___________________________________
2017-05-08 15:21:50,141 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=150, num_classes=3, optim='adagrad', reg=0.0001, rel_dim=20, seed=123, tag_dim=20, wd=0, word_dim=300)
2017-05-08 15:21:50,344 : INFO : ==> SST vocabulary size : 21705
2017-05-08 15:21:50,344 : INFO : ==> SST rel vocabulary size : 48
2017-05-08 15:21:50,344 : INFO : ==> SST tag vocabulary size : 47
2017-05-08 15:21:56,991 : INFO : _param count_
2017-05-08 15:21:56,991 : INFO : torch.Size([450, 320])
2017-05-08 15:21:56,992 : INFO : torch.Size([450, 150])
2017-05-08 15:21:56,992 : INFO : torch.Size([450])
2017-05-08 15:21:56,992 : INFO : torch.Size([450])
2017-05-08 15:21:56,992 : INFO : torch.Size([150, 150])
2017-05-08 15:21:56,992 : INFO : torch.Size([150])
2017-05-08 15:21:56,993 : INFO : torch.Size([150, 490])
2017-05-08 15:21:56,993 : INFO : torch.Size([150])
2017-05-08 15:21:56,993 : INFO : torch.Size([450, 490])
2017-05-08 15:21:56,993 : INFO : torch.Size([450, 150])
2017-05-08 15:21:56,994 : INFO : torch.Size([450])
2017-05-08 15:21:56,994 : INFO : torch.Size([450])
2017-05-08 15:21:56,994 : INFO : torch.Size([3, 150])
2017-05-08 15:21:56,994 : INFO : torch.Size([3])
2017-05-08 15:21:56,994 : INFO : sum
2017-05-08 15:21:56,995 : INFO : 598053
2017-05-08 15:21:56,995 : INFO : ____________
2017-05-08 15:25:30,404 : INFO : LOG_FILE
2017-05-08 15:25:30,404 : INFO : _________________________________start___________________________________
2017-05-08 15:25:30,410 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=150, num_classes=3, optim='adagrad', reg=0.0001, rel_dim=20, seed=123, tag_dim=20, wd=0, word_dim=300)
2017-05-08 15:25:30,667 : INFO : ==> SST vocabulary size : 21705
2017-05-08 15:25:30,667 : INFO : ==> SST rel vocabulary size : 48
2017-05-08 15:25:30,667 : INFO : ==> SST tag vocabulary size : 47
2017-05-08 15:25:37,179 : INFO : _param count_
2017-05-08 15:25:37,179 : INFO : torch.Size([450, 320])
2017-05-08 15:25:37,179 : INFO : torch.Size([450, 150])
2017-05-08 15:25:37,179 : INFO : torch.Size([450])
2017-05-08 15:25:37,180 : INFO : torch.Size([450])
2017-05-08 15:25:37,180 : INFO : torch.Size([150, 150])
2017-05-08 15:25:37,180 : INFO : torch.Size([150])
2017-05-08 15:25:37,180 : INFO : torch.Size([150, 490])
2017-05-08 15:25:37,180 : INFO : torch.Size([150])
2017-05-08 15:25:37,180 : INFO : torch.Size([450, 490])
2017-05-08 15:25:37,181 : INFO : torch.Size([450, 150])
2017-05-08 15:25:37,181 : INFO : torch.Size([450])
2017-05-08 15:25:37,181 : INFO : torch.Size([450])
2017-05-08 15:25:37,181 : INFO : torch.Size([3, 150])
2017-05-08 15:25:37,181 : INFO : torch.Size([3])
2017-05-08 15:25:37,182 : INFO : sum
2017-05-08 15:25:37,182 : INFO : 598053
2017-05-08 15:25:37,182 : INFO : ____________
2017-05-08 15:29:19,722 : INFO : ==> Dev loss   : 0.661561
2017-05-08 15:29:19,723 : INFO : Epoch
2017-05-08 15:29:19,723 : INFO : 0
2017-05-08 15:29:19,723 : INFO : dev percentage
2017-05-08 15:29:19,723 : INFO : 0.692660550459
2017-05-08 15:30:14,469 : INFO : LOG_FILE
2017-05-08 15:30:14,469 : INFO : _________________________________start___________________________________
2017-05-08 15:30:14,475 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=150, num_classes=3, optim='adagrad', reg=0.0001, rel_dim=20, seed=123, tag_dim=20, wd=0, word_dim=300)
2017-05-08 15:30:14,682 : INFO : ==> SST vocabulary size : 21705
2017-05-08 15:30:14,682 : INFO : ==> SST rel vocabulary size : 48
2017-05-08 15:30:14,683 : INFO : ==> SST tag vocabulary size : 47
2017-05-08 15:30:21,043 : INFO : _param count_
2017-05-08 15:30:21,043 : INFO : torch.Size([450, 320])
2017-05-08 15:30:21,044 : INFO : torch.Size([450, 150])
2017-05-08 15:30:21,044 : INFO : torch.Size([450])
2017-05-08 15:30:21,044 : INFO : torch.Size([450])
2017-05-08 15:30:21,044 : INFO : torch.Size([150, 150])
2017-05-08 15:30:21,045 : INFO : torch.Size([150])
2017-05-08 15:30:21,045 : INFO : torch.Size([150, 490])
2017-05-08 15:30:21,045 : INFO : torch.Size([150])
2017-05-08 15:30:21,045 : INFO : torch.Size([450, 490])
2017-05-08 15:30:21,045 : INFO : torch.Size([450, 150])
2017-05-08 15:30:21,046 : INFO : torch.Size([450])
2017-05-08 15:30:21,046 : INFO : torch.Size([450])
2017-05-08 15:30:21,046 : INFO : torch.Size([3, 150])
2017-05-08 15:30:21,046 : INFO : torch.Size([3])
2017-05-08 15:30:21,047 : INFO : sum
2017-05-08 15:30:21,047 : INFO : 598053
2017-05-08 15:30:21,047 : INFO : ____________
2017-05-08 15:31:17,244 : INFO : LOG_FILE
2017-05-08 15:31:17,244 : INFO : _________________________________start___________________________________
2017-05-08 15:31:17,252 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=150, num_classes=3, optim='adagrad', reg=0.0001, rel_dim=20, seed=123, tag_dim=20, wd=0, word_dim=300)
2017-05-08 15:31:17,464 : INFO : ==> SST vocabulary size : 21705
2017-05-08 15:31:17,465 : INFO : ==> SST rel vocabulary size : 48
2017-05-08 15:31:17,465 : INFO : ==> SST tag vocabulary size : 47
2017-05-08 15:31:24,221 : INFO : _param count_
2017-05-08 15:31:24,221 : INFO : torch.Size([450, 320])
2017-05-08 15:31:24,222 : INFO : torch.Size([450, 150])
2017-05-08 15:31:24,222 : INFO : torch.Size([450])
2017-05-08 15:31:24,222 : INFO : torch.Size([450])
2017-05-08 15:31:24,222 : INFO : torch.Size([150, 150])
2017-05-08 15:31:24,222 : INFO : torch.Size([150])
2017-05-08 15:31:24,222 : INFO : torch.Size([150, 490])
2017-05-08 15:31:24,223 : INFO : torch.Size([150])
2017-05-08 15:31:24,223 : INFO : torch.Size([450, 490])
2017-05-08 15:31:24,223 : INFO : torch.Size([450, 150])
2017-05-08 15:31:24,223 : INFO : torch.Size([450])
2017-05-08 15:31:24,223 : INFO : torch.Size([450])
2017-05-08 15:31:24,223 : INFO : torch.Size([3, 150])
2017-05-08 15:31:24,224 : INFO : torch.Size([3])
2017-05-08 15:31:24,224 : INFO : sum
2017-05-08 15:31:24,224 : INFO : 598053
2017-05-08 15:31:24,224 : INFO : ____________
2017-05-08 15:32:43,376 : INFO : LOG_FILE
2017-05-08 15:32:43,376 : INFO : _________________________________start___________________________________
2017-05-08 15:32:43,389 : INFO : Namespace(batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=150, num_classes=3, optim='adagrad', reg=0.0001, rel_dim=20, seed=123, tag_dim=20, wd=0, word_dim=300)
2017-05-08 15:32:43,777 : INFO : ==> SST vocabulary size : 21705
2017-05-08 15:32:43,778 : INFO : ==> SST rel vocabulary size : 48
2017-05-08 15:32:43,778 : INFO : ==> SST tag vocabulary size : 47
2017-05-08 15:32:51,723 : INFO : _param count_
2017-05-08 15:32:51,726 : INFO : torch.Size([450, 320])
2017-05-08 15:32:51,726 : INFO : torch.Size([450, 150])
2017-05-08 15:32:51,727 : INFO : torch.Size([450])
2017-05-08 15:32:51,727 : INFO : torch.Size([450])
2017-05-08 15:32:51,728 : INFO : torch.Size([150, 150])
2017-05-08 15:32:51,728 : INFO : torch.Size([150])
2017-05-08 15:32:51,729 : INFO : torch.Size([150, 490])
2017-05-08 15:32:51,730 : INFO : torch.Size([150])
2017-05-08 15:32:51,730 : INFO : torch.Size([450, 490])
2017-05-08 15:32:51,731 : INFO : torch.Size([450, 150])
2017-05-08 15:32:51,731 : INFO : torch.Size([450])
2017-05-08 15:32:51,732 : INFO : torch.Size([450])
2017-05-08 15:32:51,732 : INFO : torch.Size([3, 150])
2017-05-08 15:32:51,733 : INFO : torch.Size([3])
2017-05-08 15:32:51,733 : INFO : sum
2017-05-08 15:32:51,734 : INFO : 598053
2017-05-08 15:32:51,734 : INFO : ____________
2017-05-08 15:48:02,421 : INFO : LOG_FILE
2017-05-08 15:48:02,422 : INFO : _________________________________start___________________________________
2017-05-08 15:48:02,428 : INFO : Namespace(at_hid_dim=100, batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=150, num_classes=3, optim='adagrad', reg=0.0001, rel_dim=20, seed=123, tag_dim=20, wd=0, word_dim=300)
2017-05-08 15:48:02,628 : INFO : ==> SST vocabulary size : 21705
2017-05-08 15:48:02,628 : INFO : ==> SST rel vocabulary size : 48
2017-05-08 15:48:02,628 : INFO : ==> SST tag vocabulary size : 47
2017-05-08 15:48:30,542 : INFO : LOG_FILE
2017-05-08 15:48:30,543 : INFO : _________________________________start___________________________________
2017-05-08 15:48:30,549 : INFO : Namespace(at_hid_dim=100, batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=150, num_classes=3, optim='adagrad', reg=0.0001, rel_dim=20, seed=123, tag_dim=20, wd=0, word_dim=300)
2017-05-08 15:48:30,752 : INFO : ==> SST vocabulary size : 21705
2017-05-08 15:48:30,753 : INFO : ==> SST rel vocabulary size : 48
2017-05-08 15:48:30,753 : INFO : ==> SST tag vocabulary size : 47
2017-05-08 15:48:37,256 : INFO : _param count_
2017-05-08 15:48:37,256 : INFO : torch.Size([450, 320])
2017-05-08 15:48:37,256 : INFO : torch.Size([450, 150])
2017-05-08 15:48:37,256 : INFO : torch.Size([450])
2017-05-08 15:48:37,256 : INFO : torch.Size([450])
2017-05-08 15:48:37,257 : INFO : torch.Size([1, 150])
2017-05-08 15:48:37,257 : INFO : torch.Size([1])
2017-05-08 15:48:37,257 : INFO : torch.Size([150, 490])
2017-05-08 15:48:37,257 : INFO : torch.Size([150])
2017-05-08 15:48:37,257 : INFO : torch.Size([450, 490])
2017-05-08 15:48:37,257 : INFO : torch.Size([450, 150])
2017-05-08 15:48:37,257 : INFO : torch.Size([450])
2017-05-08 15:48:37,257 : INFO : torch.Size([450])
2017-05-08 15:48:37,258 : INFO : torch.Size([3, 150])
2017-05-08 15:48:37,258 : INFO : torch.Size([3])
2017-05-08 15:48:37,258 : INFO : sum
2017-05-08 15:48:37,258 : INFO : 575554
2017-05-08 15:48:37,258 : INFO : ____________
2017-05-08 15:48:46,493 : INFO : LOG_FILE
2017-05-08 15:48:46,494 : INFO : _________________________________start___________________________________
2017-05-08 15:48:46,507 : INFO : Namespace(at_hid_dim=100, batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=150, num_classes=3, optim='adagrad', reg=0.0001, rel_dim=20, seed=123, tag_dim=20, wd=0, word_dim=300)
2017-05-08 15:48:46,904 : INFO : ==> SST vocabulary size : 21705
2017-05-08 15:48:46,904 : INFO : ==> SST rel vocabulary size : 48
2017-05-08 15:48:46,905 : INFO : ==> SST tag vocabulary size : 47
2017-05-08 15:48:54,877 : INFO : _param count_
2017-05-08 15:48:54,880 : INFO : torch.Size([450, 320])
2017-05-08 15:48:54,881 : INFO : torch.Size([450, 150])
2017-05-08 15:48:54,882 : INFO : torch.Size([450])
2017-05-08 15:48:54,883 : INFO : torch.Size([450])
2017-05-08 15:48:54,884 : INFO : torch.Size([1, 150])
2017-05-08 15:48:54,885 : INFO : torch.Size([1])
2017-05-08 15:48:54,886 : INFO : torch.Size([150, 490])
2017-05-08 15:48:54,887 : INFO : torch.Size([150])
2017-05-08 15:48:54,888 : INFO : torch.Size([450, 490])
2017-05-08 15:48:54,889 : INFO : torch.Size([450, 150])
2017-05-08 15:48:54,890 : INFO : torch.Size([450])
2017-05-08 15:48:54,891 : INFO : torch.Size([450])
2017-05-08 15:48:54,892 : INFO : torch.Size([3, 150])
2017-05-08 15:48:54,893 : INFO : torch.Size([3])
2017-05-08 15:48:54,894 : INFO : sum
2017-05-08 15:48:54,895 : INFO : 575554
2017-05-08 15:48:54,896 : INFO : ____________
2017-05-08 15:52:54,455 : INFO : ==> Train loss   : 0.502687
2017-05-08 15:52:54,455 : INFO : Epoch
2017-05-08 15:52:54,457 : INFO : 0
2017-05-08 15:52:54,457 : INFO : train percentage
2017-05-08 15:52:54,457 : INFO : 0.816040462428
2017-05-08 15:52:54,458 : INFO : Epoch
2017-05-08 15:52:54,458 : INFO : 0
2017-05-08 15:52:54,458 : INFO : dev percentage
2017-05-08 15:52:54,458 : INFO : 0.807339449541
2017-05-08 15:52:54,458 : INFO : Epoch
2017-05-08 15:52:54,458 : INFO : 0
2017-05-08 15:52:54,458 : INFO : test percentage
2017-05-08 15:52:54,458 : INFO : 0.791323448655
2017-05-08 16:05:54,059 : INFO : LOG_FILE
2017-05-08 16:05:54,059 : INFO : _________________________________start___________________________________
2017-05-08 16:05:54,072 : INFO : Namespace(at_hid_dim=100, batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=150, num_classes=3, optim='adagrad', reg=0.0001, rel_dim=20, seed=123, tag_dim=20, wd=0, word_dim=300)
2017-05-08 16:05:54,465 : INFO : ==> SST vocabulary size : 21705
2017-05-08 16:05:54,466 : INFO : ==> SST rel vocabulary size : 48
2017-05-08 16:05:54,466 : INFO : ==> SST tag vocabulary size : 47
2017-05-08 16:06:02,393 : INFO : _param count_
2017-05-08 16:06:02,395 : INFO : torch.Size([450, 320])
2017-05-08 16:06:02,396 : INFO : torch.Size([450, 150])
2017-05-08 16:06:02,397 : INFO : torch.Size([450])
2017-05-08 16:06:02,397 : INFO : torch.Size([450])
2017-05-08 16:06:02,398 : INFO : torch.Size([1, 150])
2017-05-08 16:06:02,398 : INFO : torch.Size([1])
2017-05-08 16:06:02,399 : INFO : torch.Size([150, 490])
2017-05-08 16:06:02,399 : INFO : torch.Size([150])
2017-05-08 16:06:02,400 : INFO : torch.Size([450, 490])
2017-05-08 16:06:02,401 : INFO : torch.Size([450, 150])
2017-05-08 16:06:02,401 : INFO : torch.Size([450])
2017-05-08 16:06:02,402 : INFO : torch.Size([450])
2017-05-08 16:06:02,402 : INFO : torch.Size([3, 150])
2017-05-08 16:06:02,403 : INFO : torch.Size([3])
2017-05-08 16:06:02,403 : INFO : sum
2017-05-08 16:06:02,404 : INFO : 575554
2017-05-08 16:06:02,404 : INFO : ____________
2017-05-08 16:06:53,282 : INFO : LOG_FILE
2017-05-08 16:06:53,282 : INFO : _________________________________start___________________________________
2017-05-08 16:06:53,288 : INFO : Namespace(at_hid_dim=100, batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=150, num_classes=3, optim='adagrad', reg=0.0001, rel_dim=20, seed=123, tag_dim=20, wd=0, word_dim=300)
2017-05-08 16:06:53,492 : INFO : ==> SST vocabulary size : 21705
2017-05-08 16:06:53,492 : INFO : ==> SST rel vocabulary size : 48
2017-05-08 16:06:53,492 : INFO : ==> SST tag vocabulary size : 47
2017-05-08 16:07:00,025 : INFO : _param count_
2017-05-08 16:07:00,026 : INFO : torch.Size([450, 320])
2017-05-08 16:07:00,026 : INFO : torch.Size([450, 150])
2017-05-08 16:07:00,026 : INFO : torch.Size([450])
2017-05-08 16:07:00,027 : INFO : torch.Size([450])
2017-05-08 16:07:00,027 : INFO : torch.Size([1, 150])
2017-05-08 16:07:00,027 : INFO : torch.Size([1])
2017-05-08 16:07:00,027 : INFO : torch.Size([150, 490])
2017-05-08 16:07:00,027 : INFO : torch.Size([150])
2017-05-08 16:07:00,028 : INFO : torch.Size([450, 490])
2017-05-08 16:07:00,028 : INFO : torch.Size([450, 150])
2017-05-08 16:07:00,028 : INFO : torch.Size([450])
2017-05-08 16:07:00,028 : INFO : torch.Size([450])
2017-05-08 16:07:00,028 : INFO : torch.Size([3, 150])
2017-05-08 16:07:00,029 : INFO : torch.Size([3])
2017-05-08 16:07:00,029 : INFO : sum
2017-05-08 16:07:00,029 : INFO : 575554
2017-05-08 16:07:00,029 : INFO : ____________
2017-05-08 16:09:40,897 : INFO : LOG_FILE
2017-05-08 16:09:40,897 : INFO : _________________________________start___________________________________
2017-05-08 16:09:40,903 : INFO : Namespace(at_hid_dim=100, batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=150, num_classes=3, optim='adagrad', reg=0.0001, rel_dim=20, seed=123, tag_dim=20, wd=0, word_dim=300)
2017-05-08 16:09:41,105 : INFO : ==> SST vocabulary size : 21705
2017-05-08 16:09:41,105 : INFO : ==> SST rel vocabulary size : 48
2017-05-08 16:09:41,105 : INFO : ==> SST tag vocabulary size : 47
2017-05-08 16:09:47,677 : INFO : _param count_
2017-05-08 16:09:47,677 : INFO : torch.Size([450, 320])
2017-05-08 16:09:47,678 : INFO : torch.Size([450, 150])
2017-05-08 16:09:47,678 : INFO : torch.Size([450])
2017-05-08 16:09:47,678 : INFO : torch.Size([450])
2017-05-08 16:09:47,678 : INFO : torch.Size([1, 100])
2017-05-08 16:09:47,678 : INFO : torch.Size([1])
2017-05-08 16:09:47,678 : INFO : torch.Size([100, 490])
2017-05-08 16:09:47,678 : INFO : torch.Size([100])
2017-05-08 16:09:47,678 : INFO : torch.Size([450, 490])
2017-05-08 16:09:47,679 : INFO : torch.Size([450, 150])
2017-05-08 16:09:47,679 : INFO : torch.Size([450])
2017-05-08 16:09:47,679 : INFO : torch.Size([450])
2017-05-08 16:09:47,679 : INFO : torch.Size([3, 150])
2017-05-08 16:09:47,679 : INFO : torch.Size([3])
2017-05-08 16:09:47,679 : INFO : sum
2017-05-08 16:09:47,679 : INFO : 550954
2017-05-08 16:09:47,679 : INFO : ____________
2017-05-08 16:15:40,049 : INFO : LOG_FILE
2017-05-08 16:15:40,050 : INFO : _________________________________start___________________________________
2017-05-08 16:15:40,064 : INFO : Namespace(at_hid_dim=100, batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=150, num_classes=3, optim='adagrad', reg=0.0001, rel_dim=20, seed=123, tag_dim=20, wd=0, word_dim=300)
2017-05-08 16:15:40,477 : INFO : ==> SST vocabulary size : 21705
2017-05-08 16:15:40,477 : INFO : ==> SST rel vocabulary size : 48
2017-05-08 16:15:40,478 : INFO : ==> SST tag vocabulary size : 47
2017-05-08 16:15:48,675 : INFO : _param count_
2017-05-08 16:15:48,677 : INFO : torch.Size([450, 320])
2017-05-08 16:15:48,678 : INFO : torch.Size([450, 150])
2017-05-08 16:15:48,679 : INFO : torch.Size([450])
2017-05-08 16:15:48,680 : INFO : torch.Size([450])
2017-05-08 16:15:48,680 : INFO : torch.Size([1, 100])
2017-05-08 16:15:48,681 : INFO : torch.Size([1])
2017-05-08 16:15:48,681 : INFO : torch.Size([100, 490])
2017-05-08 16:15:48,682 : INFO : torch.Size([100])
2017-05-08 16:15:48,683 : INFO : torch.Size([450, 490])
2017-05-08 16:15:48,684 : INFO : torch.Size([450, 150])
2017-05-08 16:15:48,685 : INFO : torch.Size([450])
2017-05-08 16:15:48,686 : INFO : torch.Size([450])
2017-05-08 16:15:48,687 : INFO : torch.Size([3, 150])
2017-05-08 16:15:48,688 : INFO : torch.Size([3])
2017-05-08 16:15:48,689 : INFO : sum
2017-05-08 16:15:48,690 : INFO : 550954
2017-05-08 16:15:48,691 : INFO : ____________
2017-05-08 16:26:13,496 : INFO : ==> Train loss   : 0.369783
2017-05-08 16:26:13,496 : INFO : Epoch
2017-05-08 16:26:13,496 : INFO : 1
2017-05-08 16:26:13,496 : INFO : train percentage
2017-05-08 16:26:13,496 : INFO : 0.868208092486
2017-05-08 16:26:13,496 : INFO : Epoch
2017-05-08 16:26:13,496 : INFO : 1
2017-05-08 16:26:13,496 : INFO : dev percentage
2017-05-08 16:26:13,497 : INFO : 0.822247706422
2017-05-08 16:26:13,497 : INFO : Epoch
2017-05-08 16:26:13,497 : INFO : 1
2017-05-08 16:26:13,497 : INFO : test percentage
2017-05-08 16:26:13,497 : INFO : 0.809445359692
2017-05-08 16:30:04,891 : INFO : LOG_FILE
2017-05-08 16:30:04,892 : INFO : _________________________________start___________________________________
2017-05-08 16:30:04,898 : INFO : Namespace(at_hid_dim=100, batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=150, num_classes=3, optim='adagrad', reg=0.0001, rel_dim=20, seed=123, tag_dim=20, wd=0, word_dim=300)
2017-05-08 16:30:05,093 : INFO : ==> SST vocabulary size : 21705
2017-05-08 16:30:05,093 : INFO : ==> SST rel vocabulary size : 48
2017-05-08 16:30:05,094 : INFO : ==> SST tag vocabulary size : 47
2017-05-08 16:30:11,413 : INFO : _param count_
2017-05-08 16:30:11,413 : INFO : torch.Size([450, 320])
2017-05-08 16:30:11,413 : INFO : torch.Size([450, 150])
2017-05-08 16:30:11,413 : INFO : torch.Size([450])
2017-05-08 16:30:11,413 : INFO : torch.Size([450])
2017-05-08 16:30:11,414 : INFO : torch.Size([1, 100])
2017-05-08 16:30:11,414 : INFO : torch.Size([1])
2017-05-08 16:30:11,414 : INFO : torch.Size([100, 490])
2017-05-08 16:30:11,414 : INFO : torch.Size([100])
2017-05-08 16:30:11,414 : INFO : torch.Size([450, 490])
2017-05-08 16:30:11,414 : INFO : torch.Size([450, 150])
2017-05-08 16:30:11,415 : INFO : torch.Size([450])
2017-05-08 16:30:11,415 : INFO : torch.Size([450])
2017-05-08 16:30:11,415 : INFO : torch.Size([3, 150])
2017-05-08 16:30:11,415 : INFO : torch.Size([3])
2017-05-08 16:30:11,415 : INFO : sum
2017-05-08 16:30:11,415 : INFO : 550954
2017-05-08 16:30:11,415 : INFO : ____________
2017-05-08 16:33:45,899 : INFO : ==> Dev loss   : 1.130584
2017-05-08 16:33:45,900 : INFO : Epoch
2017-05-08 16:33:45,900 : INFO : 0
2017-05-08 16:33:45,900 : INFO : dev percentage
2017-05-08 16:33:45,900 : INFO : 0.524082568807
2017-05-08 16:35:34,917 : INFO : LOG_FILE
2017-05-08 16:35:34,917 : INFO : _________________________________start___________________________________
2017-05-08 16:35:34,924 : INFO : Namespace(at_hid_dim=100, batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=150, num_classes=3, optim='adagrad', reg=0.0001, rel_dim=20, seed=123, tag_dim=20, wd=0, word_dim=300)
2017-05-08 16:35:35,130 : INFO : ==> SST vocabulary size : 21705
2017-05-08 16:35:35,130 : INFO : ==> SST rel vocabulary size : 48
2017-05-08 16:35:35,130 : INFO : ==> SST tag vocabulary size : 47
2017-05-08 16:35:41,635 : INFO : _param count_
2017-05-08 16:35:41,636 : INFO : torch.Size([450, 320])
2017-05-08 16:35:41,636 : INFO : torch.Size([450, 150])
2017-05-08 16:35:41,636 : INFO : torch.Size([450])
2017-05-08 16:35:41,636 : INFO : torch.Size([450])
2017-05-08 16:35:41,637 : INFO : torch.Size([1, 100])
2017-05-08 16:35:41,637 : INFO : torch.Size([1])
2017-05-08 16:35:41,637 : INFO : torch.Size([100, 490])
2017-05-08 16:35:41,637 : INFO : torch.Size([100])
2017-05-08 16:35:41,637 : INFO : torch.Size([450, 490])
2017-05-08 16:35:41,638 : INFO : torch.Size([450, 150])
2017-05-08 16:35:41,638 : INFO : torch.Size([450])
2017-05-08 16:35:41,638 : INFO : torch.Size([450])
2017-05-08 16:35:41,638 : INFO : torch.Size([3, 150])
2017-05-08 16:35:41,638 : INFO : torch.Size([3])
2017-05-08 16:35:41,639 : INFO : sum
2017-05-08 16:35:41,639 : INFO : 550954
2017-05-08 16:35:41,639 : INFO : ____________
2017-05-08 16:57:25,878 : INFO : ==> Train loss   : 0.582989
2017-05-08 16:57:25,878 : INFO : Epoch
2017-05-08 16:57:25,879 : INFO : 0
2017-05-08 16:57:25,879 : INFO : train percentage
2017-05-08 16:57:25,879 : INFO : 0.728468208092
2017-05-08 16:57:25,879 : INFO : Epoch
2017-05-08 16:57:25,879 : INFO : 0
2017-05-08 16:57:25,879 : INFO : dev percentage
2017-05-08 16:57:25,879 : INFO : 0.70871559633
2017-05-08 16:57:25,879 : INFO : Epoch
2017-05-08 16:57:25,879 : INFO : 0
2017-05-08 16:57:25,880 : INFO : test percentage
2017-05-08 16:57:25,880 : INFO : 0.699615595826
2017-05-08 17:30:32,606 : INFO : ==> Train loss   : 0.397866
2017-05-08 17:30:32,606 : INFO : Epoch
2017-05-08 17:30:32,606 : INFO : 1
2017-05-08 17:30:32,606 : INFO : train percentage
2017-05-08 17:30:32,606 : INFO : 0.848988439306
2017-05-08 17:30:32,607 : INFO : Epoch
2017-05-08 17:30:32,607 : INFO : 1
2017-05-08 17:30:32,607 : INFO : dev percentage
2017-05-08 17:30:32,607 : INFO : 0.808486238532
2017-05-08 17:30:32,607 : INFO : Epoch
2017-05-08 17:30:32,607 : INFO : 1
2017-05-08 17:30:32,607 : INFO : test percentage
2017-05-08 17:30:32,608 : INFO : 0.800109829764
2017-05-08 17:41:27,108 : INFO : LOG_FILE
2017-05-08 17:41:27,109 : INFO : _________________________________start___________________________________
2017-05-08 17:41:27,122 : INFO : Namespace(at_hid_dim=100, batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=150, num_classes=3, optim='adagrad', reg=0.0001, rel_dim=20, seed=123, tag_dim=20, wd=0, word_dim=300)
2017-05-08 17:41:27,534 : INFO : ==> SST vocabulary size : 21705
2017-05-08 17:41:27,535 : INFO : ==> SST rel vocabulary size : 48
2017-05-08 17:41:27,535 : INFO : ==> SST tag vocabulary size : 47
2017-05-08 17:42:05,885 : INFO : _param count_
2017-05-08 17:42:05,887 : INFO : torch.Size([450, 320])
2017-05-08 17:42:05,887 : INFO : torch.Size([450, 150])
2017-05-08 17:42:05,888 : INFO : torch.Size([450])
2017-05-08 17:42:05,889 : INFO : torch.Size([450])
2017-05-08 17:42:05,889 : INFO : torch.Size([1, 100])
2017-05-08 17:42:05,890 : INFO : torch.Size([1])
2017-05-08 17:42:05,890 : INFO : torch.Size([100, 490])
2017-05-08 17:42:05,891 : INFO : torch.Size([100])
2017-05-08 17:42:05,892 : INFO : torch.Size([450, 490])
2017-05-08 17:42:05,892 : INFO : torch.Size([450, 150])
2017-05-08 17:42:05,893 : INFO : torch.Size([450])
2017-05-08 17:42:05,893 : INFO : torch.Size([450])
2017-05-08 17:42:05,894 : INFO : torch.Size([3, 150])
2017-05-08 17:42:05,894 : INFO : torch.Size([3])
2017-05-08 17:42:05,895 : INFO : sum
2017-05-08 17:42:05,895 : INFO : 550954
2017-05-08 17:42:05,896 : INFO : ____________
2017-05-08 17:46:15,646 : INFO : LOG_FILE
2017-05-08 17:46:15,646 : INFO : _________________________________start___________________________________
2017-05-08 17:46:15,660 : INFO : Namespace(at_hid_dim=100, batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=150, num_classes=3, optim='adagrad', reg=0.0001, rel_dim=20, seed=123, tag_dim=20, wd=0, word_dim=300)
2017-05-08 17:46:16,069 : INFO : ==> SST vocabulary size : 21705
2017-05-08 17:46:16,069 : INFO : ==> SST rel vocabulary size : 48
2017-05-08 17:46:16,070 : INFO : ==> SST tag vocabulary size : 47
2017-05-08 17:46:27,119 : INFO : _param count_
2017-05-08 17:46:27,122 : INFO : torch.Size([450, 320])
2017-05-08 17:46:27,122 : INFO : torch.Size([450, 150])
2017-05-08 17:46:27,123 : INFO : torch.Size([450])
2017-05-08 17:46:27,124 : INFO : torch.Size([450])
2017-05-08 17:46:27,124 : INFO : torch.Size([1, 100])
2017-05-08 17:46:27,125 : INFO : torch.Size([1])
2017-05-08 17:46:27,125 : INFO : torch.Size([100, 490])
2017-05-08 17:46:27,126 : INFO : torch.Size([100])
2017-05-08 17:46:27,126 : INFO : torch.Size([450, 490])
2017-05-08 17:46:27,127 : INFO : torch.Size([450, 150])
2017-05-08 17:46:27,128 : INFO : torch.Size([450])
2017-05-08 17:46:27,128 : INFO : torch.Size([450])
2017-05-08 17:46:27,129 : INFO : torch.Size([3, 150])
2017-05-08 17:46:27,129 : INFO : torch.Size([3])
2017-05-08 17:46:27,130 : INFO : sum
2017-05-08 17:46:27,130 : INFO : 550954
2017-05-08 17:46:27,131 : INFO : ____________
2017-05-08 18:15:45,362 : INFO : ==> Train loss   : 0.273075
2017-05-08 18:15:45,362 : INFO : Epoch
2017-05-08 18:15:45,362 : INFO : 2
2017-05-08 18:15:45,362 : INFO : train percentage
2017-05-08 18:15:45,362 : INFO : 0.906936416185
2017-05-08 18:15:45,363 : INFO : Epoch
2017-05-08 18:15:45,363 : INFO : 2
2017-05-08 18:15:45,363 : INFO : dev percentage
2017-05-08 18:15:45,363 : INFO : 0.815366972477
2017-05-08 18:15:45,363 : INFO : Epoch
2017-05-08 18:15:45,363 : INFO : 2
2017-05-08 18:15:45,363 : INFO : test percentage
2017-05-08 18:15:45,363 : INFO : 0.81109280615
2017-05-08 19:10:34,275 : INFO : ==> Train loss   : 0.212030
2017-05-08 19:10:34,275 : INFO : Epoch
2017-05-08 19:10:34,275 : INFO : 3
2017-05-08 19:10:34,275 : INFO : train percentage
2017-05-08 19:10:34,275 : INFO : 0.93323699422
2017-05-08 19:10:34,275 : INFO : Epoch
2017-05-08 19:10:34,276 : INFO : 3
2017-05-08 19:10:34,276 : INFO : dev percentage
2017-05-08 19:10:34,276 : INFO : 0.81880733945
2017-05-08 19:10:34,276 : INFO : Epoch
2017-05-08 19:10:34,276 : INFO : 3
2017-05-08 19:10:34,276 : INFO : test percentage
2017-05-08 19:10:34,276 : INFO : 0.817682591982
2017-05-08 20:14:57,632 : INFO : ==> Train loss   : 0.158876
2017-05-08 20:14:57,632 : INFO : Epoch
2017-05-08 20:14:57,632 : INFO : 4
2017-05-08 20:14:57,632 : INFO : train percentage
2017-05-08 20:14:57,632 : INFO : 0.948843930636
2017-05-08 20:14:57,633 : INFO : Epoch
2017-05-08 20:14:57,633 : INFO : 4
2017-05-08 20:14:57,633 : INFO : dev percentage
2017-05-08 20:14:57,633 : INFO : 0.817660550459
2017-05-08 20:14:57,633 : INFO : Epoch
2017-05-08 20:14:57,633 : INFO : 4
2017-05-08 20:14:57,633 : INFO : test percentage
2017-05-08 20:14:57,633 : INFO : 0.818780889621
2017-05-08 21:29:38,576 : INFO : ==> Train loss   : 0.114238
2017-05-08 21:29:38,576 : INFO : Epoch
2017-05-08 21:29:38,576 : INFO : 5
2017-05-08 21:29:38,576 : INFO : train percentage
2017-05-08 21:29:38,576 : INFO : 0.967630057803
2017-05-08 21:29:38,577 : INFO : Epoch
2017-05-08 21:29:38,577 : INFO : 5
2017-05-08 21:29:38,577 : INFO : dev percentage
2017-05-08 21:29:38,577 : INFO : 0.81880733945
2017-05-08 21:29:38,577 : INFO : Epoch
2017-05-08 21:29:38,577 : INFO : 5
2017-05-08 21:29:38,577 : INFO : test percentage
2017-05-08 21:29:38,577 : INFO : 0.817682591982
2017-05-08 23:08:46,429 : INFO : ==> Train loss   : 0.098214
2017-05-08 23:08:46,430 : INFO : Epoch
2017-05-08 23:08:46,430 : INFO : 6
2017-05-08 23:08:46,430 : INFO : train percentage
2017-05-08 23:08:46,430 : INFO : 0.97225433526
2017-05-08 23:08:46,430 : INFO : Epoch
2017-05-08 23:08:46,431 : INFO : 6
2017-05-08 23:08:46,431 : INFO : dev percentage
2017-05-08 23:08:46,431 : INFO : 0.792431192661
2017-05-08 23:08:46,431 : INFO : Epoch
2017-05-08 23:08:46,431 : INFO : 6
2017-05-08 23:08:46,431 : INFO : test percentage
2017-05-08 23:08:46,431 : INFO : 0.809994508512
2017-05-09 00:58:26,543 : INFO : ==> Train loss   : 0.072699
2017-05-09 00:58:26,543 : INFO : Epoch
2017-05-09 00:58:26,543 : INFO : 7
2017-05-09 00:58:26,543 : INFO : train percentage
2017-05-09 00:58:26,543 : INFO : 0.976734104046
2017-05-09 00:58:26,543 : INFO : Epoch
2017-05-09 00:58:26,544 : INFO : 7
2017-05-09 00:58:26,544 : INFO : dev percentage
2017-05-09 00:58:26,544 : INFO : 0.801605504587
2017-05-09 00:58:26,544 : INFO : Epoch
2017-05-09 00:58:26,544 : INFO : 7
2017-05-09 00:58:26,544 : INFO : test percentage
2017-05-09 00:58:26,544 : INFO : 0.808896210873
2017-05-09 03:00:02,309 : INFO : ==> Train loss   : 0.059523
2017-05-09 03:00:02,310 : INFO : Epoch
2017-05-09 03:00:02,310 : INFO : 8
2017-05-09 03:00:02,310 : INFO : train percentage
2017-05-09 03:00:02,310 : INFO : 0.982947976879
2017-05-09 03:00:02,310 : INFO : Epoch
2017-05-09 03:00:02,310 : INFO : 8
2017-05-09 03:00:02,310 : INFO : dev percentage
2017-05-09 03:00:02,310 : INFO : 0.799311926606
2017-05-09 03:00:02,310 : INFO : Epoch
2017-05-09 03:00:02,311 : INFO : 8
2017-05-09 03:00:02,311 : INFO : test percentage
2017-05-09 03:00:02,311 : INFO : 0.803953871499
2017-05-09 05:11:10,846 : INFO : ==> Train loss   : 0.043180
2017-05-09 05:11:10,846 : INFO : Epoch
2017-05-09 05:11:10,846 : INFO : 9
2017-05-09 05:11:10,846 : INFO : train percentage
2017-05-09 05:11:10,846 : INFO : 0.987716763006
2017-05-09 05:11:10,846 : INFO : Epoch
2017-05-09 05:11:10,847 : INFO : 9
2017-05-09 05:11:10,847 : INFO : dev percentage
2017-05-09 05:11:10,847 : INFO : 0.807339449541
2017-05-09 05:11:10,847 : INFO : Epoch
2017-05-09 05:11:10,847 : INFO : 9
2017-05-09 05:11:10,847 : INFO : test percentage
2017-05-09 05:11:10,847 : INFO : 0.807248764415
2017-05-09 07:34:53,593 : INFO : ==> Train loss   : 0.035552
2017-05-09 07:34:53,594 : INFO : Epoch
2017-05-09 07:34:53,594 : INFO : 10
2017-05-09 07:34:53,594 : INFO : train percentage
2017-05-09 07:34:53,594 : INFO : 0.990317919075
2017-05-09 07:34:53,594 : INFO : Epoch
2017-05-09 07:34:53,594 : INFO : 10
2017-05-09 07:34:53,594 : INFO : dev percentage
2017-05-09 07:34:53,594 : INFO : 0.793577981651
2017-05-09 07:34:53,595 : INFO : Epoch
2017-05-09 07:34:53,595 : INFO : 10
2017-05-09 07:34:53,595 : INFO : test percentage
2017-05-09 07:34:53,595 : INFO : 0.801757276222
2017-05-09 10:21:41,283 : INFO : ==> Train loss   : 0.035803
2017-05-09 10:21:41,283 : INFO : Epoch
2017-05-09 10:21:41,283 : INFO : 11
2017-05-09 10:21:41,283 : INFO : train percentage
2017-05-09 10:21:41,283 : INFO : 0.99176300578
2017-05-09 10:21:41,283 : INFO : Epoch
2017-05-09 10:21:41,284 : INFO : 11
2017-05-09 10:21:41,284 : INFO : dev percentage
2017-05-09 10:21:41,284 : INFO : 0.786697247706
2017-05-09 10:21:41,284 : INFO : Epoch
2017-05-09 10:21:41,284 : INFO : 11
2017-05-09 10:21:41,284 : INFO : test percentage
2017-05-09 10:21:41,284 : INFO : 0.793520043932
2017-05-09 13:29:41,274 : INFO : ==> Train loss   : 0.023059
2017-05-09 13:29:41,274 : INFO : Epoch
2017-05-09 13:29:41,275 : INFO : 12
2017-05-09 13:29:41,275 : INFO : train percentage
2017-05-09 13:29:41,275 : INFO : 0.994653179191
2017-05-09 13:29:41,275 : INFO : Epoch
2017-05-09 13:29:41,275 : INFO : 12
2017-05-09 13:29:41,275 : INFO : dev percentage
2017-05-09 13:29:41,275 : INFO : 0.798165137615
2017-05-09 13:29:41,275 : INFO : Epoch
2017-05-09 13:29:41,276 : INFO : 12
2017-05-09 13:29:41,276 : INFO : test percentage
2017-05-09 13:29:41,276 : INFO : 0.794069192751
2017-05-09 16:39:21,723 : INFO : LOG_FILE
2017-05-09 16:39:21,723 : INFO : _________________________________start___________________________________
2017-05-09 16:39:21,729 : INFO : Namespace(at_hid_dim=100, batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=150, num_classes=3, optim='adagrad', reg=0.0001, rel_dim=20, seed=123, tag_dim=20, wd=0, word_dim=300)
2017-05-09 16:39:21,953 : INFO : ==> SST vocabulary size : 21705
2017-05-09 16:39:21,953 : INFO : ==> SST rel vocabulary size : 48
2017-05-09 16:39:21,953 : INFO : ==> SST tag vocabulary size : 47
2017-05-09 16:39:28,406 : INFO : _param count_
2017-05-09 16:39:28,407 : INFO : torch.Size([450, 320])
2017-05-09 16:39:28,407 : INFO : torch.Size([450, 150])
2017-05-09 16:39:28,407 : INFO : torch.Size([450])
2017-05-09 16:39:28,407 : INFO : torch.Size([450])
2017-05-09 16:39:28,407 : INFO : torch.Size([1, 100])
2017-05-09 16:39:28,408 : INFO : torch.Size([1])
2017-05-09 16:39:28,408 : INFO : torch.Size([100, 490])
2017-05-09 16:39:28,408 : INFO : torch.Size([100])
2017-05-09 16:39:28,408 : INFO : torch.Size([450, 490])
2017-05-09 16:39:28,409 : INFO : torch.Size([450, 150])
2017-05-09 16:39:28,409 : INFO : torch.Size([450])
2017-05-09 16:39:28,409 : INFO : torch.Size([450])
2017-05-09 16:39:28,409 : INFO : torch.Size([3, 150])
2017-05-09 16:39:28,409 : INFO : torch.Size([3])
2017-05-09 16:39:28,410 : INFO : sum
2017-05-09 16:39:28,410 : INFO : 550954
2017-05-09 16:39:28,410 : INFO : ____________
2017-05-09 17:02:42,689 : INFO : ==> Train loss   : 0.446418
2017-05-09 17:02:42,689 : INFO : Epoch
2017-05-09 17:02:42,689 : INFO : 0
2017-05-09 17:02:42,690 : INFO : train percentage
2017-05-09 17:02:42,690 : INFO : 0.813150289017
2017-05-09 17:02:42,690 : INFO : Epoch
2017-05-09 17:02:42,690 : INFO : 0
2017-05-09 17:02:42,690 : INFO : dev percentage
2017-05-09 17:02:42,690 : INFO : 0.741972477064
2017-05-09 17:02:42,690 : INFO : Epoch
2017-05-09 17:02:42,691 : INFO : 0
2017-05-09 17:02:42,691 : INFO : test percentage
2017-05-09 17:02:42,691 : INFO : 0.719934102142
2017-05-09 17:19:21,583 : INFO : LOG_FILE
2017-05-09 17:19:21,583 : INFO : _________________________________start___________________________________
2017-05-09 17:19:21,589 : INFO : Namespace(at_hid_dim=100, batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=150, num_classes=3, optim='adagrad', reg=0.0001, rel_dim=20, seed=123, tag_dim=20, wd=0, word_dim=300)
2017-05-09 17:19:21,795 : INFO : ==> SST vocabulary size : 21701
2017-05-09 17:19:21,795 : INFO : ==> SST rel vocabulary size : 44
2017-05-09 17:19:21,795 : INFO : ==> SST tag vocabulary size : 43
2017-05-09 17:19:36,981 : INFO : _param count_
2017-05-09 17:19:36,981 : INFO : torch.Size([450, 320])
2017-05-09 17:19:36,981 : INFO : torch.Size([450, 150])
2017-05-09 17:19:36,982 : INFO : torch.Size([450])
2017-05-09 17:19:36,982 : INFO : torch.Size([450])
2017-05-09 17:19:36,982 : INFO : torch.Size([1, 100])
2017-05-09 17:19:36,982 : INFO : torch.Size([1])
2017-05-09 17:19:36,982 : INFO : torch.Size([100, 490])
2017-05-09 17:19:36,982 : INFO : torch.Size([100])
2017-05-09 17:19:36,982 : INFO : torch.Size([450, 490])
2017-05-09 17:19:36,983 : INFO : torch.Size([450, 150])
2017-05-09 17:19:36,983 : INFO : torch.Size([450])
2017-05-09 17:19:36,983 : INFO : torch.Size([450])
2017-05-09 17:19:36,983 : INFO : torch.Size([3, 150])
2017-05-09 17:19:36,983 : INFO : torch.Size([3])
2017-05-09 17:19:36,983 : INFO : sum
2017-05-09 17:19:36,983 : INFO : 550954
2017-05-09 17:19:36,984 : INFO : ____________
2017-05-09 17:19:36,984 : INFO : ==> File found, loading to memory
2017-05-09 17:19:40,765 : INFO : ==> GLOVE vocabulary size: 2196016
2017-05-09 17:19:41,000 : INFO : done creating emb, quit
2017-05-09 17:19:41,000 : INFO : quit program due to memory leak during preprocess data, please rerun sentiment.py
2017-05-09 17:25:19,154 : INFO : LOG_FILE
2017-05-09 17:25:19,155 : INFO : _________________________________start___________________________________
2017-05-09 17:25:19,161 : INFO : Namespace(at_hid_dim=100, batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=150, num_classes=3, optim='adagrad', reg=0.0001, rel_dim=20, seed=123, tag_dim=20, wd=0, word_dim=300)
2017-05-09 17:25:19,361 : INFO : ==> SST vocabulary size : 21701
2017-05-09 17:25:19,361 : INFO : ==> SST rel vocabulary size : 44
2017-05-09 17:25:19,361 : INFO : ==> SST tag vocabulary size : 43
2017-05-09 17:27:42,940 : INFO : LOG_FILE
2017-05-09 17:27:42,940 : INFO : _________________________________start___________________________________
2017-05-09 17:27:42,947 : INFO : Namespace(at_hid_dim=100, batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=150, num_classes=3, optim='adagrad', reg=0.0001, rel_dim=20, seed=123, tag_dim=20, wd=0, word_dim=300)
2017-05-09 17:27:43,144 : INFO : ==> SST vocabulary size : 21701
2017-05-09 17:27:43,145 : INFO : ==> SST rel vocabulary size : 44
2017-05-09 17:27:43,145 : INFO : ==> SST tag vocabulary size : 43
2017-05-09 17:27:58,177 : INFO : _param count_
2017-05-09 17:27:58,177 : INFO : torch.Size([450, 320])
2017-05-09 17:27:58,178 : INFO : torch.Size([450, 150])
2017-05-09 17:27:58,178 : INFO : torch.Size([450])
2017-05-09 17:27:58,178 : INFO : torch.Size([450])
2017-05-09 17:27:58,178 : INFO : torch.Size([1, 100])
2017-05-09 17:27:58,178 : INFO : torch.Size([1])
2017-05-09 17:27:58,178 : INFO : torch.Size([100, 490])
2017-05-09 17:27:58,178 : INFO : torch.Size([100])
2017-05-09 17:27:58,179 : INFO : torch.Size([450, 490])
2017-05-09 17:27:58,179 : INFO : torch.Size([450, 150])
2017-05-09 17:27:58,179 : INFO : torch.Size([450])
2017-05-09 17:27:58,179 : INFO : torch.Size([450])
2017-05-09 17:27:58,179 : INFO : torch.Size([3, 150])
2017-05-09 17:27:58,179 : INFO : torch.Size([3])
2017-05-09 17:27:58,179 : INFO : sum
2017-05-09 17:27:58,179 : INFO : 550954
2017-05-09 17:27:58,180 : INFO : ____________
2017-05-09 17:27:58,180 : INFO : ==> File found, loading to memory
2017-05-09 17:28:01,972 : INFO : ==> GLOVE vocabulary size: 2196016
2017-05-09 17:28:02,211 : INFO : done creating emb, quit
2017-05-09 17:28:02,211 : INFO : quit program due to memory leak during preprocess data, please rerun sentiment.py
2017-05-09 17:28:27,240 : INFO : LOG_FILE
2017-05-09 17:28:27,240 : INFO : _________________________________start___________________________________
2017-05-09 17:28:27,247 : INFO : Namespace(at_hid_dim=100, batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=150, num_classes=3, optim='adagrad', reg=0.0001, rel_dim=20, seed=123, tag_dim=20, wd=0, word_dim=300)
2017-05-09 17:28:27,446 : INFO : ==> SST vocabulary size : 21701
2017-05-09 17:28:27,446 : INFO : ==> SST rel vocabulary size : 44
2017-05-09 17:28:27,446 : INFO : ==> SST tag vocabulary size : 43
2017-05-09 17:28:33,907 : INFO : _param count_
2017-05-09 17:28:33,907 : INFO : torch.Size([450, 320])
2017-05-09 17:28:33,907 : INFO : torch.Size([450, 150])
2017-05-09 17:28:33,908 : INFO : torch.Size([450])
2017-05-09 17:28:33,908 : INFO : torch.Size([450])
2017-05-09 17:28:33,908 : INFO : torch.Size([1, 100])
2017-05-09 17:28:33,908 : INFO : torch.Size([1])
2017-05-09 17:28:33,908 : INFO : torch.Size([100, 490])
2017-05-09 17:28:33,908 : INFO : torch.Size([100])
2017-05-09 17:28:33,909 : INFO : torch.Size([450, 490])
2017-05-09 17:28:33,909 : INFO : torch.Size([450, 150])
2017-05-09 17:28:33,909 : INFO : torch.Size([450])
2017-05-09 17:28:33,909 : INFO : torch.Size([450])
2017-05-09 17:28:33,909 : INFO : torch.Size([3, 150])
2017-05-09 17:28:33,909 : INFO : torch.Size([3])
2017-05-09 17:28:33,909 : INFO : sum
2017-05-09 17:28:33,910 : INFO : 550954
2017-05-09 17:28:33,910 : INFO : ____________
2017-05-09 17:34:56,987 : INFO : LOG_FILE
2017-05-09 17:34:56,987 : INFO : _________________________________start___________________________________
2017-05-09 17:34:57,001 : INFO : Namespace(at_hid_dim=100, batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=150, num_classes=3, optim='adagrad', reg=0.0001, rel_dim=20, seed=123, tag_dim=20, wd=0, word_dim=300)
2017-05-09 17:34:57,214 : INFO : ==> SST vocabulary size : 21701
2017-05-09 17:34:57,214 : INFO : ==> SST rel vocabulary size : 44
2017-05-09 17:34:57,215 : INFO : ==> SST tag vocabulary size : 43
2017-05-09 17:35:03,854 : INFO : _param count_
2017-05-09 17:35:03,854 : INFO : torch.Size([450, 320])
2017-05-09 17:35:03,854 : INFO : torch.Size([450, 150])
2017-05-09 17:35:03,854 : INFO : torch.Size([450])
2017-05-09 17:35:03,855 : INFO : torch.Size([450])
2017-05-09 17:35:03,855 : INFO : torch.Size([1, 100])
2017-05-09 17:35:03,855 : INFO : torch.Size([1])
2017-05-09 17:35:03,855 : INFO : torch.Size([100, 490])
2017-05-09 17:35:03,855 : INFO : torch.Size([100])
2017-05-09 17:35:03,855 : INFO : torch.Size([450, 490])
2017-05-09 17:35:03,855 : INFO : torch.Size([450, 150])
2017-05-09 17:35:03,856 : INFO : torch.Size([450])
2017-05-09 17:35:03,856 : INFO : torch.Size([450])
2017-05-09 17:35:03,856 : INFO : torch.Size([3, 150])
2017-05-09 17:35:03,856 : INFO : torch.Size([3])
2017-05-09 17:35:03,856 : INFO : sum
2017-05-09 17:35:03,856 : INFO : 550954
2017-05-09 17:35:03,856 : INFO : ____________
2017-05-09 17:56:51,364 : INFO : ==> Train loss   : 0.311503
2017-05-09 17:56:51,364 : INFO : Epoch
2017-05-09 17:56:51,365 : INFO : 0
2017-05-09 17:56:51,365 : INFO : train percentage
2017-05-09 17:56:51,365 : INFO : 0.886560693642
2017-05-09 17:56:51,365 : INFO : Epoch
2017-05-09 17:56:51,365 : INFO : 0
2017-05-09 17:56:51,365 : INFO : dev percentage
2017-05-09 17:56:51,365 : INFO : 0.81995412844
2017-05-09 17:56:51,365 : INFO : Epoch
2017-05-09 17:56:51,365 : INFO : 0
2017-05-09 17:56:51,366 : INFO : test percentage
2017-05-09 17:56:51,366 : INFO : 0.802306425041
2017-05-09 18:29:44,367 : INFO : ==> Train loss   : 0.215117
2017-05-09 18:29:44,367 : INFO : Epoch
2017-05-09 18:29:44,368 : INFO : 1
2017-05-09 18:29:44,368 : INFO : train percentage
2017-05-09 18:29:44,368 : INFO : 0.919075144509
2017-05-09 18:29:44,368 : INFO : Epoch
2017-05-09 18:29:44,368 : INFO : 1
2017-05-09 18:29:44,368 : INFO : dev percentage
2017-05-09 18:29:44,368 : INFO : 0.801605504587
2017-05-09 18:29:44,368 : INFO : Epoch
2017-05-09 18:29:44,368 : INFO : 1
2017-05-09 18:29:44,369 : INFO : test percentage
2017-05-09 18:29:44,369 : INFO : 0.805052169138
2017-05-09 19:12:03,081 : INFO : ==> Train loss   : 0.154583
2017-05-09 19:12:03,081 : INFO : Epoch
2017-05-09 19:12:03,082 : INFO : 2
2017-05-09 19:12:03,082 : INFO : train percentage
2017-05-09 19:12:03,082 : INFO : 0.946965317919
2017-05-09 19:12:03,082 : INFO : Epoch
2017-05-09 19:12:03,082 : INFO : 2
2017-05-09 19:12:03,082 : INFO : dev percentage
2017-05-09 19:12:03,082 : INFO : 0.80504587156
2017-05-09 19:12:03,082 : INFO : Epoch
2017-05-09 19:12:03,083 : INFO : 2
2017-05-09 19:12:03,083 : INFO : test percentage
2017-05-09 19:12:03,083 : INFO : 0.799011532125
2017-05-09 20:11:43,994 : INFO : ==> Train loss   : 0.110647
2017-05-09 20:11:43,995 : INFO : Epoch
2017-05-09 20:11:43,995 : INFO : 3
2017-05-09 20:11:43,995 : INFO : train percentage
2017-05-09 20:11:43,995 : INFO : 0.961416184971
2017-05-09 20:11:43,995 : INFO : Epoch
2017-05-09 20:11:43,995 : INFO : 3
2017-05-09 20:11:43,995 : INFO : dev percentage
2017-05-09 20:11:43,996 : INFO : 0.80619266055
2017-05-09 20:11:43,996 : INFO : Epoch
2017-05-09 20:11:43,996 : INFO : 3
2017-05-09 20:11:43,996 : INFO : test percentage
2017-05-09 20:11:43,996 : INFO : 0.824821526634
2017-05-09 21:18:42,144 : INFO : ==> Train loss   : 0.072817
2017-05-09 21:18:42,144 : INFO : Epoch
2017-05-09 21:18:42,145 : INFO : 4
2017-05-09 21:18:42,145 : INFO : train percentage
2017-05-09 21:18:42,145 : INFO : 0.977023121387
2017-05-09 21:18:42,145 : INFO : Epoch
2017-05-09 21:18:42,145 : INFO : 4
2017-05-09 21:18:42,145 : INFO : dev percentage
2017-05-09 21:18:42,145 : INFO : 0.808486238532
2017-05-09 21:18:42,145 : INFO : Epoch
2017-05-09 21:18:42,146 : INFO : 4
2017-05-09 21:18:42,146 : INFO : test percentage
2017-05-09 21:18:42,146 : INFO : 0.81164195497
2017-05-09 22:38:27,227 : INFO : ==> Train loss   : 0.062612
2017-05-09 22:38:27,227 : INFO : Epoch
2017-05-09 22:38:27,228 : INFO : 5
2017-05-09 22:38:27,228 : INFO : train percentage
2017-05-09 22:38:27,228 : INFO : 0.979046242775
2017-05-09 22:38:27,228 : INFO : Epoch
2017-05-09 22:38:27,228 : INFO : 5
2017-05-09 22:38:27,228 : INFO : dev percentage
2017-05-09 22:38:27,228 : INFO : 0.802752293578
2017-05-09 22:38:27,228 : INFO : Epoch
2017-05-09 22:38:27,228 : INFO : 5
2017-05-09 22:38:27,229 : INFO : test percentage
2017-05-09 22:38:27,229 : INFO : 0.807797913234
2017-05-10 00:18:50,220 : INFO : ==> Train loss   : 0.092886
2017-05-10 00:18:50,220 : INFO : Epoch
2017-05-10 00:18:50,220 : INFO : 6
2017-05-10 00:18:50,220 : INFO : train percentage
2017-05-10 00:18:50,220 : INFO : 0.966184971098
2017-05-10 00:18:50,221 : INFO : Epoch
2017-05-10 00:18:50,221 : INFO : 6
2017-05-10 00:18:50,221 : INFO : dev percentage
2017-05-10 00:18:50,221 : INFO : 0.775229357798
2017-05-10 00:18:50,221 : INFO : Epoch
2017-05-10 00:18:50,221 : INFO : 6
2017-05-10 00:18:50,221 : INFO : test percentage
2017-05-10 00:18:50,221 : INFO : 0.80340472268
2017-05-10 01:44:37,124 : INFO : LOG_FILE
2017-05-10 01:44:37,124 : INFO : _________________________________start___________________________________
2017-05-10 01:44:37,131 : INFO : Namespace(at_hid_dim=100, batchsize=25, cuda=True, data='data/sst/', emblr=0.1, epochs=200, fine_grain=False, glove='data/glove/', input_dim=300, lr=0.05, mem_dim=150, num_classes=3, optim='adagrad', reg=0.0001, rel_dim=20, seed=123, tag_dim=20, wd=0.0001, word_dim=300)
2017-05-10 01:44:37,351 : INFO : ==> SST vocabulary size : 21701
2017-05-10 01:44:37,351 : INFO : ==> SST rel vocabulary size : 44
2017-05-10 01:44:37,352 : INFO : ==> SST tag vocabulary size : 43
2017-05-10 01:44:43,921 : INFO : _param count_
2017-05-10 01:44:43,921 : INFO : torch.Size([450, 320])
2017-05-10 01:44:43,922 : INFO : torch.Size([450, 150])
2017-05-10 01:44:43,922 : INFO : torch.Size([450])
2017-05-10 01:44:43,922 : INFO : torch.Size([450])
2017-05-10 01:44:43,922 : INFO : torch.Size([1, 100])
2017-05-10 01:44:43,922 : INFO : torch.Size([1])
2017-05-10 01:44:43,922 : INFO : torch.Size([100, 490])
2017-05-10 01:44:43,923 : INFO : torch.Size([100])
2017-05-10 01:44:43,923 : INFO : torch.Size([450, 490])
2017-05-10 01:44:43,923 : INFO : torch.Size([450, 150])
2017-05-10 01:44:43,923 : INFO : torch.Size([450])
2017-05-10 01:44:43,923 : INFO : torch.Size([450])
2017-05-10 01:44:43,924 : INFO : torch.Size([3, 150])
2017-05-10 01:44:43,924 : INFO : torch.Size([3])
2017-05-10 01:44:43,924 : INFO : sum
2017-05-10 01:44:43,924 : INFO : 550954
2017-05-10 01:44:43,924 : INFO : ____________
